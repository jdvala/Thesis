{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM DE 32 class.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jdvala/Thesis/blob/master/LSTM_DE_32_class.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "m0TxQ65zixbh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Bidirectional LSTM for Geman with 32 classes\n",
        "\n",
        "The bidirectional LSTM is trained on sentence level and there are two evaluations, one on sentence level and one on document level"
      ]
    },
    {
      "metadata": {
        "id": "cIiz-Z6uivei",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Imports\n",
        "import os\n",
        "import keras\n",
        "import sys\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM, Bidirectional\n",
        "from keras.layers import Embedding as emb\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import load_model\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn\n",
        "from keras.utils import generic_utils \n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "\n",
        "# Setting seed to get reproducable results\n",
        "from numpy.random import seed\n",
        "from tensorflow import set_random_seed\n",
        "SEED = 13\n",
        "seed(SEED)\n",
        "set_random_seed(SEED)\n",
        "\n",
        "# For displaying the whole conf matrix\n",
        "np.set_printoptions(threshold=np.nan)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "H2lyy5hCjMqa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## Setting Up Google Drive\n",
        "The data used in this notebook is available in my drive."
      ]
    },
    {
      "metadata": {
        "id": "pVsPIWVTK3Gf",
        "colab_type": "code",
        "outputId": "a868c7c8-4856-4c1c-c960-bf96fe593085",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "#embding_path = '/content/gdrive/My Drive/en.de.context.emb'"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "aScNdU9Ujc_w",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Getting the data\n",
        "\n",
        "The data is pickled and hence unpickling it here.\n"
      ]
    },
    {
      "metadata": {
        "id": "lqHTjrhlkMy8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# unpickle data\n",
        "import pickle\n",
        "def unpickle(obj):\n",
        "    with open(obj, 'rb') as picklehandle:\n",
        "        toReturn = pickle.load(picklehandle)\n",
        "    return toReturn\n",
        "\n",
        "en_de_combined = unpickle('/content/gdrive/My Drive/combined_data.pkl')\n",
        "label = unpickle('/content/gdrive/My Drive/en-de-label.pkl')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mDq-U-yXjpE9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Test Train Split\n",
        "\n",
        "Before doing anything, Split the data into test and train sets, so there is no information leak from train data to test data.\n",
        "This is not a problem in case of one language as every instance is either in train or test set, but in case of multilingual data it might so happen that a document from one language is in  train set and the same document from another language might end up in test set, this might be a problem, and to avoid it we split the data as soon as we have it."
      ]
    },
    {
      "metadata": {
        "id": "z_i2lhgDk83J",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Initial Test Train Split\n",
        "train_data, test_data, train_la, test_la = train_test_split(en_de_combined, label,test_size=0.3, random_state=SEED)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QIMp2zuQkleM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Seperate the data\n",
        "\n",
        "As mentioned above there is a slight chance that the information leak might happen. Hence during curation of the data, **English** and **German** data as well as their document id(manually generated), file names, multiple labels and thier labels were combined in a single list with *'\\n\\n\\n'*(three new line characters). This was done to ensure there is no information loss what so ever."
      ]
    },
    {
      "metadata": {
        "id": "_psRNM96GxUM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def seperate_data(data, label):\n",
        "    \"\"\"Seperates data from combined data, it is seperated by '\\n\\n\\n', three new line charaters\n",
        "    Returns: english data, german data, file name, doc_id, multiple labels\n",
        "    \"\"\"\n",
        "    en_data = [] \n",
        "    de_data = []\n",
        "    file_name = []\n",
        "    doc_id = []\n",
        "    multilabel = []\n",
        "    labels = []\n",
        "    \n",
        "    if isinstance(data, list):\n",
        "        for doc, l in zip(data,label):\n",
        "            en_data.append(doc.split('\\n\\n\\n')[0])\n",
        "            de_data.append(doc.split('\\n\\n\\n')[1])\n",
        "            file_name.append(doc.split('\\n\\n\\n')[2])\n",
        "            doc_id.append(doc.split('\\n\\n\\n')[3])\n",
        "            multilabel.append(doc.split('\\n\\n\\n')[4])\n",
        "            labels.append(l)\n",
        "    return en_data,de_data, file_name, doc_id, multilabel, labels\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ci53TB18HrT-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Seperating train and test data\n",
        "train_en_data,train_de_data, train_file_name, train_doc_id, train_multilabel, train_label = seperate_data(train_data, train_la)\n",
        "\n",
        "test_en_data,test_de_data, test_file_name, test_doc_id, test_multilabel, test_label = seperate_data(test_data, test_la)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PvcWndJsluXo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Sliding Window\n",
        "\n",
        "Sliding window, helper function to chunk the incoming document into predefined chuck length and step size"
      ]
    },
    {
      "metadata": {
        "id": "T0p0-kVyEfcu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def slidingWindow(sequence,winSize,step):\n",
        "    \"\"\"Returns a generator that will iterate through\n",
        "    the defined chunks of input sequence. Input sequence\n",
        "    must be sliceable.\"\"\"\n",
        "\n",
        "    # Pre-compute number of chunks to emit\n",
        "    numOfChunks = ((len(sequence)-winSize)/step)+1\n",
        "    # Do the work\n",
        "    for i in range(0,round(numOfChunks)*step,step):\n",
        "        yield sequence[i:i+winSize]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vNgEzuTNl-nl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Numbering Labels\n",
        "\n",
        "Manually labeling the alpha labels as the evaluation based on documents will require more control over the label  "
      ]
    },
    {
      "metadata": {
        "id": "JBmZ9505DgPg",
        "colab_type": "code",
        "outputId": "db55a21c-422e-4ac5-e5e5-433f1f9be102",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "# Numbering the labels\n",
        "label_num = dict(enumerate(sorted(set(label))))\n",
        "print(label_num)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{0: 'agriculture', 1: 'audiovisual_and_media', 2: 'budget', 3: 'competition', 4: 'consumers', 5: 'culture', 6: 'customs', 7: 'development', 8: 'economic_and_monetary_affairs', 9: 'education_training_youth', 10: 'employment_and_social_policy', 11: 'energy', 12: 'enlargement', 13: 'enterprise', 14: 'environment', 15: 'external_relations', 16: 'external_trade', 17: 'fight_against_fraud', 18: 'food_safety', 19: 'foreign_and_security_policy', 20: 'human_rights', 21: 'humanitarian_aid', 22: 'information_society', 23: 'institutional_affairs', 24: 'internal_market', 25: 'justice_freedom_security', 26: 'maritime_affairs_and_fisheries', 27: 'public_health', 28: 'regional_policy', 29: 'research_innovation', 30: 'taxation', 31: 'transport'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Bqjj3K1NmWS5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Train Sentence preparation German\n",
        "\n",
        "From the training documents we are creating sentences and the giving them corresponding numeric labels to each sentence"
      ]
    },
    {
      "metadata": {
        "id": "8JImdQ4qlE9a",
        "colab_type": "code",
        "outputId": "9efcf0a0-35c9-43bb-b824-d2a1179b0a80",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# Train data preparation\n",
        "_train_sentence = []\n",
        "_train_label = []\n",
        "\n",
        "for doc, labe in zip(train_de_data, train_label):\n",
        "    # call the sliding window on doc\n",
        "    \n",
        "    slides = slidingWindow(doc.split(' '), 30, 10)\n",
        "    \n",
        "    # get the num label \n",
        "    for key, value in label_num.items():\n",
        "        if value == labe:\n",
        "            num = key\n",
        "            \n",
        "      \n",
        "    for slide in slides:\n",
        "        _train_sentence.append(slide)\n",
        "        _train_label.append(num)\n",
        "\n",
        "\n",
        "# ensuring the number of samples in train set and labels\n",
        "print(len(_train_sentence), len(_train_label))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "137319 137319\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qemei-HbmuL2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Tokenizing training sentence\n",
        "\n",
        "Toknizing the training sentences and then fitting it on train sentence and then use the same tokenizer object on test data\n",
        "Also calculate the vocabulary size which we will need in the embedding layer. "
      ]
    },
    {
      "metadata": {
        "id": "PM5hxLg-GYDH",
        "colab_type": "code",
        "outputId": "55632215-2bf4-4b71-e432-ff9a1027df22",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "cell_type": "code",
      "source": [
        "# tokenizing Sentences Using Keras tokenizer\n",
        "tokenizer = keras.preprocessing.text.Tokenizer()\n",
        "\n",
        "# Tokenizing the sentences (This process may take some time depending on your corpus size)\n",
        "tokenizer.fit_on_texts(_train_sentence)\n",
        "\n",
        "# Lets see what our vocabulary size is\n",
        "vocab_size = len(tokenizer.word_index) + 1   # We are adding 1 here because it takes indexing from zero\n",
        "print(\"Vocabulary size is: {}\".format(vocab_size))\n",
        "\n",
        "# Sentence encoding (it means we are now converting words into numbers)\n",
        "sent_encoded = tokenizer.texts_to_sequences(_train_sentence)\n",
        "print(\"The number of sentence in train set after encoding: {}\".format(len(sent_encoded)))\n",
        "\n",
        "\n",
        "# Start padding with the 30, although we wont need it, but still as precautionary measure\n",
        "max_len = len(_train_sentence[1])\n",
        "print('Maximum length of sentences in training set is', max_len)\n",
        "padded_sents = keras.preprocessing.sequence.pad_sequences(sent_encoded, maxlen=max_len, padding='post')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocabulary size is: 52239\n",
            "The number of sentence in train set after encoding: 137319\n",
            "Maximum length of sentences in training set is 30\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RXswQd3qn0Xt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## One Hot Encoding Labels\n",
        "\n",
        "The numerical labels needs to be converted into its one hot encoded form."
      ]
    },
    {
      "metadata": {
        "id": "GJbJAHtlgNYN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Converting train labels into one hot encoded form\n",
        "oht_obj = OneHotEncoder(sparse=False, categories='auto')\n",
        "oht_obj.fit((np.reshape(_train_label, (-1,1))))\n",
        "\n",
        "train_labels = oht_obj.transform((np.reshape(_train_label, (-1,1))))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "68jWOCson--a",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Callback\n",
        "\n",
        "Two call backs are used here,\n",
        "\n",
        "* *reduce_rate*:  Which helps in situation where we are stuck on a Plateau.\n",
        "* *early_stopping*: It monitors the validation loss and in case of overfitting it will wait for the number of epochs given by user before stopping the leanring process.\n"
      ]
    },
    {
      "metadata": {
        "id": "sB2BE6IjHNBk",
        "colab_type": "code",
        "outputId": "fc7fc90b-5ea7-4056-d03f-afa94be1d083",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "# Other callbacks \n",
        "reduce_rate = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=0, verbose=1, \n",
        "                                                mode='auto', epsilon=0.0001, cooldown=0, min_lr=0)\n",
        "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, \n",
        "                                           patience=2, verbose=1, mode='auto')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/callbacks.py:1065: UserWarning: `epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
            "  warnings.warn('`epsilon` argument is deprecated and '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "M8b1_QAPv_pl",
        "colab_type": "code",
        "outputId": "fa730bd9-86a2-4e49-db73-62053a4e7fec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "cell_type": "code",
      "source": [
        "learning_rate = 0.001\n",
        "optimizer = keras.optimizers.RMSprop(lr=learning_rate, rho=0.9, epsilon=None, decay=0.0)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Si5H--iso4ki",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## Model Architecture"
      ]
    },
    {
      "metadata": {
        "id": "QnatoFO6qL6W",
        "colab_type": "code",
        "outputId": "bfc17e25-3407-4c40-a9df-9b7bd5e531e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 661
        }
      },
      "cell_type": "code",
      "source": [
        "from IPython.display import Image\n",
        "Image('/content/model.png')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAKECAIAAACB3HpjAAAABmJLR0QA/wD/AP+gvaeTAAAgAElE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\nAIjhGRAAMQQIgBgCBEAMAQIg5h1GdCmeYIkYAAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "metadata": {
        "id": "Y2qkLpDhG4Pb",
        "colab_type": "code",
        "outputId": "5ad35d8d-0097-4eab-d6e7-24f098400b42",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        }
      },
      "cell_type": "code",
      "source": [
        "# Create sequential model\n",
        "model = Sequential()\n",
        "model.add(emb(vocab_size, 200, input_length=max_len))   \n",
        "model.add(Bidirectional(LSTM(40, activation='tanh',return_sequences=True, kernel_regularizer=keras.regularizers.l2(0.04))))# LSTM layer \n",
        "model.add(keras.layers.Dropout(0.5))\n",
        "model.add(Bidirectional(LSTM(40, activation='tanh',return_sequences=False, kernel_regularizer=keras.regularizers.l2(0.03))))\n",
        "model.add(keras.layers.Dropout(0.5))\n",
        "model.add(Dense(32, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer= optimizer, metrics=['accuracy'])\n",
        "print(model.summary())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 30, 200)           10447800  \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 30, 80)            77120     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 30, 80)            0         \n",
            "_________________________________________________________________\n",
            "bidirectional_2 (Bidirection (None, 80)                38720     \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 80)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 32)                2592      \n",
            "=================================================================\n",
            "Total params: 10,566,232\n",
            "Trainable params: 10,566,232\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "fI6lwDyBpGsu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Model visualization\n",
        "from keras.utils import plot_model\n",
        "plot_model(model, to_file='model.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "S_xYFvkjpES6",
        "colab_type": "code",
        "outputId": "b03f8d2f-f54d-4c96-e1ec-03d8e48a35c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        }
      },
      "cell_type": "code",
      "source": [
        "# Training the mdoel\n",
        "model.fit(padded_sents, train_labels, validation_split=0.3, epochs=20, batch_size=32, \n",
        "          verbose=1, callbacks=[reduce_rate,early_stop])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train on 96123 samples, validate on 41196 samples\n",
            "Epoch 1/20\n",
            "96123/96123 [==============================] - 621s 6ms/step - loss: 3.2347 - acc: 0.1343 - val_loss: 3.0669 - val_acc: 0.1444\n",
            "Epoch 2/20\n",
            "96123/96123 [==============================] - 617s 6ms/step - loss: 2.5827 - acc: 0.2375 - val_loss: 2.9153 - val_acc: 0.1770\n",
            "Epoch 3/20\n",
            "96123/96123 [==============================] - 620s 6ms/step - loss: 2.3175 - acc: 0.3182 - val_loss: 2.8461 - val_acc: 0.2313\n",
            "Epoch 4/20\n",
            "96123/96123 [==============================] - 626s 7ms/step - loss: 2.0738 - acc: 0.4089 - val_loss: 2.8420 - val_acc: 0.2528\n",
            "Epoch 5/20\n",
            "96123/96123 [==============================] - 636s 7ms/step - loss: 1.8633 - acc: 0.4817 - val_loss: 2.7845 - val_acc: 0.2990\n",
            "Epoch 6/20\n",
            "96123/96123 [==============================] - 1112s 12ms/step - loss: 1.7029 - acc: 0.5437 - val_loss: 2.7173 - val_acc: 0.3316\n",
            "Epoch 7/20\n",
            "96123/96123 [==============================] - 1122s 12ms/step - loss: 1.5632 - acc: 0.5935 - val_loss: 2.7380 - val_acc: 0.3486\n",
            "\n",
            "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "Epoch 8/20\n",
            "96123/96123 [==============================] - 1131s 12ms/step - loss: 1.2774 - acc: 0.6828 - val_loss: 2.7274 - val_acc: 0.3626\n",
            "\n",
            "Epoch 00008: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "Epoch 00008: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4690f6dd68>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "metadata": {
        "id": "7iDNmLaa1hMd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Saving the model\n",
        "model.save('/content/gdrive/My Drive/Thesis Models/DE_32_CLASS_LSTM.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "f3vkqxvtqtKp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Evaluation on Document level\n",
        "\n",
        "SVMs are trained on document level and to make a fair evaluation the LSTMs needs to be evaluated on document level as well, but LSTM are trained on sentence level as due to hardware limitations one can not feed the whole document hence the technique used here is a little unique. \n",
        "\n",
        "So to make a fair comparision, the evaluation has to be done manually, first the document has to be divided into sentences with same technique used during training, then when all the sentence from a single document is curated then they are encoded into numeric form and padded to make all of them of equal length.\n",
        "\n",
        "Then each sentence is predicted and the predictions are normalized and combined to make it a single prediction for the whole document.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "S5Lq1Y2hl_DG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        },
        "outputId": "e47b0e33-62e2-4384-fd48-f345af29146b"
      },
      "cell_type": "code",
      "source": [
        "# Loading the model for evaluation\n",
        "from keras.models import load_model\n",
        "model = load_model('/content/gdrive/My Drive/Thesis Models/DE_32_CLASS_LSTM.h5')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "UqYuNrVoHNuo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler, Normalizer, StandardScaler\n",
        "\n",
        "original_label = []   # list to store the original label \n",
        "predicted_label = []   # list to store the predicted label\n",
        "\n",
        "for first_data, first_label in zip(test_de_data,test_label):\n",
        "    ## TMP LIST for each doc\n",
        "    sent_pred = []\n",
        "    \n",
        "    # start chunking the text into 30 words with 10 word slide\n",
        "    slides = slidingWindow(first_data.split(' '),30,10)\n",
        "        \n",
        "    for key,value in label_num.items():\n",
        "        if value == first_label:\n",
        "            num = key\n",
        "    \n",
        "    doc_sent = []\n",
        "    for slide in slides:\n",
        "        \n",
        "        a = ' '.join(slide)\n",
        "        \n",
        "        doc_sent.append(a)\n",
        "    \n",
        "        \n",
        "    # we have the slide here, create the sequence from text to numbers\n",
        "    text_sequence = tokenizer.texts_to_sequences(doc_sent)\n",
        "\n",
        "    # pad it to make flat 30 lenght\n",
        "    text_padded = keras.preprocessing.sequence.pad_sequences(text_sequence, maxlen=30, padding='post')\n",
        "\n",
        "\n",
        "    # predict the label\n",
        "    sent_pred.append(model.predict(text_padded))        \n",
        "    \n",
        "    # normailizing the predictions before combining them.\n",
        "    nor_data = []\n",
        "    for predc in sent_pred:\n",
        "        transformer2 = Normalizer().fit(predc)\n",
        "        nor_data.append(transformer2.transform(predc))    \n",
        "        \n",
        "    # adding all the predictions of sentences of a single document into one.\n",
        "    sent = np.zeros(32)\n",
        "    for sen in nor_data:\n",
        "        for i in range(len(sen)):\n",
        "            sent += sen[i]\n",
        "    \n",
        "    # populating lists of the predicted labels and original labels for further evaluation\n",
        "    predicted_label.append(np.argmax(sent, axis=0))\n",
        "    original_label.append(num)\n",
        "    \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xoWIONwMVYYI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_label[1:10]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EQXiyNdcfvPZ",
        "colab_type": "code",
        "outputId": "8572e4ae-923b-4e58-dcc3-c135d588c369",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# Accuracy on document level\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "print(\"Accuracy of the model on document level is: {:.2f} %\".format(accuracy_score(original_label, predicted_label)*100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the model on document level is: 65.40 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RxpNYfiSrpac",
        "colab_type": "code",
        "outputId": "7484baef-9cd9-4c74-f3d4-b1ca3313344a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1154
        }
      },
      "cell_type": "code",
      "source": [
        "# Classification report and confusion Matrix\n",
        "np.set_printoptions(threshold=np.nan)\n",
        "print(confusion_matrix(original_label, predicted_label))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[20  0  0  0  1  0  0  0  0  0  0  0  0  0  3  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  1  0  0  0]\n",
            " [ 0  0  0  0  0  1  1  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  2  0\n",
            "   0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  2\n",
            "   0  1  0  0  2  3  0  0]\n",
            " [ 0  0  0  5  0  0  0  0  0  0  0  0  0  4  0  0  0  0  0  0  0  0  0  0\n",
            "   1  0  0  0  0  0  0  5]\n",
            " [ 0  0  0  0 23  0  0  0  0  0  0  0  0  0  0  0  0  0  2  0  0  0  0  1\n",
            "   7  2  0  0  0  1  0  1]\n",
            " [ 0  0  0  0  0  2  0  0  0  1  0  0  1  1  0  1  0  0  0  0  0  0  0  0\n",
            "   0  1  0  0  0  0  0  0]\n",
            " [ 1  0  0  0  1  0  7  0  0  0  1  0  0  1  1  0  1  0  0  0  0  0  0  0\n",
            "   0  2  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0 17  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0 41  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  1]\n",
            " [ 0  0  0  0  0  0  0  0  0 22  1  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  3  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  1 41  0  0  0  0  0  0  0  0  0  0  0  1  0\n",
            "   1  1  0  0  2  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  1 17  0  1  5  0  0  0  0  0  0  0  0  0\n",
            "   1  0  0  0  0  0  0  3]\n",
            " [ 0  0  0  0  0  0  0  0  1  0  0  2  9  1  0  0  0  0  0  0  0  0  0  1\n",
            "   0  1  1  0  0  0  0  0]\n",
            " [ 1  0  0  0  0  0  0  0  0  0  0  0  1  3  2  0  0  0  0  1  0  0  1  2\n",
            "   1  0  0  0  0  0  0  1]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  2 35  0  0  0  0  0  0  0  0  1\n",
            "   2  0  0  0  1  0  0  3]\n",
            " [ 0  0  0  0  0  0  0  4  0  0  0  0  0  0  0  8  2  0  0  3  0  0  0  0\n",
            "   0  4  0  0  0  1  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  1  0  3  0  9  0  0  0  0  0  0  1\n",
            "   0  0  0  0  0  0  0  0]\n",
            " [ 1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0\n",
            "   0  6  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  4  0  0  0  0  0  0  0  0  0  3  0  0  0 29  0  0  0  0  0\n",
            "   1  0  1  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  3  0  0  0  6  0  0  0  1\n",
            "   0  0  0  0  0  2  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  2  0  0  0  0  1  0  0  0  0  4  0  0  1\n",
            "   0  4  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  2  0  1  0  0  0  0  0  0  0  0  0  1  0  3  0  0\n",
            "   0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  1  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0 30  0\n",
            "   2  6  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  1  3  0  0  1  1  0  0  0  0  0  0  0  0 20\n",
            "   0  3  0  0  0  0  0  1]\n",
            " [ 0  0  0  0  6  0  0  0  2  0  4  0  0  1  0  0  0  0  0  0  0  0  7  2\n",
            "  49  1  0  0  0  0  0  2]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  2  0  1  0  0  0  0  0  0  0  0  0  4  1\n",
            "   1 54  0  0  0  1  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  3  0  0  0  0  0  0  0  0  0\n",
            "   0  0 21  0  1  0  0  2]\n",
            " [ 2  0  0  0  3  0  1  0  0  6  3  0  0  0  0  0  0  0  0  0  0  0  1  2\n",
            "   0  3  0  0  0  0  0  1]\n",
            " [ 2  0  0  0  0  0  0  0  0  0  0  1  0  0  2  0  0  0  0  0  0  0  1  0\n",
            "   0  0  0  0 14  0  0  1]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  1  0  2  0  0  1  0  0  0  0  0  1  1\n",
            "   0  2  0  0  1  5  0  0]\n",
            " [ 0  0  0  0  0  0  2  0  0  0  1  0  1  0  0  0  0  0  0  0  0  0  0  0\n",
            "   1  2  0  0  0  0  6  1]\n",
            " [ 0  0  0  0  0  0  0  1  0  0  0  0  1  3  1  0  0  0  0  0  0  0  4  0\n",
            "   3  1  0  0  0  0  0 33]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "38kGsHlrr6tk",
        "colab_type": "code",
        "outputId": "8b41acd3-dc1e-4be2-9094-ed2ae8c39350",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 745
        }
      },
      "cell_type": "code",
      "source": [
        "print(classification_report(original_label, predicted_label))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.80      0.77        25\n",
            "           1       0.00      0.00      0.00         5\n",
            "           2       0.00      0.00      0.00        10\n",
            "           3       1.00      0.33      0.50        15\n",
            "           4       0.59      0.62      0.61        37\n",
            "           5       0.67      0.29      0.40         7\n",
            "           6       0.64      0.47      0.54        15\n",
            "           7       0.68      0.94      0.79        18\n",
            "           8       0.93      0.95      0.94        43\n",
            "           9       0.69      0.85      0.76        26\n",
            "          10       0.69      0.87      0.77        47\n",
            "          11       0.81      0.61      0.69        28\n",
            "          12       0.56      0.56      0.56        16\n",
            "          13       0.14      0.23      0.17        13\n",
            "          14       0.59      0.80      0.68        44\n",
            "          15       0.57      0.36      0.44        22\n",
            "          16       0.64      0.64      0.64        14\n",
            "          17       0.00      0.00      0.00         8\n",
            "          18       0.94      0.76      0.84        38\n",
            "          19       0.55      0.50      0.52        12\n",
            "          20       1.00      0.33      0.50        12\n",
            "          21       1.00      0.43      0.60         7\n",
            "          22       0.57      0.75      0.65        40\n",
            "          23       0.56      0.67      0.61        30\n",
            "          24       0.70      0.66      0.68        74\n",
            "          25       0.56      0.84      0.67        64\n",
            "          26       0.91      0.78      0.84        27\n",
            "          27       0.00      0.00      0.00        22\n",
            "          28       0.64      0.67      0.65        21\n",
            "          29       0.38      0.36      0.37        14\n",
            "          30       1.00      0.43      0.60        14\n",
            "          31       0.60      0.70      0.65        47\n",
            "\n",
            "   micro avg       0.65      0.65      0.65       815\n",
            "   macro avg       0.60      0.54      0.55       815\n",
            "weighted avg       0.65      0.65      0.63       815\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "FsA-X2Bqo6Lh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Evaluation on Sentence level\n"
      ]
    },
    {
      "metadata": {
        "id": "dAAY4c28n23m",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# converting docs into sentences and corresponding numerical labels\n",
        "_test_sentences = []\n",
        "_test_label_alpha = []\n",
        "_test_label_num = []\n",
        "\n",
        "for _t_data, t_label in zip(test_de_data, test_label):\n",
        "    # start chunking the text into 30 words with 10 word slide\n",
        "    slides = slidingWindow(_t_data.split(' '),30,10)\n",
        "        \n",
        "    for key,value in label_num.items():\n",
        "        if value == t_label:\n",
        "            num = key\n",
        "    \n",
        "    \n",
        "    for slide in slides:\n",
        "        _test_sentences.append(' '.join(slide))\n",
        "        _test_label_alpha.append(t_label)\n",
        "        _test_label_num.append(num)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Gnl6eZ4ApV7j",
        "colab_type": "code",
        "outputId": "38f65c9e-5ec6-44a7-9eb7-1dc70df211bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "len(_test_sentences), len(_test_label_alpha), len(_test_label_num)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(59448, 59448, 59448)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "metadata": {
        "id": "0e5eYf8kqdQj",
        "colab_type": "code",
        "outputId": "4ab7513f-493b-4aac-d076-3d1c28a96849",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# Coverting labels to one hot encoded format\n",
        "test_label = oht_obj.transform(np.reshape(_test_label_num,(-1,1)))\n",
        "print(len(_test_label_num))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "59448\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ddPi9c1OVHyB",
        "colab_type": "code",
        "outputId": "b425daf8-a2be-4ea1-9994-08724644d487",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 585
        }
      },
      "cell_type": "code",
      "source": [
        "set(_test_label_num)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0,\n",
              " 1,\n",
              " 2,\n",
              " 3,\n",
              " 4,\n",
              " 5,\n",
              " 6,\n",
              " 7,\n",
              " 8,\n",
              " 9,\n",
              " 10,\n",
              " 11,\n",
              " 12,\n",
              " 13,\n",
              " 14,\n",
              " 15,\n",
              " 16,\n",
              " 17,\n",
              " 18,\n",
              " 19,\n",
              " 20,\n",
              " 21,\n",
              " 22,\n",
              " 23,\n",
              " 24,\n",
              " 25,\n",
              " 26,\n",
              " 27,\n",
              " 28,\n",
              " 29,\n",
              " 30,\n",
              " 31}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "metadata": {
        "id": "DVFw4c3iq90t",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Test sentences to numeric converstion\n",
        "test_sequences = tokenizer.texts_to_sequences(_test_sentences)\n",
        "padded_sents_test = keras.preprocessing.sequence.pad_sequences(test_sequences, maxlen=max_len, padding='post')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "U8B9g1OmrReh",
        "colab_type": "code",
        "outputId": "142e2122-fa22-48b5-e814-f568474c824c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "print(len(padded_sents_test))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "59448\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1CqU97fXrdT3",
        "colab_type": "code",
        "outputId": "98c30a87-8378-4a33-d224-e1f0c38e9ae3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "scores = model.evaluate(padded_sents_test, test_label, verbose=1)\n",
        "print(\"Accuracy on sentence level: %.2f%%\" % (scores[1]*100))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "59448/59448 [==============================] - 41s 697us/step\n",
            "Accuracy on sentence level: 35.61%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "JxEJNQLZrmz6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "pred = model.predict(padded_sents_test)\n",
        "y_pred = np.argmax(pred, axis=1)\n",
        "y_true = np.argmax(test_label, axis=1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-GdQlYdVwgAa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1723
        },
        "outputId": "4ce47105-709c-4c70-dc03-9988310cd457"
      },
      "cell_type": "code",
      "source": [
        "print(confusion_matrix(y_true, y_pred))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 963    0    4    5  100    0    5   41   34   10   47   36   48   62\n",
            "   475   16   61    4  126    0    1    0   32   32   50   24  240   52\n",
            "    84   56   16  134]\n",
            " [   1    3    0    1    8   83   57    0    5   14   11    1    4   24\n",
            "    10    6    2    2    9    1   11    0   95   10   22   29    1    8\n",
            "     4    3    1   12]\n",
            " [  23    0   20    1    1    1    6   56   38   20   24   17    9   55\n",
            "    45   19   37    7    1    0    5    3   10   56   11   38    7   13\n",
            "    88   70   16   13]\n",
            " [  18    0    0   88   12    1    3    0   12    2   20   83   12  157\n",
            "   115    2   12    2    1    0    0    0   27   56   76   24   49   23\n",
            "    21   14    6  191]\n",
            " [  80    0    0    2  694    0    4   11   13   15   50   17    2   52\n",
            "    75    1    7    0  104    0    3    0  169   69  298   79   57   28\n",
            "    12   18    1  205]\n",
            " [   0    0    0    0    1   60   12    8    6   34   13    5   30   12\n",
            "    10   27   12    5    3   22   20    6   23   20    2   50    0    7\n",
            "    10    7    1    3]\n",
            " [  42    0    0    0   34   13  306   12   20    5   36   14   22   34\n",
            "    54   18   76    9   30    5    7    3   87   32   44   84   32   22\n",
            "    26   24   79   42]\n",
            " [  31    0    7    0    1    5    9  510   35   24   27   13   27   22\n",
            "    27  105   94    9    5   47   31   26   11    7    2   17   10   21\n",
            "    39   71    5    1]\n",
            " [   8    0    0    4    8    2    4    7 3185   29  306   25   99  145\n",
            "    31    9    8    8    0    1    3    0   30  161   57   19   14   33\n",
            "    57    7    2   32]\n",
            " [   6    0    0    1    0   12    6   11   15 1123  224    4    7   23\n",
            "    11   32    8    8    3    2   46    1   49   50   23  183    2   20\n",
            "     6   11    0    0]\n",
            " [   8    0    3    3   27    3    8   26  187  263 1488   36   67   92\n",
            "    48   42   20   18   10    7   33    0  119  160  107  118   33   82\n",
            "    82   32    1   44]\n",
            " [  15    0    2   38   16    0    5    9   33   10   35  401   36  213\n",
            "   199    5   13    7    6    0    0    0   51   51   91   32   41   29\n",
            "    92   80    1  151]\n",
            " [  28    0    1   17    0    1    7   15  109   16   73  159  357  107\n",
            "    38   24   19   12    7   13   18    0   11   82   10  124   75   25\n",
            "   118   25    4   22]\n",
            " [  21    0    0    5   12    0    0   12   58    8   27   38   57  129\n",
            "    72   17   19    3    6   23    1    3   23   70   54   26   18   21\n",
            "    34   18    3   44]\n",
            " [ 128    0    1   35   42    0    4   57   28   17   49  148   29  138\n",
            "   877   28   63   11   25    0    5    0   79   56   93   73  126   89\n",
            "    87   99    3  180]\n",
            " [  23    1    4    0    1   14   37  206   30   50   51   25   77   31\n",
            "    72  231  139   16    3  139   83   23   44   15   10  178   12   17\n",
            "    87  120    5    9]\n",
            " [  44    0    0    3   12    7   35   35   12    4   26    7   14   46\n",
            "    88   53  240    6    9   11    8    4   21   36   22   34   11   25\n",
            "    17   34   10   19]\n",
            " [  17    0    0    0    9    5   32    2   23   13   13    2    2   12\n",
            "    29   30   26    5    6    2    9    0   56   26   26  123    4    8\n",
            "     3   13   15   16]\n",
            " [ 259    0    0    2  282    0   22    3    2    5   23   11    0   19\n",
            "   152    7   17    1  971    0    1    0   61   17   60   67  115   40\n",
            "     8   17   21   81]\n",
            " [   8    0    1    1    3    0    5   25    3   16   20   22   15   25\n",
            "    19   72   25   23    4  143   22    6   16   42    9   42    3   14\n",
            "    24   43    0    6]\n",
            " [   2    0    0    0    0    5    9    8   11   77   85    3   26   19\n",
            "     6   59   11   16    3   29  187    9   22   51   15  176    0   19\n",
            "     8   17    0    0]\n",
            " [  10    0    0    0    1   10    1   74   11   13   19    2   16   15\n",
            "    12   65   20   19    0  130   19  128    7   17    1   26    3    6\n",
            "     6   15    0    2]\n",
            " [  19    2    0    1   80   13   30    7   32   71  127   35   48   84\n",
            "    64   20   35   11   17    0   24    0 1327   89  323  393    7   41\n",
            "    39   71    2   81]\n",
            " [  19    0    4    4    5    2    9   16   69   90  187   37   10  102\n",
            "    44   34   12   12    4    6   12    1   52  779   92  520    4   28\n",
            "    46   36    2   68]\n",
            " [  39    1    1    4  359    4   23   15  170   59  285   41   14  209\n",
            "   140   39   38   11   40    0   10    0  574  290 1576  217   25   66\n",
            "    49   69   20  344]\n",
            " [  21    1    5    1   43   10   43   29   18  171  170   19   59  121\n",
            "    96   82   56   37   17   32  100    6  428  226  166 2465    4  100\n",
            "    47   91    3   43]\n",
            " [  80    0    8   20   19    0    9   11   20   11   25   55   26   85\n",
            "   219   13   15    4   20    2    1    0   33   39   46   39  933   33\n",
            "    81   46    2  137]\n",
            " [  51    0    0    3  100    4   26   19   18  139  269   16    9   52\n",
            "    65   29   31    6   39    3   29    2  146   48   63  147   13   99\n",
            "    19   37   15   49]\n",
            " [ 186    0    8    5   20    4    4   71  136   96  160  185  138  200\n",
            "   300   58   33   27   11    6   15    0   81   83   43   45   83   54\n",
            "   476  151    6   84]\n",
            " [   4    0    7    0    3    2    6   21   22   21   29   57   16   70\n",
            "    43   22   45    7    0    0    3    0   51   55   32   66   14   25\n",
            "    47  204    2   12]\n",
            " [  33    0    0    0    9    1   67    3   18   12   54    1   12    7\n",
            "    36   10   49    3   58    1    6    0   37   20   26   48    0   19\n",
            "     6    9  150   28]\n",
            " [  35    0    3   32  163    0    4   42   72   29   70   94   42  249\n",
            "   208   15   23    6   11    1    1    0  198   80  352  111  151   71\n",
            "    78   59    5 1053]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "CgTt24tFsllq",
        "colab_type": "code",
        "outputId": "058696e0-4f8a-4a24-a8d5-7c9b39b98e3f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 710
        }
      },
      "cell_type": "code",
      "source": [
        "print(classification_report(y_true, y_pred))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.43      0.35      0.39      2758\n",
            "           1       0.38      0.01      0.01       438\n",
            "           2       0.25      0.03      0.05       710\n",
            "           3       0.32      0.09      0.14      1027\n",
            "           4       0.34      0.34      0.34      2066\n",
            "           5       0.23      0.15      0.18       409\n",
            "           6       0.38      0.25      0.30      1212\n",
            "           7       0.37      0.41      0.39      1239\n",
            "           8       0.72      0.74      0.73      4294\n",
            "           9       0.46      0.60      0.52      1887\n",
            "          10       0.37      0.47      0.41      3167\n",
            "          11       0.25      0.24      0.25      1662\n",
            "          12       0.27      0.24      0.25      1517\n",
            "          13       0.05      0.16      0.08       822\n",
            "          14       0.24      0.34      0.28      2570\n",
            "          15       0.19      0.13      0.16      1753\n",
            "          16       0.19      0.27      0.22       893\n",
            "          17       0.02      0.01      0.01       527\n",
            "          18       0.63      0.43      0.51      2264\n",
            "          19       0.23      0.22      0.22       657\n",
            "          20       0.26      0.21      0.24       873\n",
            "          21       0.58      0.20      0.29       648\n",
            "          22       0.33      0.43      0.38      3093\n",
            "          23       0.28      0.34      0.30      2306\n",
            "          24       0.41      0.33      0.37      4732\n",
            "          25       0.44      0.52      0.48      4710\n",
            "          26       0.45      0.46      0.45      2032\n",
            "          27       0.09      0.06      0.07      1546\n",
            "          28       0.26      0.17      0.21      2769\n",
            "          29       0.13      0.23      0.17       886\n",
            "          30       0.38      0.21      0.27       723\n",
            "          31       0.34      0.32      0.33      3258\n",
            "\n",
            "   micro avg       0.36      0.36      0.36     59448\n",
            "   macro avg       0.32      0.28      0.28     59448\n",
            "weighted avg       0.37      0.36      0.35     59448\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mfE7y7tfstYZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}