{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM 2 Clusters KMeans Clustered data.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "xPmUx16HunB7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# LSTM 2 Cluster KMeans Clustered Data(EN-DE)\n",
        "\n",
        "The idea here is to divide the data into two clusters based on the results from K-Means clustering.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "WYNVUD3ZpFZj",
        "colab_type": "code",
        "outputId": "b9a82d45-d0e9-472e-dee7-6ea6d219c2e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "# Imports\n",
        "import os\n",
        "import keras\n",
        "import sys\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM, Bidirectional\n",
        "from keras.layers import Embedding as emb\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import load_model\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "eLNThdyLHGHo",
        "colab_type": "code",
        "outputId": "3b5fabe2-35ac-423f-cc02-ebdc86db650f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "embding_path = '/content/gdrive/My Drive/en.de.context.emb'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LbHesQk90IL5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# unpickle data\n",
        "import pickle\n",
        "def unpickle(obj):\n",
        "    with open(obj, 'rb') as picklehandle:\n",
        "        toReturn = pickle.load(picklehandle)\n",
        "    return toReturn\n",
        "\n",
        "\n",
        "\n",
        "en_de_combined = unpickle('/content/gdrive/My Drive/combined_data.pkl')\n",
        "label = unpickle('/content/gdrive/My Drive/en-de-label.pkl')\n",
        "# en_data = unpickle('/content/EN-DATA.pkl')\n",
        "# en_label = unpickle('/content/EN-LABEL.pkl')\n",
        "# de_data = unpickle('/content/DE-DATA.pkl')\n",
        "# de_label = unpickle('/content/DE-LABEL.pkl')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yH0Y3azSUnbc",
        "colab_type": "code",
        "outputId": "d0429f9c-c267-4bd1-fc44-d6d4ffa681d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "len(en_de_combined), len(label)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2716, 2716)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "id": "yIONIpFCocp2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Initial Test Train Split\n",
        "train_data, test_data, train_la, test_la = train_test_split(en_de_combined, label,test_size=0.3, random_state=13)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fxZqZW2Uwhru",
        "colab_type": "code",
        "outputId": "0e667c97-ffb5-4357-c8b3-d74ba3fc368e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "len(train_data)+ len(test_data)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2716"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "u_iRosbtocdP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# ## Spliting the data\n",
        "\n",
        "# def split(data, label):\n",
        "#     \"\"\"Splits the data\"\"\"\n",
        "#     en_data = []\n",
        "#     de_data = []\n",
        "#     file_name = []\n",
        "#     doc_id = []\n",
        "#     multi_label = []\n",
        "#     train_label = []\n",
        "#     en_data.append(data.split('\\n\\n\\n')[0])\n",
        "#     de_data.append(data.split('\\n\\n\\n')[1])\n",
        "#     file_name.append(data.split('\\n\\n\\n')[2])\n",
        "#     doc_id.append(data.split('\\n\\n\\n')[3])\n",
        "#     multi_label.append(data.split('\\n\\n\\n')[4])\n",
        "#     train_label.append(label)\n",
        "    \n",
        "#     return en_data, de_data, file_name, doc_id, multi_label, train_label\n",
        "\n",
        "\n",
        "# en_train_data = de_train_data = file_name_train =  doc_id_train = multilabel_train = train_label = []\n",
        "# en_test_data = de_test_data = file_name_test = doc_id_test = multilabel_test = test_label = []\n",
        "\n",
        "\n",
        "# # train_data\n",
        "# for data, label in zip(train_data, train_la):\n",
        "#     a,de_train_data,file_name_train,doc_id_train,multilabel_train,train_label = split(data, label)\n",
        "#     en_train_data.append(a)\n",
        "#     de_train_data.append(b) \n",
        "#     file_name_train.append(c) \n",
        "#     doc_id_train.append(d) \n",
        "#     multilabel_train.append(e)\n",
        "#     train_label.append(f)\n",
        "    \n",
        "\n",
        "# # # test_data\n",
        "# for data, label in zip(test_data, test_la):\n",
        "#     en_test_data,en_test_data,file_name_test,doc_id_test,multilabel_test,test_label = split(data, label)\n",
        "# #     en_test_data.append(a)\n",
        "# #     de_test_data.append(b) \n",
        "# #     file_name_test.append(c) \n",
        "# #     doc_id_test.append(d) \n",
        "# #     multilabel_test.append(e)\n",
        "# #     test_label.append(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oJTyalw5ulTp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# KMeans performed on the documents suggested that these classes should be togather in one cluster.\n",
        "cluster_1_info = ['agriculture',\n",
        " 'audiovisual_and_media',\n",
        " 'competition',\n",
        " 'consumers',\n",
        " 'employment_and_social_policy',\n",
        " 'energy',\n",
        " 'enterprise',\n",
        " 'environment',\n",
        " 'food_safety',\n",
        " 'information_society',\n",
        " 'internal_market',\n",
        " 'public_health',\n",
        " 'taxation',\n",
        " 'transport']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "47cpzbQMNeL1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# sliding window for creating sentences\n",
        "def slidingWindow(sequence,winSize,step):\n",
        "    \"\"\"Returns a generator that will iterate through\n",
        "    the defined chunks of input sequence. Input sequence\n",
        "    must be sliceable.\"\"\"\n",
        "\n",
        "    # Pre-compute number of chunks to emit\n",
        "    numOfChunks = ((len(sequence)-winSize)/step)+1\n",
        "    # Do the work\n",
        "    for i in range(0,round(numOfChunks)*step,step):\n",
        "        yield sequence[i:i+winSize]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Nf-PqYs8oSNy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# TRAIN DATA\n",
        "# dividing data with second sampling technique, the first one was already done where the duplicates from the \n",
        "# major class were removed, and if there were duplicates in the same class they were removed too.\n",
        "# we dont need the multiclass information of doc ids here so I will not bother about it here \n",
        "cluster_1_data = []\n",
        "cluster_1_label = []\n",
        "\n",
        "root_data = []\n",
        "root_label = []\n",
        "\n",
        "cluster_2_data = []\n",
        "cluster_2_label = []\n",
        "\n",
        "# for statistics\n",
        "count_cluster_1 =0\n",
        "count_cluster_2 =0\n",
        "count_root = 0\n",
        "\n",
        "# we will just divide the train data and labels\n",
        "\n",
        "for combined_doc, label in zip(train_data, train_la):\n",
        "    if label == 'content':\n",
        "        pass\n",
        "    elif label in cluster_1_info:\n",
        "        \"\"\"call the split function on the data\"\"\"\n",
        "        count_cluster_1 +=1\n",
        "        count_root +=1\n",
        "        cluster_1_data.append(combined_doc.split('\\n\\n\\n')[0])\n",
        "        cluster_1_data.append(combined_doc.split('\\n\\n\\n')[1])\n",
        "        cluster_1_label.append(label)\n",
        "        cluster_1_label.append(label)\n",
        "        \n",
        "        root_data.append(combined_doc.split('\\n\\n\\n')[0])\n",
        "        root_data.append(combined_doc.split('\\n\\n\\n')[1])\n",
        "        root_label.append(1)    # label for cluster 1 in the root classifier is 1\n",
        "        root_label.append(1)\n",
        "    elif label not in cluster_1_info:\n",
        "        count_cluster_2 +=1\n",
        "        count_root+=1\n",
        "        cluster_2_data.append(combined_doc.split('\\n\\n\\n')[0])\n",
        "        cluster_2_data.append(combined_doc.split('\\n\\n\\n')[1])\n",
        "        cluster_2_label.append(label)\n",
        "        cluster_2_label.append(label)\n",
        "        \n",
        "        root_data.append(combined_doc.split('\\n\\n\\n')[0])\n",
        "        root_data.append(combined_doc.split('\\n\\n\\n')[1])\n",
        "        root_label.append(2)    # label for cluster 2 in root classifier is 2 \n",
        "        root_label.append(2)\n",
        "    else:\n",
        "        print(\"something wrong\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pM9HlQnrpOev",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# TEST DATA\n",
        "cluster_1_data_test = []\n",
        "cluster_1_doc_id_test = []\n",
        "cluster_1_label_test = []\n",
        "cluster_1_multilabel_test = []\n",
        "cluster_1_file_name_test = []\n",
        "\n",
        "\n",
        "root_test_data = []\n",
        "root_test_label = []\n",
        "root_test_doc_id = []\n",
        "root_test_file_name = []\n",
        "root_test_multilabel = []\n",
        "\n",
        "cluster_2_data_test = []\n",
        "cluster_2_doc_id_test = []\n",
        "cluster_2_label_test = []\n",
        "cluster_2_multilabel_test = []\n",
        "cluster_2_file_name_test = []\n",
        "\n",
        "# for statistics\n",
        "count_cluster_1_test = 0\n",
        "count_cluster_2_test = 0\n",
        "count_root_test = 0\n",
        "# we will just divide the train data and labels\n",
        "\n",
        "for combine_doc, label in zip(test_data, test_la):\n",
        "    if label == 'content':\n",
        "        pass\n",
        "    elif label in cluster_1_info:\n",
        "        count_cluster_1_test +=1\n",
        "        count_root_test +=1\n",
        "        cluster_1_data_test.append(combine_doc.split('\\n\\n\\n')[0])\n",
        "        cluster_1_data_test.append(combine_doc.split('\\n\\n\\n')[1])\n",
        "        cluster_1_label_test.append(label)\n",
        "        \n",
        "        cluster_1_multilabel_test.append(combine_doc.split('\\n\\n\\n')[4])\n",
        "        cluster_1_doc_id_test.append(combine_doc.split('\\n\\n\\n')[3])\n",
        "        cluster_1_file_name_test.append(combine_doc.split('\\n\\n\\n')[2])\n",
        "        cluster_1_label_test.append(label)\n",
        "        \n",
        "        cluster_1_multilabel_test.append(combine_doc.split('\\n\\n\\n')[4])\n",
        "        cluster_1_doc_id_test.append(combine_doc.split('\\n\\n\\n')[3])\n",
        "        cluster_1_file_name_test.append(combine_doc.split('\\n\\n\\n')[2])\n",
        "        \n",
        "        root_test_data.append(combine_doc.split('\\n\\n\\n')[0])\n",
        "        root_test_data.append(combine_doc.split('\\n\\n\\n')[1])\n",
        "        root_test_label.append(1)\n",
        "        root_test_doc_id.append(combine_doc.split('\\n\\n\\n')[3])\n",
        "        root_test_file_name.append(combine_doc.split('\\n\\n\\n')[2])\n",
        "        root_test_multilabel.append(combine_doc.split('\\n\\n\\n')[4])\n",
        "        root_test_label.append(1)\n",
        "        root_test_doc_id.append(combine_doc.split('\\n\\n\\n')[3])\n",
        "        root_test_file_name.append(combine_doc.split('\\n\\n\\n')[2])\n",
        "        root_test_multilabel.append(combine_doc.split('\\n\\n\\n')[4])\n",
        "        \n",
        "    elif label not in cluster_1_info:\n",
        "        count_cluster_2_test +=1\n",
        "        count_root_test +=1\n",
        "        cluster_2_data_test.append(combine_doc.split('\\n\\n\\n')[0])\n",
        "        cluster_2_data_test.append(combine_doc.split('\\n\\n\\n')[1])\n",
        "        cluster_2_label_test.append(label)\n",
        "        cluster_2_multilabel_test.append(combine_doc.split('\\n\\n\\n')[4])\n",
        "        cluster_2_doc_id_test.append(combine_doc.split('\\n\\n\\n')[3])\n",
        "        cluster_2_file_name_test.append(combine_doc.split('\\n\\n\\n')[2])\n",
        "        cluster_2_label_test.append(label)\n",
        "        cluster_2_multilabel_test.append(combine_doc.split('\\n\\n\\n')[4])\n",
        "        cluster_2_doc_id_test.append(combine_doc.split('\\n\\n\\n')[3])\n",
        "        cluster_2_file_name_test.append(combine_doc.split('\\n\\n\\n')[2])\n",
        "        \n",
        "        root_test_data.append(combine_doc.split('\\n\\n\\n')[0])\n",
        "        root_test_data.append(combine_doc.split('\\n\\n\\n')[1])\n",
        "        root_test_label.append(2)\n",
        "        root_test_doc_id.append(combine_doc.split('\\n\\n\\n')[3])\n",
        "        root_test_file_name.append(combine_doc.split('\\n\\n\\n')[2])\n",
        "        root_test_multilabel.append(combine_doc.split('\\n\\n\\n')[4])\n",
        "        root_test_label.append(2)\n",
        "        root_test_doc_id.append(combine_doc.split('\\n\\n\\n')[3])\n",
        "        root_test_file_name.append(combine_doc.split('\\n\\n\\n')[2])\n",
        "        root_test_multilabel.append(combine_doc.split('\\n\\n\\n')[4])\n",
        "    else:\n",
        "        print(\"Something wrong\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jk0PhKbOpmlW",
        "colab_type": "code",
        "outputId": "fe04c797-3142-4ae7-b47a-a3b5074fc616",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "cell_type": "code",
      "source": [
        "# Train statistics\n",
        "print(\"Total docs in cluster 1 train are: {}\".format(len(cluster_1_data)))\n",
        "print(\"Total docs in cluster 2 train are: {}\".format(len(cluster_2_data)))\n",
        "print(\"Total docs in root_classifier train are: {}\".format(len(root_data)))\n",
        "\n",
        "# test statistics\n",
        "print(\"Total docs in cluster 1 test are: {}\".format(len(cluster_1_data_test)))\n",
        "print(\"Total docs in cluster 2 test are: {}\".format(len(cluster_2_data_test)))\n",
        "print(\"Total docs in root test are: {}\".format(len(root_test_data)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total docs in cluster 1 train are: 1980\n",
            "Total docs in cluster 2 train are: 1822\n",
            "Total docs in root_classifier train are: 3802\n",
            "Total docs in cluster 1 test are: 898\n",
            "Total docs in cluster 2 test are: 732\n",
            "Total docs in root test are: 1630\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ifP-d5V936hz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Cluster 1 "
      ]
    },
    {
      "metadata": {
        "id": "Mqdw4S08Gixl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Assiginig numbers to labels"
      ]
    },
    {
      "metadata": {
        "id": "rgeYCckJ36u1",
        "colab_type": "code",
        "outputId": "aac32ab7-0365-4a9e-a89b-81a777daa979",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "cell_type": "code",
      "source": [
        "# Assigning numbers to labels of cluster 1 and 2\n",
        "num_label_cluster_1 = dict(list(enumerate(sorted(set(cluster_1_label)))))\n",
        "num_label_cluster_1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'agriculture',\n",
              " 1: 'audiovisual_and_media',\n",
              " 2: 'competition',\n",
              " 3: 'consumers',\n",
              " 4: 'employment_and_social_policy',\n",
              " 5: 'energy',\n",
              " 6: 'enterprise',\n",
              " 7: 'environment',\n",
              " 8: 'food_safety',\n",
              " 9: 'information_society',\n",
              " 10: 'internal_market',\n",
              " 11: 'public_health',\n",
              " 12: 'taxation',\n",
              " 13: 'transport'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "metadata": {
        "id": "PRuKC8riG7Lm",
        "colab_type": "code",
        "outputId": "e76eba46-f00b-4c4e-ec48-39f0d26792d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "freq = Counter(cluster_1_label)\n",
        "freq"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({'agriculture': 130,\n",
              "         'audiovisual_and_media': 26,\n",
              "         'competition': 64,\n",
              "         'consumers': 176,\n",
              "         'employment_and_social_policy': 254,\n",
              "         'energy': 92,\n",
              "         'enterprise': 86,\n",
              "         'environment': 180,\n",
              "         'food_safety': 140,\n",
              "         'information_society': 218,\n",
              "         'internal_market': 320,\n",
              "         'public_health': 60,\n",
              "         'taxation': 50,\n",
              "         'transport': 184})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "metadata": {
        "id": "XKu-R8NUGonO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Train sentence preparation"
      ]
    },
    {
      "metadata": {
        "id": "jx-tyGFwppHx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Cluster 1 train data, sentence conversion\n",
        "cluster_1_sent_train = []  # List to store the sentence\n",
        "cluster_1_labels_train = [] # List to store the label(alpha)\n",
        "cluster_1_label_num_train = []\n",
        "\n",
        "\n",
        "for first_data, first_label in zip(cluster_1_data, cluster_1_label):\n",
        "    # start chunking the text into 30 words with 10 word slide\n",
        "    slides = slidingWindow(first_data.split(' '),30,10)\n",
        "        \n",
        "    for key,value in num_label_cluster_1.items():\n",
        "        if value == first_label:\n",
        "            num = key\n",
        "    \n",
        "    \n",
        "    for slide in slides:\n",
        "        cluster_1_sent_train.append(' '.join(slide))\n",
        "        cluster_1_labels_train.append(first_label)\n",
        "        cluster_1_label_num_train.append(num)\n",
        "\n",
        "        \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6Z8LX0RgbVE4",
        "colab_type": "code",
        "outputId": "8f7532cc-b182-4fdc-87c3-3e51db3c1e58",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "len(cluster_1_sent_train), len(cluster_1_label_num_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(109895, 109895)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "metadata": {
        "id": "wtbKz_bJMA7E",
        "colab_type": "code",
        "outputId": "07d243a0-c319-4a2c-84a7-cb2ffedaebe2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "cell_type": "code",
      "source": [
        "Counter(cluster_1_labels_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({'agriculture': 8788,\n",
              "         'audiovisual_and_media': 1501,\n",
              "         'competition': 3119,\n",
              "         'consumers': 8052,\n",
              "         'employment_and_social_policy': 14797,\n",
              "         'energy': 5600,\n",
              "         'enterprise': 4841,\n",
              "         'environment': 10005,\n",
              "         'food_safety': 7652,\n",
              "         'information_society': 14794,\n",
              "         'internal_market': 15409,\n",
              "         'public_health': 3094,\n",
              "         'taxation': 3204,\n",
              "         'transport': 9039})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "metadata": {
        "id": "4D0dmQ9CMBBd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class_weights = dict()\n",
        "\n",
        "max_value = max(Counter(cluster_1_labels_train).values())\n",
        "\n",
        "for keys, values in Counter(cluster_1_labels_train).items():\n",
        "    for _keys, _values in num_label_cluster_1.items():\n",
        "        if keys == _values:\n",
        "            class_weights[_keys] = (max_value/ values)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sVjoYlVoMBAP",
        "colab_type": "code",
        "outputId": "08d2c104-53c6-44e2-ed52-731ce36550b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "cell_type": "code",
      "source": [
        "class_weights"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 1.7534137460172963,\n",
              " 1: 10.265822784810126,\n",
              " 2: 4.940365501763385,\n",
              " 3: 1.913686040735221,\n",
              " 4: 1.0413597350814354,\n",
              " 5: 2.751607142857143,\n",
              " 6: 3.1830200371824002,\n",
              " 7: 1.5401299350324837,\n",
              " 8: 2.0137219027705173,\n",
              " 9: 1.0415709071245098,\n",
              " 10: 1.0,\n",
              " 11: 4.980284421460892,\n",
              " 12: 4.809300873907615,\n",
              " 13: 1.7047239738909172}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "metadata": {
        "id": "-VDkrW7GGvVL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### One hot encoding train and test labels"
      ]
    },
    {
      "metadata": {
        "id": "vwd7rxfUGuo4",
        "colab_type": "code",
        "outputId": "e0547e0b-f25f-4f4c-d9ea-26f70eaa859e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "cell_type": "code",
      "source": [
        "# Define one_hot_encoder object\n",
        "onehot_encoder = OneHotEncoder(sparse=False)\n",
        "\n",
        "cluster_1_train_label = onehot_encoder.fit_transform(np.reshape(cluster_1_label_num_train,(-1,1)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
            "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
            "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "AzfXxSCNG4HR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Tokenizing train sentences"
      ]
    },
    {
      "metadata": {
        "id": "bczn-grnG4kc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(num_words=10000)\n",
        "tokenizer.fit_on_texts(cluster_1_sent_train)\n",
        "cluster_1_train_sequences = tokenizer.texts_to_sequences(cluster_1_sent_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vvx8HVlOG6kh",
        "colab_type": "code",
        "outputId": "ee00e5c8-79f3-48c0-b0b5-2844ae7b6cb1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "word_index = tokenizer.word_index\n",
        "vocab_size = len(word_index)+1\n",
        "max_len = 30\n",
        "print('max_length is', max_len)\n",
        "cluster_1_padded_sents = keras.preprocessing.sequence.pad_sequences(cluster_1_train_sequences, maxlen=max_len, padding='post')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "max_length is 30\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0UP3ffY6G-RM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Embedding Matrix creation"
      ]
    },
    {
      "metadata": {
        "id": "FmheThMpG8V9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# converting embedding matrix into a form that can be used in keras embedding layer\n",
        "embeddings_index = {}\n",
        "with open(embding_path, 'r') as embpath:\n",
        "    pretrained_embeding = embpath.readlines()\n",
        "    \n",
        "    for i, line in enumerate(pretrained_embeding):\n",
        "        if i == 0:\n",
        "            pass\n",
        "        else:\n",
        "            values = line.split()\n",
        "            word = values[0]\n",
        "            coefs = np.asarray(values[1:], dtype='float32')\n",
        "            embeddings_index[word] = coefs\n",
        "\n",
        "embedding_matrix = np.zeros((len(word_index) + 1, 200))\n",
        "for word, i in word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        # words not found in embedding index will be all-zeros.\n",
        "        embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tCdLGiPM0UYL",
        "colab_type": "code",
        "outputId": "52cbc949-499f-4870-a408-7f2151feed80",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "print('shape embedding matrix: {}'.format(embedding_matrix.shape))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shape embedding matrix: (43329, 200)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "IMJwatXBCp1I",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## One Hot Encoding Labels\n",
        "\n",
        "The numerical labels needs to be converted into its one hot encoded form."
      ]
    },
    {
      "metadata": {
        "id": "MNegok1-HTY5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Callbacks\n"
      ]
    },
    {
      "metadata": {
        "id": "Is61FoE5HAeo",
        "colab_type": "code",
        "outputId": "acb79b27-2c3d-44a3-a0d4-0989fc8ed88b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "# Other callbacks \n",
        "reduce_rate = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=0, verbose=1, \n",
        "                                                mode='auto', epsilon=0.0001, cooldown=0, min_lr=0)\n",
        "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, \n",
        "                                           patience=2, verbose=1, mode='auto')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/callbacks.py:1065: UserWarning: `epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
            "  warnings.warn('`epsilon` argument is deprecated and '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "07UMP2sQ4j62",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learning_rate = 0.001\n",
        "optimizer = keras.optimizers.RMSprop(lr=learning_rate, rho=0.9, epsilon=None, decay=0.0)\n",
        "#optimizer = keras.optimizers.Adam(lr=learning_rate, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "J4RzVNho_7dD",
        "colab_type": "code",
        "outputId": "f3b0484e-5e6a-48e3-e6cc-3305417f5161",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "cell_type": "code",
      "source": [
        "# Cluster 1 train data, sentence conversion\n",
        "cluster_1_sent_test = []  # List to store the sentence\n",
        "cluster_1_labels_test = [] # List to store the label(alpha)\n",
        "cluster_1_label_num_test = []\n",
        "\n",
        "\n",
        "for first_data, first_label in zip(cluster_1_data_test, cluster_1_label_test):\n",
        "    # start chunking the text into 30 words with 10 word slide\n",
        "    slides = slidingWindow(first_data.split(' '),30,10)\n",
        "        \n",
        "    for key,value in num_label_cluster_1.items():\n",
        "        if value == first_label:\n",
        "            num = key\n",
        "    \n",
        "    \n",
        "    for slide in slides:\n",
        "        cluster_1_sent_test.append(' '.join(slide))\n",
        "        cluster_1_labels_test.append(first_label)\n",
        "        cluster_1_label_num_test.append(num)\n",
        "\n",
        "cluster_1_test_label = onehot_encoder.fit_transform(np.reshape(cluster_1_label_num_test,(-1,1)))\n",
        "cluster_1_test_sequences = tokenizer.texts_to_sequences(cluster_1_sent_test)\n",
        "# Testing the data\n",
        "cluster_1_padded_sents_test = keras.preprocessing.sequence.pad_sequences(cluster_1_test_sequences, maxlen=max_len, padding='post')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
            "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
            "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "J01A-28BG60h",
        "colab_type": "code",
        "outputId": "1aeddbe3-3eaf-4a8c-9950-3847da4b0c76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        }
      },
      "cell_type": "code",
      "source": [
        "cluster_1_test_sequences[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1882,\n",
              " 579,\n",
              " 21,\n",
              " 1156,\n",
              " 149,\n",
              " 134,\n",
              " 238,\n",
              " 186,\n",
              " 57,\n",
              " 2346,\n",
              " 91,\n",
              " 149,\n",
              " 134,\n",
              " 238,\n",
              " 186,\n",
              " 57,\n",
              " 2346,\n",
              " 91,\n",
              " 149,\n",
              " 134,\n",
              " 238,\n",
              " 186,\n",
              " 57,\n",
              " 2346,\n",
              " 91,\n",
              " 149,\n",
              " 134,\n",
              " 238,\n",
              " 186,\n",
              " 57,\n",
              " 2346,\n",
              " 91,\n",
              " 149,\n",
              " 134]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "metadata": {
        "id": "EPTWgxMHHbGM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Training"
      ]
    },
    {
      "metadata": {
        "id": "0pHqyBnrHaBy",
        "colab_type": "code",
        "outputId": "8a5ab555-3e30-4f6a-c636-ed4f100ca936",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1142
        }
      },
      "cell_type": "code",
      "source": [
        "# Create sequential model\n",
        "model = Sequential()\n",
        "model.add(emb(vocab_size, 200, weights=[embedding_matrix], input_length=30, trainable=False))   \n",
        "model.add(Bidirectional(LSTM(40, activation='tanh',return_sequences=True, kernel_regularizer=keras.regularizers.l2(0.04))))# LSTM layer \n",
        "model.add(keras.layers.Dropout(0.5))\n",
        "model.add(Bidirectional(LSTM(40, activation='tanh',return_sequences=False, kernel_regularizer=keras.regularizers.l2(0.01))))\n",
        "model.add(keras.layers.Dropout(0.5))\n",
        "model.add(Dense(14, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer= optimizer, metrics=['accuracy'])\n",
        "print(model.summary())\n",
        "model.fit(cluster_1_padded_sents, cluster_1_train_label, validation_data=(cluster_1_padded_sents_test,cluster_1_test_label), epochs=20, batch_size=32, \n",
        "          verbose=1, callbacks=[reduce_rate,early_stop])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 30, 200)           8665800   \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 30, 80)            77120     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 30, 80)            0         \n",
            "_________________________________________________________________\n",
            "bidirectional_2 (Bidirection (None, 80)                38720     \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 80)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 14)                1134      \n",
            "=================================================================\n",
            "Total params: 8,782,774\n",
            "Trainable params: 116,974\n",
            "Non-trainable params: 8,665,800\n",
            "_________________________________________________________________\n",
            "None\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train on 109895 samples, validate on 48781 samples\n",
            "Epoch 1/20\n",
            "109895/109895 [==============================] - 349s 3ms/step - loss: 2.0014 - acc: 0.4800 - val_loss: 1.8662 - val_acc: 0.4669\n",
            "Epoch 2/20\n",
            "109895/109895 [==============================] - 352s 3ms/step - loss: 1.6715 - acc: 0.5427 - val_loss: 1.8382 - val_acc: 0.4890\n",
            "Epoch 3/20\n",
            "109895/109895 [==============================] - 343s 3ms/step - loss: 1.6270 - acc: 0.5592 - val_loss: 1.8348 - val_acc: 0.4942\n",
            "Epoch 4/20\n",
            "109895/109895 [==============================] - 339s 3ms/step - loss: 1.5948 - acc: 0.5706 - val_loss: 1.8167 - val_acc: 0.5044\n",
            "Epoch 5/20\n",
            "109895/109895 [==============================] - 338s 3ms/step - loss: 1.5716 - acc: 0.5796 - val_loss: 1.7439 - val_acc: 0.5152\n",
            "Epoch 6/20\n",
            "109895/109895 [==============================] - 337s 3ms/step - loss: 1.5552 - acc: 0.5858 - val_loss: 1.7220 - val_acc: 0.5268\n",
            "Epoch 7/20\n",
            "109895/109895 [==============================] - 332s 3ms/step - loss: 1.5373 - acc: 0.5902 - val_loss: 1.7464 - val_acc: 0.5244\n",
            "\n",
            "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "Epoch 8/20\n",
            "109895/109895 [==============================] - 329s 3ms/step - loss: 1.3420 - acc: 0.6339 - val_loss: 1.5406 - val_acc: 0.5668\n",
            "Epoch 9/20\n",
            "109895/109895 [==============================] - 327s 3ms/step - loss: 1.2833 - acc: 0.6418 - val_loss: 1.5228 - val_acc: 0.5675\n",
            "Epoch 10/20\n",
            "109895/109895 [==============================] - 321s 3ms/step - loss: 1.2635 - acc: 0.6446 - val_loss: 1.5140 - val_acc: 0.5668\n",
            "Epoch 11/20\n",
            "109895/109895 [==============================] - 319s 3ms/step - loss: 1.2508 - acc: 0.6444 - val_loss: 1.5144 - val_acc: 0.5656\n",
            "\n",
            "Epoch 00011: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "Epoch 12/20\n",
            "109895/109895 [==============================] - 319s 3ms/step - loss: 1.2206 - acc: 0.6533 - val_loss: 1.5082 - val_acc: 0.5690\n",
            "Epoch 13/20\n",
            "109895/109895 [==============================] - 321s 3ms/step - loss: 1.2106 - acc: 0.6559 - val_loss: 1.5098 - val_acc: 0.5682\n",
            "\n",
            "Epoch 00013: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
            "Epoch 14/20\n",
            "109895/109895 [==============================] - 316s 3ms/step - loss: 1.2045 - acc: 0.6571 - val_loss: 1.5087 - val_acc: 0.5689\n",
            "\n",
            "Epoch 00014: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
            "Epoch 00014: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff062d84ba8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "metadata": {
        "id": "ApFDb0nU3baR",
        "colab_type": "code",
        "outputId": "61221262-02ec-43aa-c8da-cabf053225a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "model.evaluate(cluster_1_padded_sents_test, cluster_1_test_label)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "48781/48781 [==============================] - 33s 674us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.5087447229467565, 0.5689100264520536]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "metadata": {
        "id": "PKDB_PCQprMM",
        "colab_type": "code",
        "outputId": "71fffdd4-413a-4bce-c4d6-7d9f44dca3df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "cluster_1_padded_sents_test[0].shape, cluster_1_test_label[0].shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((30,), (14,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "metadata": {
        "id": "4kfJ56HSAMgX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Test Data Preparation\n"
      ]
    },
    {
      "metadata": {
        "id": "1i5UgxsFAHlD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Cluster 1 test data, sentence conversion\n",
        "from sklearn.preprocessing import MinMaxScaler, Normalizer, StandardScaler\n",
        "\n",
        "doc_id_pred = []\n",
        "file_name_pred = []\n",
        "multi_label_pred = []\n",
        "pred_one_hot_encoded = []\n",
        "label_one_hot_encoded = []\n",
        "prd_for_doc = []\n",
        "\n",
        "original_label = []\n",
        "predicted_label = []\n",
        "\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "from collections import Counter \n",
        "\n",
        "\n",
        "counter = 0\n",
        "for first_data, first_label, _doc_id, _multi, _file_name in zip(cluster_1_data_test, cluster_1_label_test, \n",
        "                                   cluster_1_doc_id_test,cluster_1_multilabel_test,\n",
        "                                   cluster_1_file_name_test ):\n",
        "    \n",
        "    ## TMP LIST for each doc\n",
        "    sent_pred = []\n",
        "    \n",
        "    # start chunking the text into 30 words with 10 word slide\n",
        "    slides = slidingWindow(first_data.split(' '),30,10)\n",
        "        \n",
        "    for key,value in num_label_cluster_1.items():\n",
        "        if value == first_label:\n",
        "            num = key\n",
        "    \n",
        "    doc_sent = []\n",
        "    for slide in slides:\n",
        "        \n",
        "        a = ' '.join(slide)\n",
        "        \n",
        "        doc_sent.append(a)\n",
        "        \n",
        "    # we have the slide here, create the sequence from text to numbers\n",
        "    text_sequence = tokenizer.texts_to_sequences(doc_sent)\n",
        "#     print(text_sequence)\n",
        "#     sys.exit()\n",
        "\n",
        "    # pad it to make flat 30 lenght\n",
        "    text_padded = keras.preprocessing.sequence.pad_sequences(text_sequence, maxlen=30, padding='post')\n",
        "\n",
        "    # Convert the label for this into one hot encoding\n",
        "    label_one_hot = onehot_encoder.fit_transform(np.reshape(num,(1,-1)))\n",
        "\n",
        "    # predict the label\n",
        "    sent_pred.append(model.predict(text_padded))        \n",
        "    \n",
        "\n",
        "     #after predicting everything for every slide\n",
        "    # take the argmax on the document \n",
        "#     doc_predictions = []\n",
        "#     for i in sent_pred: \n",
        "#         doc_predictions.append(np.argmax(i,axis=1))\n",
        "    nor_data = []\n",
        "    for predc in sent_pred:\n",
        "        transformer2 = Normalizer().fit(predc)\n",
        "        nor_data.append(transformer2.transform(predc))    \n",
        "        \n",
        "    sent = np.zeros(14)\n",
        "    for sen in nor_data:\n",
        "        for i in range(len(sen)):\n",
        "            sent += sen[i]\n",
        "    \n",
        "    predicted_label.append(np.argmax(sent, axis=0))\n",
        "    original_label.append(num)\n",
        "    \n",
        "    \n",
        "    \n",
        "#     pre_for_doc = []\n",
        "#     # count the max number of instances \n",
        "#     for sentence_pred in doc_predictions:\n",
        "#         pre_for_doc.append(Counter(sentence_pred).most_common(1)[0][0])\n",
        "   \n",
        "#     prd_for_doc.append(Counter(pre_for_doc).most_common(1)[0][0])\n",
        "  \n",
        "    # for counting precision recall and fscore\n",
        "    label_one_hot_encoded.append(num)\n",
        "    doc_id_pred.append(_doc_id)\n",
        "    file_name_pred.append(_file_name)\n",
        "    multi_label_pred.append(_multi)\n",
        "#     counter+=1\n",
        "#     if counter == 2:\n",
        "#         sys.exit()\n",
        "    \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "#         cluster_1_sent_test.append(' '.join(slide))\n",
        "#         cluster_1_labels_test.append(first_label)\n",
        "#         cluster_1_label_num_test.append(num)\n",
        "#         cluster_1_sent_file_name_test.append(_file_name)\n",
        "#         cluster_1_sent_doc_id_test.append(_doc_id)\n",
        "#         cluster_1_sent_multilabel_test.append(_multi)\n",
        "        \n",
        "        \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Z2PC3G4vXHaH",
        "colab_type": "code",
        "outputId": "87877c03-eedc-4998-b1ab-029d16cd9bbe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "len(text_sequence[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "32"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "metadata": {
        "id": "RKYSghbgHcsn",
        "colab_type": "code",
        "outputId": "ae452388-04bb-4f3d-84c8-6a662d3aaa0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "accuracy_score(original_label, predicted_label)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.779510022271715"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "metadata": {
        "id": "3TVNFRX7J_wz",
        "colab_type": "code",
        "outputId": "713f0bb4-7222-41f5-8dcf-f563f6b8b22b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "cell_type": "code",
      "source": [
        "Counter(original_label)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({0: 50,\n",
              "         1: 10,\n",
              "         2: 30,\n",
              "         3: 74,\n",
              "         4: 94,\n",
              "         5: 56,\n",
              "         6: 26,\n",
              "         7: 88,\n",
              "         8: 76,\n",
              "         9: 80,\n",
              "         10: 148,\n",
              "         11: 44,\n",
              "         12: 28,\n",
              "         13: 94})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "metadata": {
        "id": "IN5dJzbgHC8L",
        "colab_type": "code",
        "outputId": "6db7fcab-500e-4b5b-af6c-c79ab5846c5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        }
      },
      "cell_type": "code",
      "source": [
        "confusion_matrix(original_label, predicted_label)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 42,   0,   0,   3,   2,   0,   0,   2,   1,   0,   0,   0,   0,\n",
              "          0],\n",
              "       [  0,   3,   2,   0,   0,   0,   0,   0,   0,   5,   0,   0,   0,\n",
              "          0],\n",
              "       [  0,   0,  25,   0,   0,   0,   0,   0,   0,   0,   1,   0,   0,\n",
              "          4],\n",
              "       [  2,   0,   0,  45,   1,   0,   0,   2,   3,   3,  11,   0,   0,\n",
              "          7],\n",
              "       [  0,   0,   0,   0,  82,   0,   1,   0,   0,   3,   7,   1,   0,\n",
              "          0],\n",
              "       [  0,   0,   0,   2,   1,  42,   0,   6,   0,   1,   3,   1,   0,\n",
              "          0],\n",
              "       [  2,   0,   0,   0,   2,   0,  12,   3,   0,   3,   4,   0,   0,\n",
              "          0],\n",
              "       [  0,   0,   0,   2,   2,   0,   0,  77,   0,   1,   3,   0,   0,\n",
              "          3],\n",
              "       [  0,   0,   0,   6,   0,   0,   0,   4,  61,   0,   5,   0,   0,\n",
              "          0],\n",
              "       [  0,   0,   0,   0,   1,   0,   0,   0,   0,  68,   7,   0,   0,\n",
              "          4],\n",
              "       [  0,   0,   0,  10,   4,   0,   5,   1,   1,   4, 120,   1,   1,\n",
              "          1],\n",
              "       [  0,   0,   0,   4,  10,   0,   0,   0,   2,   0,   4,  24,   0,\n",
              "          0],\n",
              "       [  0,   0,   0,   0,   2,   0,   0,   0,   0,   3,   1,   0,  20,\n",
              "          2],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   8,   0,   3,   4,   0,   0,\n",
              "         79]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "metadata": {
        "id": "ppjTeB_oGm7i",
        "colab_type": "code",
        "outputId": "dd56c5c7-135d-4c10-f245-926ba3be7f6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "cell_type": "code",
      "source": [
        "print(classification_report(original_label, predicted_label))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.84      0.87        50\n",
            "           1       1.00      0.30      0.46        10\n",
            "           2       0.93      0.83      0.88        30\n",
            "           3       0.62      0.61      0.62        74\n",
            "           4       0.77      0.87      0.82        94\n",
            "           5       1.00      0.75      0.86        56\n",
            "           6       0.67      0.46      0.55        26\n",
            "           7       0.75      0.88      0.81        88\n",
            "           8       0.90      0.80      0.85        76\n",
            "           9       0.72      0.85      0.78        80\n",
            "          10       0.71      0.81      0.75       148\n",
            "          11       0.89      0.55      0.68        44\n",
            "          12       0.95      0.71      0.82        28\n",
            "          13       0.79      0.84      0.81        94\n",
            "\n",
            "   micro avg       0.78      0.78      0.78       898\n",
            "   macro avg       0.83      0.72      0.75       898\n",
            "weighted avg       0.79      0.78      0.78       898\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2knH3IVOH6hy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Evaluation"
      ]
    },
    {
      "metadata": {
        "id": "3k3VzYoQH53h",
        "colab_type": "code",
        "outputId": "03e790a8-133b-481c-f098-b1cbd479f868",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 942
        }
      },
      "cell_type": "code",
      "source": [
        "# cluster_1_test_label = onehot_encoder.transform(np.reshape(cluster_1_label_num_test,(-1,1)))\n",
        "# cluster_1_test_sequences = tokenizer.texts_to_sequences(cluster_1_sent_test)\n",
        "# model.save('my_method_cluster_1_model.h5')  # creates a HDF5 file 'my_model.h5'\n",
        "\n",
        "# # Testing the data\n",
        "# cluster_1_padded_sents_test = keras.preprocessing.sequence.pad_sequences(cluster_1_test_sequences, maxlen=max_len, padding='post')\n",
        "# scores = model.evaluate(cluster_1_padded_sents_test, cluster_1_test_label, verbose=1)\n",
        "# print(\"Accuracy: %.2f%%\" % (scores[1]*100))\n",
        "# # Classification Report (Precision, Recall and F1-Score)\n",
        "\n",
        "\n",
        "y_true = np.argmax(cluster_1_test_label, axis=1)\n",
        "y_pred = np.argmax(model.predict(cluster_1_padded_sents_test),axis=1)\n",
        "classificationReport = classification_report(y_true, y_pred)\n",
        "\n",
        "print(classificationReport)\n",
        "\n",
        "conf = confusion_matrix(y_true, y_pred)\n",
        "seaborn.heatmap(conf)\n",
        "print(confusion_matrix(y_true, y_pred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.68      0.70      4421\n",
            "           1       0.74      0.32      0.45       719\n",
            "           2       0.66      0.57      0.61      1651\n",
            "           3       0.41      0.41      0.41      3339\n",
            "           4       0.57      0.69      0.62      5064\n",
            "           5       0.68      0.48      0.57      2702\n",
            "           6       0.37      0.33      0.35      1330\n",
            "           7       0.55      0.63      0.59      4149\n",
            "           8       0.69      0.64      0.66      3657\n",
            "           9       0.51      0.62      0.56      5052\n",
            "          10       0.48      0.55      0.51      7712\n",
            "          11       0.66      0.36      0.46      2492\n",
            "          12       0.63      0.51      0.57      1186\n",
            "          13       0.65      0.60      0.62      5307\n",
            "\n",
            "   micro avg       0.57      0.57      0.57     48781\n",
            "   macro avg       0.60      0.53      0.55     48781\n",
            "weighted avg       0.58      0.57      0.57     48781\n",
            "\n",
            "[[2996   11  105  281  200    4   25  230  170   92  226   13   23   45]\n",
            " [   9  229   60    5   12    2    6    7    9  272   98    8    0    2]\n",
            " [  60    3  935   15   33   24   42   15    2   73  226    0   23  200]\n",
            " [ 108    0   26 1384  100    5    9  125  313  179  630   20   19  421]\n",
            " [ 114    3   15   73 3484   28  189  119   26  365  483   97   15   53]\n",
            " [ 100    0   31   96  107 1304   46  390   27  205  270   23   28   75]\n",
            " [  74    0   27   45  115   54  444   92   14  192  209    8   26   30]\n",
            " [ 118    1    6  181  171  197   48 2623  115  170  287   24   33  175]\n",
            " [ 155    0    1  375   47   13    1  233 2338   38  296   88   11   61]\n",
            " [  58   34   36  111  312   53   90  107   23 3129  810   36    7  246]\n",
            " [ 137    5  104  492  561  107  224  228  193  866 4209  139   97  350]\n",
            " [  51   23    3  203  688   15   29   86  101  148  222  889   23   11]\n",
            " [  45    0    7   17  137    9   10   48   19   55  180    4  608   47]\n",
            " [  90    0   53   61  179   93   46  432   52  377  695    2   47 3180]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAccAAAFKCAYAAABo0pS0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nZxrGAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 576x396 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "KAXATl5DLuNm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Cluster 2"
      ]
    },
    {
      "metadata": {
        "id": "pcJJw8T-L4D4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Assigning numbers to labels"
      ]
    },
    {
      "metadata": {
        "id": "JvgXk-4hHZOB",
        "colab_type": "code",
        "outputId": "523829eb-a66f-430b-d802-703b7289271a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "cell_type": "code",
      "source": [
        "num_label_cluster_2 = dict(list(enumerate(sorted(set(cluster_2_label)))))\n",
        "num_label_cluster_2\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'budget',\n",
              " 1: 'culture',\n",
              " 2: 'customs',\n",
              " 3: 'development',\n",
              " 4: 'economic_and_monetary_affairs',\n",
              " 5: 'education_training_youth',\n",
              " 6: 'enlargement',\n",
              " 7: 'external_relations',\n",
              " 8: 'external_trade',\n",
              " 9: 'fight_against_fraud',\n",
              " 10: 'foreign_and_security_policy',\n",
              " 11: 'human_rights',\n",
              " 12: 'humanitarian_aid',\n",
              " 13: 'institutional_affairs',\n",
              " 14: 'justice_freedom_security',\n",
              " 15: 'maritime_affairs_and_fisheries',\n",
              " 16: 'regional_policy',\n",
              " 17: 'research_innovation'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "metadata": {
        "id": "GEckdQiwMGah",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Tain sentence preparation"
      ]
    },
    {
      "metadata": {
        "id": "JkpvvKX1MDEF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Cluster 2 train data, sentence conversion\n",
        "cluster_2_sent_train = []  # List to store the sentence\n",
        "cluster_2_labels_train = [] # List to store the label(alpha)\n",
        "cluster_2_label_num_train = []\n",
        "\n",
        "\n",
        "for second_data, second_label in zip(cluster_2_data, cluster_2_label):\n",
        "    # start chunking the text into 30 words with 10 word slide\n",
        "    slides = slidingWindow(second_data.split(' '),30,10)\n",
        "        \n",
        "    for key,value in num_label_cluster_2.items():\n",
        "        if value == second_label:\n",
        "            num = key\n",
        "    \n",
        "    \n",
        "    for slide in slides:\n",
        "        cluster_2_sent_train.append(' '.join(slide))\n",
        "        cluster_2_labels_train.append(second_label)\n",
        "        cluster_2_label_num_train.append(num)\n",
        "        \n",
        "# Cluster 2 test data        \n",
        "cluster_2_sent_test = []  # List to store the sentence\n",
        "cluster_2_labels_test = [] # List to store the label(alpha)\n",
        "cluster_2_label_num_test = []\n",
        "\n",
        "\n",
        "for second_data, second_label in zip(cluster_2_data_test, cluster_2_label_test):\n",
        "    # start chunking the text into 30 words with 10 word slide\n",
        "    slides = slidingWindow(second_data.split(' '),30,10)\n",
        "        \n",
        "    for key,value in num_label_cluster_2.items():\n",
        "        if value == second_label:\n",
        "            num = key\n",
        "    \n",
        "    \n",
        "    for slide in slides:\n",
        "        cluster_2_sent_test.append(' '.join(slide))\n",
        "        cluster_2_labels_test.append(second_label)\n",
        "        cluster_2_label_num_test.append(num)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lOCPUGsAMNVD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Tokenizing train sentences & one hot encoding train test labels"
      ]
    },
    {
      "metadata": {
        "id": "9iY3p8HjMIgM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# tokenizing cluster 2 sents\n",
        "tokenizer_cls2 = Tokenizer()\n",
        "tokenizer_cls2.fit_on_texts(cluster_2_sent_train+cluster_2_sent_train)\n",
        "cluster_2_train_sequences = tokenizer_cls2.texts_to_sequences(cluster_2_sent_train)\n",
        "cluster_2_test_sequences = tokenizer_cls2.texts_to_sequences(cluster_2_sent_test)\n",
        "\n",
        "# padding the sentences\n",
        "cluster_2_padded_sents = keras.preprocessing.sequence.pad_sequences(cluster_2_train_sequences, maxlen=30, padding='post')\n",
        "\n",
        "# checking vocab size\n",
        "word_index_cls2 = tokenizer_cls2.word_index\n",
        "vocab_size_cls2 = len(word_index_cls2)+1\n",
        "onehot_encoder = OneHotEncoder(sparse=False)\n",
        "\n",
        "onehot_encoder.fit(np.reshape(cluster_2_label_num_train,(-1,1)))\n",
        "\n",
        "cluster_2_train_label = onehot_encoder.transform(np.reshape(cluster_2_label_num_train,(-1,1)))\n",
        "cluster_2_test_label = onehot_encoder.transform(np.reshape(cluster_2_label_num_test,(-1,1)))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cN7ASuyXcPif",
        "colab_type": "code",
        "outputId": "9da6f407-e588-43b7-9ba3-21d0ab59bd59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "cluster_2_train_label[1]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
              "       0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "metadata": {
        "id": "7-FPFfCwMVFK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Embedding Matrix creation"
      ]
    },
    {
      "metadata": {
        "id": "39cGLW65MQLq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# converting embedding matrix into a form that can be used in keras embedding layer\n",
        "embeddings_index_cls2 = {}\n",
        "with open(embding_path, 'r') as embpath:\n",
        "    pretrained_embeding = embpath.readlines()\n",
        "    \n",
        "    for i, line in enumerate(pretrained_embeding):\n",
        "        if i == 0:\n",
        "            pass\n",
        "        else:\n",
        "            values = line.split()\n",
        "            word = values[0]\n",
        "            coefs = np.asarray(values[1:], dtype='float32')\n",
        "            embeddings_index_cls2[word] = coefs\n",
        "            \n",
        "# preparing embedding matrix for cluster 2\n",
        "embedding_matrix_cls2 = np.zeros((len(word_index_cls2) + 1, 200))\n",
        "for word, i in word_index_cls2.items():\n",
        "    embedding_vector = embeddings_index_cls2.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        # words not found in embedding index will be all-zeros.\n",
        "        embedding_matrix_cls2[i] = embedding_vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4hq_DmG2Mbpc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**bold text**### Training\n"
      ]
    },
    {
      "metadata": {
        "id": "2mEKGliGMZNH",
        "colab_type": "code",
        "outputId": "42b6690b-9da4-4652-d522-32f300c0f0ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1360
        }
      },
      "cell_type": "code",
      "source": [
        "# Create sequential model_cls2\n",
        "model_cls2 = Sequential()\n",
        "model_cls2.add(emb(vocab_size_cls2, 200, weights=[embedding_matrix_cls2], input_length=30, trainable=False))   \n",
        "model_cls2.add(Bidirectional(LSTM(40, activation='tanh',return_sequences=True, kernel_regularizer=keras.regularizers.l2(0.1))))# LSTM layer \n",
        "model_cls2.add(keras.layers.Dropout(0.4))\n",
        "model_cls2.add(Bidirectional(LSTM(40, activation='tanh',return_sequences=False, kernel_regularizer=keras.regularizers.l2(0.1))))\n",
        "model_cls2.add(keras.layers.Dropout(0.4))\n",
        "model_cls2.add(Dense(18, activation='softmax'))\n",
        "model_cls2.compile(loss='categorical_crossentropy', optimizer= 'adam', metrics=['accuracy'])\n",
        "print(model_cls2.summary())\n",
        "model_cls2.fit(cluster_2_padded_sents, cluster_2_train_label, validation_split=0.2, epochs=50, batch_size=512, \n",
        "          verbose=1, callbacks=[reduce_rate,early_stop])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, 30, 200)           7863200   \n",
            "_________________________________________________________________\n",
            "bidirectional_3 (Bidirection (None, 30, 80)            77120     \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 30, 80)            0         \n",
            "_________________________________________________________________\n",
            "bidirectional_4 (Bidirection (None, 80)                38720     \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 80)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 18)                1458      \n",
            "=================================================================\n",
            "Total params: 7,980,498\n",
            "Trainable params: 117,298\n",
            "Non-trainable params: 7,863,200\n",
            "_________________________________________________________________\n",
            "None\n",
            "Train on 89319 samples, validate on 22330 samples\n",
            "Epoch 1/50\n",
            "89319/89319 [==============================] - 139s 2ms/step - loss: 15.7409 - acc: 0.3110 - val_loss: 2.6408 - val_acc: 0.3570\n",
            "Epoch 2/50\n",
            "89319/89319 [==============================] - 134s 2ms/step - loss: 2.0382 - acc: 0.4461 - val_loss: 2.1282 - val_acc: 0.3764\n",
            "Epoch 3/50\n",
            "89319/89319 [==============================] - 139s 2ms/step - loss: 1.8504 - acc: 0.4745 - val_loss: 2.0640 - val_acc: 0.4076\n",
            "Epoch 4/50\n",
            "89319/89319 [==============================] - 141s 2ms/step - loss: 1.8098 - acc: 0.4926 - val_loss: 1.9776 - val_acc: 0.4204\n",
            "Epoch 5/50\n",
            "89319/89319 [==============================] - 141s 2ms/step - loss: 1.7668 - acc: 0.5089 - val_loss: 1.9703 - val_acc: 0.4251\n",
            "Epoch 6/50\n",
            "89319/89319 [==============================] - 142s 2ms/step - loss: 1.7305 - acc: 0.5193 - val_loss: 1.9142 - val_acc: 0.4607\n",
            "Epoch 7/50\n",
            "89319/89319 [==============================] - 142s 2ms/step - loss: 1.6981 - acc: 0.5277 - val_loss: 1.9109 - val_acc: 0.4607\n",
            "Epoch 8/50\n",
            "89319/89319 [==============================] - 141s 2ms/step - loss: 1.6732 - acc: 0.5365 - val_loss: 1.8868 - val_acc: 0.4676\n",
            "Epoch 9/50\n",
            "89319/89319 [==============================] - 142s 2ms/step - loss: 1.6479 - acc: 0.5424 - val_loss: 1.8783 - val_acc: 0.4690\n",
            "Epoch 10/50\n",
            "89319/89319 [==============================] - 143s 2ms/step - loss: 1.6370 - acc: 0.5458 - val_loss: 1.9051 - val_acc: 0.4609\n",
            "\n",
            "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "Epoch 11/50\n",
            "89319/89319 [==============================] - 141s 2ms/step - loss: 1.5479 - acc: 0.5696 - val_loss: 1.7838 - val_acc: 0.4943\n",
            "Epoch 12/50\n",
            "89319/89319 [==============================] - 142s 2ms/step - loss: 1.5135 - acc: 0.5738 - val_loss: 1.7609 - val_acc: 0.4994\n",
            "Epoch 13/50\n",
            "89319/89319 [==============================] - 141s 2ms/step - loss: 1.4984 - acc: 0.5766 - val_loss: 1.7555 - val_acc: 0.4971\n",
            "Epoch 14/50\n",
            "89319/89319 [==============================] - 141s 2ms/step - loss: 1.4877 - acc: 0.5778 - val_loss: 1.7487 - val_acc: 0.4977\n",
            "Epoch 15/50\n",
            "89319/89319 [==============================] - 140s 2ms/step - loss: 1.4794 - acc: 0.5782 - val_loss: 1.7401 - val_acc: 0.4999\n",
            "Epoch 16/50\n",
            "89319/89319 [==============================] - 141s 2ms/step - loss: 1.4724 - acc: 0.5795 - val_loss: 1.7506 - val_acc: 0.4953\n",
            "\n",
            "Epoch 00016: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "Epoch 17/50\n",
            "89319/89319 [==============================] - 141s 2ms/step - loss: 1.4517 - acc: 0.5845 - val_loss: 1.7310 - val_acc: 0.5023\n",
            "Epoch 18/50\n",
            "89319/89319 [==============================] - 141s 2ms/step - loss: 1.4477 - acc: 0.5856 - val_loss: 1.7310 - val_acc: 0.5016\n",
            "\n",
            "Epoch 00018: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
            "Epoch 19/50\n",
            "89319/89319 [==============================] - 141s 2ms/step - loss: 1.4466 - acc: 0.5857 - val_loss: 1.7291 - val_acc: 0.5022\n",
            "Epoch 20/50\n",
            "89319/89319 [==============================] - 141s 2ms/step - loss: 1.4470 - acc: 0.5871 - val_loss: 1.7283 - val_acc: 0.5022\n",
            "Epoch 21/50\n",
            "89319/89319 [==============================] - 141s 2ms/step - loss: 1.4438 - acc: 0.5877 - val_loss: 1.7272 - val_acc: 0.5025\n",
            "Epoch 22/50\n",
            "89319/89319 [==============================] - 140s 2ms/step - loss: 1.4431 - acc: 0.5876 - val_loss: 1.7278 - val_acc: 0.5020\n",
            "\n",
            "Epoch 00022: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
            "Epoch 23/50\n",
            "89319/89319 [==============================] - 140s 2ms/step - loss: 1.4443 - acc: 0.5868 - val_loss: 1.7278 - val_acc: 0.5020\n",
            "\n",
            "Epoch 00023: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
            "Epoch 00023: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff04e9abe80>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "metadata": {
        "id": "e7wu5EtCMexV",
        "colab_type": "code",
        "outputId": "179e7ecf-ee11-4a32-cd6b-b9a08109766c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1418
        }
      },
      "cell_type": "code",
      "source": [
        "# Testing the data\n",
        "model_cls2.save('my_method_cluster_2_model.h5')  # creates a HDF5 file 'my_model.h5'\n",
        "\n",
        "#cluster_2_test_sequences = tokenizer_cls2.texts_to_sequences(cluster_2_sent_test)\n",
        "cluster_2_padded_sents_test = keras.preprocessing.sequence.pad_sequences(cluster_2_test_sequences, maxlen=30, padding='post')\n",
        "\n",
        "scores_cls2 = model_cls2.evaluate(cluster_2_padded_sents_test, cluster_2_test_label, verbose=1)\n",
        "print(\"Accuracy: %.2f%%\" % (scores_cls2[1]*100))\n",
        "\n",
        "y_true = np.argmax(cluster_2_test_label, axis=1)\n",
        "y_pred = np.argmax(model_cls2.predict(cluster_2_padded_sents_test),axis=1)\n",
        "classificationReport_cls2 = classification_report(y_true, y_pred)\n",
        "\n",
        "print(classificationReport_cls2)\n",
        "\n",
        "\n",
        "conf_cls2 = confusion_matrix(y_true, y_pred)\n",
        "seaborn.heatmap(conf_cls2)\n",
        "print(confusion_matrix(y_true, y_pred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "47157/47157 [==============================] - 34s 714us/step\n",
            "Accuracy: 49.73%\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.45      0.21      0.29      1139\n",
            "           1       0.47      0.01      0.03       652\n",
            "           2       0.49      0.31      0.38      1964\n",
            "           3       0.27      0.45      0.34      1986\n",
            "           4       0.72      0.82      0.77      6914\n",
            "           5       0.52      0.77      0.62      3027\n",
            "           6       0.38      0.34      0.36      2462\n",
            "           7       0.40      0.07      0.12      2793\n",
            "           8       0.31      0.40      0.35      1451\n",
            "           9       0.26      0.16      0.20       840\n",
            "          10       0.23      0.29      0.26      1061\n",
            "          11       0.47      0.12      0.19      1417\n",
            "          12       0.32      0.19      0.24      1050\n",
            "          13       0.39      0.49      0.43      3687\n",
            "          14       0.53      0.69      0.60      7592\n",
            "          15       0.56      0.60      0.58      3276\n",
            "          16       0.66      0.37      0.47      4443\n",
            "          17       0.35      0.47      0.40      1403\n",
            "\n",
            "   micro avg       0.50      0.50      0.50     47157\n",
            "   macro avg       0.43      0.38      0.37     47157\n",
            "weighted avg       0.50      0.50      0.47     47157\n",
            "\n",
            "[[ 240    0   34   68  185   48   11    4   16   52    6    1   10   81\n",
            "    81   50  182   70]\n",
            " [   8    9    0   17   16  303  108    3    1    0    4    0    1   42\n",
            "    31   18   30   61]\n",
            " [   3    0  603   13   63    8  306   18  122   32   11    0    0  132\n",
            "   438  165    6   44]\n",
            " [   7    0   19  899  117  112   83   72  188    4   33   13  118   40\n",
            "   101   42   89   49]\n",
            " [  43    0    3   37 5663  167  264    3   28   72    8    0    7  244\n",
            "   144   80  116   35]\n",
            " [   1    0    5   37   93 2331    8    2    5    0   46    5    5   92\n",
            "   256   31   43   67]\n",
            " [   4    0   40  145  363   19  844   36   62   12   43   16   14  216\n",
            "   328  234   42   44]\n",
            " [   3    0   77  820   98  120  118  202  411   13  153   16   33   67\n",
            "   404   53   56  149]\n",
            " [   1    0   78  120   62   20   25   33  581    2   38    3    5  194\n",
            "   144  118    9   18]\n",
            " [   7    0  108   13   53    7    1    5   41  136    9    0    1   88\n",
            "   305   35    7   24]\n",
            " [  15    1   15   90    9   38   18   18   24    3  309   26   44  126\n",
            "   208   23   21   73]\n",
            " [   0    0    2   57   33  180   22   22    9    2  191  166   55  131\n",
            "   508   15   11   13]\n",
            " [   0    0    8   91   14   34   13   18   19    2  196   58  196  204\n",
            "   168    6   14    9]\n",
            " [  26    1   32   20  117  199   20    5   51   40  129   11    7 1790\n",
            "  1010   45   22  162]\n",
            " [  43    1  166   93  121  273  123   50  146  113  141   28   78  711\n",
            "  5216  119   51  119]\n",
            " [  36    2   15  213  199   66   54    8   78   28   13    1    8  124\n",
            "   282 1958  130   61]\n",
            " [  76    4   13  562  538  368  157    5   33   12    8    4   31  180\n",
            "   175  426 1647  204]\n",
            " [  19    1    4   70   68  154   61    7   39    2   16    2    3  114\n",
            "    89   66   27  661]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAccAAAFKCAYAAABo0pS0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niMgIiyMREZERFkciIiIj/wPBtFznjLATrgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 576x396 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "WntUbP5k7Km1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "doc_id_pred = []\n",
        "file_name_pred = []\n",
        "multi_label_pred = []\n",
        "pred_one_hot_encoded = []\n",
        "label_one_hot_encoded = []\n",
        "prd_for_doc = []\n",
        "\n",
        "original_label = []\n",
        "predicted_label = []\n",
        "\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "from collections import Counter \n",
        "\n",
        "\n",
        "counter = 0\n",
        "for first_data, first_label in zip(cluster_2_data_test, cluster_2_label_test):\n",
        "    \n",
        "    ## TMP LIST for each doc\n",
        "    sent_pred = []\n",
        "    \n",
        "    # start chunking the text into 30 words with 10 word slide\n",
        "    slides = slidingWindow(first_data.split(' '),30,10)\n",
        "        \n",
        "    for key,value in num_label_cluster_2.items():\n",
        "        if value == first_label:\n",
        "            num = key\n",
        "    \n",
        "    doc_sent = []\n",
        "    for slide in slides:\n",
        "        \n",
        "        a = ' '.join(slide)\n",
        "        \n",
        "        doc_sent.append(a)\n",
        "        \n",
        "    # we have the slide here, create the sequence from text to numbers\n",
        "    text_sequence = tokenizer_cls2.texts_to_sequences(doc_sent)\n",
        "#     print(text_sequence)\n",
        "#     sys.exit()\n",
        "\n",
        "    # pad it to make flat 30 lenght\n",
        "    text_padded = keras.preprocessing.sequence.pad_sequences(text_sequence, maxlen=30, padding='post')\n",
        "\n",
        "    # Convert the label for this into one hot encoding\n",
        "    label_one_hot = onehot_encoder.fit_transform(np.reshape(num,(1,-1)))\n",
        "\n",
        "    # predict the label\n",
        "    sent_pred.append(model_cls2.predict(text_padded))        \n",
        "    \n",
        "\n",
        "     #after predicting everything for every slide\n",
        "    # take the argmax on the document \n",
        "#     doc_predictions = []\n",
        "#     for i in sent_pred: \n",
        "#         doc_predictions.append(np.argmax(i,axis=1))\n",
        "    nor_data = []\n",
        "    for predc in sent_pred:\n",
        "        transformer2 = Normalizer().fit(predc)\n",
        "        nor_data.append(transformer2.transform(predc))    \n",
        "        \n",
        "    sent = np.zeros(18)\n",
        "    for sen in nor_data:\n",
        "        for i in range(len(sen)):\n",
        "            sent += sen[i]\n",
        "    \n",
        "    predicted_label.append(np.argmax(sent, axis=0))\n",
        "    original_label.append(num)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uBJlEkwQmCSr",
        "colab_type": "code",
        "outputId": "14ad4f03-c89a-4604-a6c8-968fa09090d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "accuracy_score(original_label, predicted_label)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6953551912568307"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "metadata": {
        "id": "mVgXe4bE2p5x",
        "colab_type": "code",
        "outputId": "d49f10b9-da9d-40bf-b665-d52d82f55293",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        }
      },
      "cell_type": "code",
      "source": [
        "confusion_matrix(original_label, predicted_label)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  9,   0,   0,   1,   3,   1,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   2,   0,   4,   0],\n",
              "       [  0,   0,   0,   0,   0,  12,   2,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0],\n",
              "       [  0,   0,  13,   0,   0,   0,   6,   0,   2,   0,   0,   0,   0,\n",
              "          0,   9,   0,   0,   0],\n",
              "       [  0,   0,   0,  29,   1,   2,   0,   0,   3,   0,   0,   0,   1,\n",
              "          0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,  85,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          1,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,  49,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   3,   0,   0,   0],\n",
              "       [  0,   0,   0,   1,   2,   0,  21,   0,   1,   0,   0,   0,   0,\n",
              "          3,   2,   2,   0,   0],\n",
              "       [  0,   0,   0,  25,   1,   0,   1,   2,   7,   0,   1,   0,   0,\n",
              "          0,   6,   0,   0,   1],\n",
              "       [  0,   0,   1,   3,   2,   0,   0,   0,  18,   0,   0,   0,   0,\n",
              "          3,   1,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   4,   0,   0,   0,\n",
              "          0,  10,   2,   0,   0],\n",
              "       [  0,   0,   0,   2,   0,   0,   0,   0,   0,   0,  13,   0,   0,\n",
              "          3,   5,   0,   0,   1],\n",
              "       [  0,   0,   0,   0,   0,   3,   0,   0,   0,   0,   2,   5,   0,\n",
              "          1,  13,   0,   0,   0],\n",
              "       [  0,   0,   0,   1,   0,   0,   0,   0,   0,   0,   3,   1,   6,\n",
              "          1,   2,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   4,   0,   0,   0,   0,   1,   0,   0,\n",
              "         39,  11,   0,   0,   5],\n",
              "       [  0,   0,   1,   0,   0,   3,   0,   0,   2,   0,   1,   0,   0,\n",
              "          3, 117,   0,   0,   1],\n",
              "       [  1,   0,   0,   1,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   1,  49,   0,   0],\n",
              "       [  0,   0,   0,   6,   3,   1,   0,   0,   0,   0,   0,   0,   0,\n",
              "          3,   1,   0,  28,   0],\n",
              "       [  0,   0,   0,   0,   1,   3,   0,   0,   0,   0,   0,   0,   0,\n",
              "          1,   1,   0,   0,  22]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "metadata": {
        "id": "PM4fa5A420dc",
        "colab_type": "code",
        "outputId": "498e9eae-d810-441f-e275-5b576a2ec601",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        }
      },
      "cell_type": "code",
      "source": [
        "print(classification_report(original_label, predicted_label))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.45      0.60        20\n",
            "           1       0.00      0.00      0.00        14\n",
            "           2       0.87      0.43      0.58        30\n",
            "           3       0.42      0.81      0.55        36\n",
            "           4       0.85      0.99      0.91        86\n",
            "           5       0.63      0.94      0.75        52\n",
            "           6       0.70      0.66      0.68        32\n",
            "           7       1.00      0.05      0.09        44\n",
            "           8       0.55      0.64      0.59        28\n",
            "           9       1.00      0.25      0.40        16\n",
            "          10       0.62      0.54      0.58        24\n",
            "          11       0.83      0.21      0.33        24\n",
            "          12       0.86      0.43      0.57        14\n",
            "          13       0.67      0.65      0.66        60\n",
            "          14       0.64      0.91      0.75       128\n",
            "          15       0.92      0.91      0.92        54\n",
            "          16       0.88      0.67      0.76        42\n",
            "          17       0.73      0.79      0.76        28\n",
            "\n",
            "   micro avg       0.70      0.70      0.70       732\n",
            "   macro avg       0.73      0.57      0.58       732\n",
            "weighted avg       0.74      0.70      0.66       732\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}