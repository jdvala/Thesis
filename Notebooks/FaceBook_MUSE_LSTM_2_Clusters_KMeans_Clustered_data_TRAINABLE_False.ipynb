{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FaceBook MUSE LSTM 2 Clusters KMeans Clustered data TRAINABLE-False.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "xPmUx16HunB7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# LSTM 2 Cluster KMeans Clustered Data(EN-DE) with Facebooks MUSE word embedding\n",
        "\n",
        "The idea here is to divide the data into two clusters based on the results from K-Means clustering. Trainable False\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "WYNVUD3ZpFZj",
        "colab_type": "code",
        "outputId": "34b2a7d6-b1d0-4f92-88f1-d22be701c328",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "# Imports\n",
        "import os\n",
        "import keras\n",
        "import sys\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM, Bidirectional\n",
        "from keras.layers import Embedding as emb\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import load_model\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn \n",
        "\n",
        "# Setting seed to get reproducable results\n",
        "from numpy.random import seed\n",
        "from tensorflow import set_random_seed\n",
        "SEED = 13\n",
        "seed(SEED)\n",
        "set_random_seed(SEED)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "eLNThdyLHGHo",
        "colab_type": "code",
        "outputId": "ae970a5f-e390-4475-ece0-d5a8324ac588",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "TEeI0omc0F10",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Getting English and German word embeddings\n",
        "with open('/content/gdrive/My Drive/Thesis/fbMUSE/wiki.multi.en.vec') as e:\n",
        "    en_vec = e.readlines()\n",
        "with open('/content/gdrive/My Drive/Thesis/fbMUSE/wiki.multi.de.vec') as d:\n",
        "    de_vec = d.readlines()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YBd_CLDaH6NR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "en_de= en_vec+de_vec"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7-Y-5EKbnpAJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Preparing Data\n",
        "The word embedding created using facebooks MUSE are not preprocessed in anyway except fot lower case the words. So in order to use these word embedding we need the data into the same format. "
      ]
    },
    {
      "metadata": {
        "id": "DaS4Gsp1Eb0B",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!unzip /content/gdrive/My\\ Drive/Thesis/data/Scrapped_raw.zip "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RLnKeFeGqMvS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!python removeMajority_drive.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OLyX7ZHoGtFE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The above command will create dataset for the training of facebooks word embeddings as the embeddings were trained on unprocessed data, I had to prepare that too. All though all the words need to be lower cased."
      ]
    },
    {
      "metadata": {
        "id": "J5B7SaFVq1nx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# unpickle data\n",
        "import pickle\n",
        "def unpickle(obj):\n",
        "    with open(obj, 'rb') as picklehandle:\n",
        "        toReturn = pickle.load(picklehandle)\n",
        "    return toReturn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LbHesQk90IL5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "en_de_combined = unpickle('/content/combined_data.pkl')\n",
        "label = unpickle('/content/en-de-label.pkl')\n",
        "# en_data = unpickle('/content/EN-DATA.pkl')\n",
        "# en_label = unpickle('/content/EN-LABEL.pkl')\n",
        "# de_data = unpickle('/content/DE-DATA.pkl')\n",
        "# de_label = unpickle('/content/DE-LABEL.pkl')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yH0Y3azSUnbc",
        "colab_type": "code",
        "outputId": "051c841e-7edc-4477-fef1-84c0d40cec39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "len(en_de_combined), len(label)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2701, 2701)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "yIONIpFCocp2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Initial Test Train Split\n",
        "train_data, test_data, train_la, test_la = train_test_split(en_de_combined, label,test_size=0.3, random_state=13)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fxZqZW2Uwhru",
        "colab_type": "code",
        "outputId": "8362a96a-71fa-483b-a3f6-4a4dcf5097d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "len(train_data)+ len(test_data)\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2701"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "metadata": {
        "id": "M6fWb3IfG7g7",
        "colab_type": "code",
        "outputId": "658006a6-3028-4128-da6f-805907c9ee60",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "cell_type": "code",
      "source": [
        "train_data[1]"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Noise emission by equipment used outdoors Noise emission by equipment used outdoors SUMMARY OF: Directive 2000/14/EC on noise emission in the environment by equipment for use outdoors WHAT IS THE AIM OF THE DIRECTIVE? It aims to: improve the control of noise emissions by 57 types of equipment used outdoors (Articles 12 and 13, Annex I), such as: compressors,excavator-loaders,different types of saws,mixers, etc.; promote the smooth functioning of the EU single market; improve the health and well-being of citizens by reducing the noise emitted by equipment used outdoors. It repeals and replaces legal instruments on noise emissions for each type of construction plant and equipment, as well as Directive 84/538/EEC on lawnmowers. KEY POINTS The directives purpose is four-fold: to harmonise noise emission standards; to harmonise conformity assessment* procedures; to harmonise noise level marking; to gather data on noise emissions. The following types of equipment are excluded: non-powered attachments (to tools) that are separately placed on the market or put into service* (except for hand-held concrete-breakers and picks); all equipment intended for the transport of goods or persons by public road or rail or by air or on waterways; equipment designed and constructed for use by the police or the military. EU countries are responsible for verifying that the rules laid down by the directive are being applied. Annexes to VIII contains the various conformity assessment procedures to be used. The manufacturer or the person placing the equipment on the market or putting it into service must ensure (Articles and 8) that: they have drawn up an ‘EC declaration of conformity certifying that each of item of equipment bearing the CE marking conforms with the directive; they have affixed an indelible legible marking to each item of equipment indicating the guaranteed sound power level. Where an EU country ascertains that equipment does not comply with these conditions, it must withdraw it from the market or prohibit its use. Labelling is compulsory for all items of equipment covered by the directive and must include: the CE marking visibly, legibly and indelibly affixed to each item of equipment; details of the sound power level LWA* in dB(A)* in relation to pW*. The noise emission limits laid down for certain types of equipment involved stages, so as to enable businesses to adapt to the new regulations. The emission limits for stage took effect years after the directives entry into force and more stringent limits entered into force in 2006. EU countries may set up notified bodies which are responsible for monitoring the noise emission limits applicable to the equipment. These monitoring controls apply both to the equipment design phase and the equipment production phase. It should be noted, however, that it is not necessary to monitor the design of equipment that is subject only to compulsory marking. With view to assessing the impact of the directive, procedure for the collection of noise emission data was established. This information serves as the basis for customers to choose less noisy equipment and for devising economic incentives and awards. Manufacturers or their authorised representatives are required to send to the relevant authorities in EU countries, as well as to the European Commission, copy of the EC declaration of conformity for equipment placed on the market. The directive has 24 articles and 10 annexes covering: definitions of equipment; EC declaration of conformity; method of measurement of airborne noise emitted by equipment for use outdoors; models of the CE marking of conformity and of the indication of the guaranteed sound power level; internal control of production; internal control of production with assessment of technical documentation and periodical checking; unit verification; full quality assurance; minimum criteria to be taken into account by EU countries for the notification of bodies (the notified bodies mentioned above); unit verification model of conformity certificate. Possible revisions to the legislation An evaluation and impact assessment study of Directive 2000/14/EC has been ongoing since May 2017. Its results, as well as previously completed studies, will be used by the Commission as the basis for the upcoming revision process of EU legislation in this field. public consultation was launched in January 2018 and ran until April 2018. FROM WHEN DOES THE DIRECTIVE APPLY? It has applied since January 2002 and had to become law in the EU countries by July 2001. BACKGROUND For more information, see: Noise emission by outdoor equipment (European Commission). KEY TERMS Conformity assessment: the process confirming that product satisfies the necessary process, service, system, person or body requirements. Putting into service: the moment of first use by the end-user for purposes for which the good was intended. LWA: measure of the acoustic energy emitted by machine, i.e. the sound power. dB(A): average sound level in decibels as perceived by the human ear. 1pW: picowatt the international standard reference value of sound power when this quantity is expressed as level in decibels. MAIN DOCUMENT Directive 2000/14/EC of the European Parliament and of the Council of May 2000 on the approximation of the laws of the Member States relating to the noise emission in the environment by equipment for use outdoors (OJ 162, 3.7.2000, pp. 1-78) Successive amendments to Directive 2000/14/EC have been incorporated in the original text. This consolidated version is of documentary value only. RELATED DOCUMENTS Commission Recommendation of August 2003 concerning the guidelines on the revised interim computation methods for industrial noise, aircraft noise, road traffic noise and railway noise, and related emission data (OJ 212, 22.8.2003, pp. 49-64) Directive 2002/49/EC of the European Parliament and of the Council of 25 June 2002 relating to the assessment and management of environmental noise Declaration by the Commission in the Conciliation Committee on the Directive relating to the assessment and management of environmental noise (OJ 189, 18.7.2002, pp. 12-25) See consolidated version. last update 19.07.2018\\n\\n\\nGeräuschemissionen im Freien betriebener Geräte und Maschinen Geräuschemissionen im Freien betriebener Geräte und Maschinen ZUSAMMENFASSUNG DES DOKUMENTS: Richtlinie 2000/14/EG über umweltbelastende Geräuschemissionen von zur Verwendung im Freien vorgesehenen Geräten und Maschinen WAS IST DER ZWECK DIESER RICHTLINIE? Sie zielt darauf ab,die Kontrolle von Geräuschemissionen bei 57 im Freien verwendeten Gerätetypen (Artikel 12 und 13, Anhang I) zu verbessern, z.B.:Kompressoren,Ladebagger,Verschiedene Arten von Sägen,Mixer usw.; das reibungslose Funktionieren des EU-Binnenmarktes zu fördern; die Gesundheit und das Wohlbefinden der Bürger durch Verringerung der Geräuschemissionen von im Freien verwendeten Geräten zu verbessern. Mit dieser Richtlinie werden die neun bestehenden Rechtsvorschriften zu Geräuschemissionen für jeden Typ von Baumaschinen und Ausstattung sowie die Richtlinie 84/538/EEC für Rasenmäher aufgehoben und ersetzt. WICHTIGE ECKPUNKTE Die Richtlinie verfolgt vier Ziele:die Geräuschemissionen zu harmonisieren; die Konformitätsbewertung* zu harmonisieren Verfahren; Die Geräuschpegelmarkierung zu harmonisieren; Daten zu Geräuschemissionen zu sammeln. Folgende Typen von Geräten und Maschinen werden ausgeschlossen:nicht angetriebene Anbaugeräte (an Werkzeugen), die separat auf den Markt gebracht oder in Betrieb* genommen werden (außer für handbetätigte Betonbrecher und Spitzhacken); alle Geräte und Maschinen, die für den Gütertransport oder die Beförderung von Personen auf öffentlichen Straßen, Schienen, auf dem Luft- oder Wasserwege bestimmt sind; Geräte und Maschinen, die für polizeiliche oder militärische Zwecke konzipiert und gebaut werden. Die EU-Länder sind dafür verantwortlich, zu überprüfen, ob die in der Richtlinie festgelegten Regeln angewendet werden. Anhänge bis VIII enthalten die verschiedenen zu verwendenden Konformitätsbewertungsverfahren. Die Hersteller oder Personen, die ein Gerät oder eine Maschine auf den Markt bringen oder in Betrieb nehmen, müssen (Artikel und 8) sicherstellen, dass:sie für jede Maschine eine „EG-Konformitätserklärung“ ausstellen und bescheinigen, dass jedes Gerät oder Maschine mit der CE-Kennzeichnung der Richtlinie entspricht; an jedem Gerät/jeder Maschine eine gut sichtbare, lesbare und dauerhafte Kennzeichnung anbringen, die den garantierten Schalleistungspegel angibt. Der betreffende EU-Staat muss Maschinen und Geräte, die diesen Bedingungen nicht genügen, aus dem Verkehr ziehen bzw. ihre Inbetriebnahme verbieten. Die Kennzeichnung ist für alle von der Richtlinie erfassten Geräte obligatorisch und muss Folgendes enthalten:das gut sichtbar, lesbar und dauerhaft an jedem Gerät/jeder Maschine angebrachte CE-Zeichen und Details zum Schallleistungspegel LWA* in dB(A)* bezogen auf pW*. Die Geräuschemissionsgrenzwerte für bestimmte Geräte und Maschinen werden in zwei Stufen eingeführt, damit sich die Unternehmen an die neuen Vorschriften anpassen können. Die Emissionsgrenzwerte für Stufe wurden zwei Jahre nach Inkrafttreten der Richtlinie in rechtsgültig, und 2006 sind strengere Grenzwerte in Kraft getreten. Die EU-Länder können notifizierte Stellen einrichten, die für die Überwachung der für die Geräte und Maschinen geltenden Geräuschemissionsgrenzwerte zuständig sind. Die Geräte und Maschinen sind sowohl beim Entwurf als auch bei der Herstellung zu kontrollieren. Dagegen braucht die Bauart von solchen Geräten und Maschinen nicht überprüft zu werden, für die lediglich eine Kennzeichnung vorgeschrieben ist. Damit die Auswirkungen der Richtlinie überprüft werden können, wurden Daten über Geräuschemissionen erhoben. Diese Informationen dienen den Kunden als Grundlage für die Auswahl geräuschärmerer Geräte sowie für die Ausarbeitung wirtschaftlicher Anreize und Belohnungen. Hersteller oder ihre Bevollmächtigte müssen den zuständigen Behörden in den EU-Ländern sowie der Europäischen Kommission eine Kopie der EG-Konformitätserklärung für auf den Markt gebrachte Geräte und Maschinen übermitteln. Richtlinie hat 24 Artikel und 10 Anhänge, die Folgendes abdecken:Definitionen von Geräten und Maschinen; EG-Konformitätserklärung; Verfahren zur Ermittlung des Luftschalls, der von zur Verwendung im Freien vorgesehenen Geräten und Maschinen erzeugt wird; Muster der CE-Konformitätskennzeichnung und der Angabe des garantierten Schallleistungspegels; Interne Fertigungskontrolle; Interne Fertigungskontrolle mit Begutachtung der technischen Unterlagen und regelmäßiger Prüfung; Einzelprüfung; Umfassende Qualitätssicherung; Von den Mitgliedstaaten zu berücksichtigende Mindestkriterien für die Notifizierung der Stellen (die oben erwähnten notifizierten Stellen); Einzelprüfung Muster der Konformitätsbescheinigung. Mögliche Überarbeitungen der Rechtsvorschriften Seit Mai 2017 wird eine Evaluierungs- und Folgenabschätzungsstudie der Richtlinie 2000/14/EG durchgeführt. Deren Ergebnisse sowie die bereits abgeschlossenen Studien werden von der Kommission als Grundlage für die anstehende Überarbeitung der EU-Rechtsvorschriften in diesem Bereich verwendet. Eine öffentliche Anhörung wurde im Januar 2018 eingeleitet und verlief bis April 2018. WANN TRITT DIE RICHTLINIE IN KRAFT? Die Richtlinie ist am Donnerstag, 3. Januar 2002 in Kraft getreten und musste bis spätestens Dienstag, 3. Juli 2001 von den EU-Ländern in nationales Recht umgesetzt werden. HINTERGRUND Weiterführende Informationen:Geräuschemission von im Freien gebrauchten Maschinen und Geräten (Europäische Kommission). SCHLÜSSELBEGRIFFE Konformitätsbewertung: das Verfahren zur Bestätigung, dass spezifische Anforderungen an ein Produkt, ein Verfahren, eine Dienstleistung, ein System, eine Person oder eine Stelle erfüllt worden sind. Inbetriebnahme: der Zeitpunkt der ersten Verwendung durch den Endverbraucher für Zwecke, für die die Ware bestimmt war; LWA: Maß für die von einer Maschine abgegebene akustische Energie, d. h. die Schallleistung. dB(A): durchschnittlicher Schallpegel in Dezibel, wie er vom menschlichen Ohr wahrgenommen wird. pW: Pikowatt der internationale Standard-Referenzwert für die Schallleistung, wenn diese Menge in Dezibel ausgedrückt wird. HAUPTDOKUMENT Richtlinie 2000/14/EG des Europäischen Parlaments und des Rates vom 8. Mai 2000 zur Angleichung der Rechtsvorschriften der Mitgliedstaaten über umweltbelastende Geräuschemissionen von zur Verwendung im Freien vorgesehenen Geräten und Maschinen (ABl. 162 vom 3.7.2000, S. 1-78) Die nachfolgenden Änderungen der Richtlinie 2000/14/EG wurden in den Originaltext eingefügt. Diese konsolidierte Fassung hat ausschließlich dokumentarischen Charakter. VERBUNDENE DOKUMENTE Empfehlung der Kommission vom 6. August 2003 über Leitlinien für die geänderten vorläufigen Berechnungsmethoden für Industrie-, Flug-, Straßenverkehrs- und Eisenbahnlärm und diesbezügliche Emissionsdaten (ABI 212, 22.8.2003, S. 49-64) Richtlinie 2002/49/EG des Europäischen Parlaments und des Rates vom 25. Juni 2002 über die Bewertung und Bekämpfung von Umgebungslärm Erklärung der Kommission im Vermittlungsausschuss zur Richtlinie über die Bewertung und Bekämpfung von Umgebungslärm (ABI 189, 18.7.2002, S. 12-25) Siehe konsolidierte Fassung. Letzte Aktualisierung: 19.07.2018\\n\\n\\nNoise emission by equipment used outdoors.txt\\n\\n\\ndoc_2220\\n\\n\\nresearch_innovation environment internal_market consumers'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "oJTyalw5ulTp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# KMeans performed on the documents suggested that these classes should be togather in one cluster.\n",
        "cluster_1_info = ['agriculture',\n",
        " 'audiovisual_and_media',\n",
        " 'competition',\n",
        " 'consumers',\n",
        " 'employment_and_social_policy',\n",
        " 'energy',\n",
        " 'enterprise',\n",
        " 'environment',\n",
        " 'food_safety',\n",
        " 'information_society',\n",
        " 'internal_market',\n",
        " 'public_health',\n",
        " 'taxation',\n",
        " 'transport']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "47cpzbQMNeL1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# sliding window for creating sentences\n",
        "def slidingWindow(sequence,winSize,step):\n",
        "    \"\"\"Returns a generator that will iterate through\n",
        "    the defined chunks of input sequence. Input sequence\n",
        "    must be sliceable.\"\"\"\n",
        "\n",
        "    # Pre-compute number of chunks to emit\n",
        "    numOfChunks = ((len(sequence)-winSize)/step)+1\n",
        "    # Do the work\n",
        "    for i in range(0,round(numOfChunks)*step,step):\n",
        "        yield sequence[i:i+winSize]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Nf-PqYs8oSNy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# TRAIN DATA\n",
        "# dividing data with second sampling technique, the first one was already done where the duplicates from the \n",
        "# major class were removed, and if there were duplicates in the same class they were removed too.\n",
        "# we dont need the multiclass information of doc ids here so I will not bother about it here \n",
        "cluster_1_data = []\n",
        "cluster_1_label = []\n",
        "\n",
        "root_data = []\n",
        "root_label = []\n",
        "\n",
        "cluster_2_data = []\n",
        "cluster_2_label = []\n",
        "\n",
        "# for statistics\n",
        "count_cluster_1 =0\n",
        "count_cluster_2 =0\n",
        "count_root = 0\n",
        "\n",
        "# we will just divide the train data and labels\n",
        "\n",
        "for combined_doc, label in zip(train_data, train_la):\n",
        "    if label == 'content':\n",
        "        pass\n",
        "    elif label in cluster_1_info:\n",
        "        \"\"\"call the split function on the data\"\"\"\n",
        "        count_cluster_1 +=1\n",
        "        count_root +=1\n",
        "        cluster_1_data.append(combined_doc.split('\\n\\n\\n')[0])\n",
        "        cluster_1_data.append(combined_doc.split('\\n\\n\\n')[1])\n",
        "        cluster_1_label.append(label)\n",
        "        cluster_1_label.append(label)\n",
        "        \n",
        "        root_data.append(combined_doc.split('\\n\\n\\n')[0])\n",
        "        root_data.append(combined_doc.split('\\n\\n\\n')[1])\n",
        "        root_label.append(1)    # label for cluster 1 in the root classifier is 1\n",
        "        root_label.append(1)\n",
        "    elif label not in cluster_1_info:\n",
        "        count_cluster_2 +=1\n",
        "        count_root+=1\n",
        "        cluster_2_data.append(combined_doc.split('\\n\\n\\n')[0])\n",
        "        cluster_2_data.append(combined_doc.split('\\n\\n\\n')[1])\n",
        "        cluster_2_label.append(label)\n",
        "        cluster_2_label.append(label)\n",
        "        \n",
        "        root_data.append(combined_doc.split('\\n\\n\\n')[0])\n",
        "        root_data.append(combined_doc.split('\\n\\n\\n')[1])\n",
        "        root_label.append(2)    # label for cluster 2 in root classifier is 2 \n",
        "        root_label.append(2)\n",
        "    else:\n",
        "        print('Something is wrong')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pM9HlQnrpOev",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# TEST DATA\n",
        "cluster_1_data_test = []\n",
        "cluster_1_doc_id_test = []\n",
        "cluster_1_label_test = []\n",
        "cluster_1_multilabel_test = []\n",
        "cluster_1_file_name_test = []\n",
        "\n",
        "\n",
        "root_test_data = []\n",
        "root_test_label = []\n",
        "root_test_doc_id = []\n",
        "root_test_file_name = []\n",
        "root_test_multilabel = []\n",
        "\n",
        "cluster_2_data_test = []\n",
        "cluster_2_doc_id_test = []\n",
        "cluster_2_label_test = []\n",
        "cluster_2_multilabel_test = []\n",
        "cluster_2_file_name_test = []\n",
        "\n",
        "# for statistics\n",
        "count_cluster_1_test = 0\n",
        "count_cluster_2_test = 0\n",
        "count_root_test = 0\n",
        "# we will just divide the train data and labels\n",
        "\n",
        "for combine_doc, label in zip(test_data, test_la):\n",
        "    if label == 'content':\n",
        "        pass\n",
        "    elif label in cluster_1_info:\n",
        "        count_cluster_1_test +=1\n",
        "        count_root_test +=1\n",
        "        cluster_1_data_test.append(combine_doc.split('\\n\\n\\n')[0])\n",
        "        cluster_1_data_test.append(combine_doc.split('\\n\\n\\n')[1])\n",
        "        cluster_1_label_test.append(label)\n",
        "        \n",
        "        cluster_1_multilabel_test.append(combine_doc.split('\\n\\n\\n')[4])\n",
        "        cluster_1_doc_id_test.append(combine_doc.split('\\n\\n\\n')[3])\n",
        "        cluster_1_file_name_test.append(combine_doc.split('\\n\\n\\n')[2])\n",
        "        cluster_1_label_test.append(label)\n",
        "        \n",
        "        cluster_1_multilabel_test.append(combine_doc.split('\\n\\n\\n')[4])\n",
        "        cluster_1_doc_id_test.append(combine_doc.split('\\n\\n\\n')[3])\n",
        "        cluster_1_file_name_test.append(combine_doc.split('\\n\\n\\n')[2])\n",
        "        \n",
        "        root_test_data.append(combine_doc.split('\\n\\n\\n')[0])\n",
        "        root_test_data.append(combine_doc.split('\\n\\n\\n')[1])\n",
        "        root_test_label.append(1)\n",
        "        root_test_doc_id.append(combine_doc.split('\\n\\n\\n')[3])\n",
        "        root_test_file_name.append(combine_doc.split('\\n\\n\\n')[2])\n",
        "        root_test_multilabel.append(combine_doc.split('\\n\\n\\n')[4])\n",
        "        root_test_label.append(1)\n",
        "        root_test_doc_id.append(combine_doc.split('\\n\\n\\n')[3])\n",
        "        root_test_file_name.append(combine_doc.split('\\n\\n\\n')[2])\n",
        "        root_test_multilabel.append(combine_doc.split('\\n\\n\\n')[4])\n",
        "        \n",
        "    elif label not in cluster_1_info:\n",
        "        count_cluster_2_test +=1\n",
        "        count_root_test +=1\n",
        "        cluster_2_data_test.append(combine_doc.split('\\n\\n\\n')[0])\n",
        "        cluster_2_data_test.append(combine_doc.split('\\n\\n\\n')[1])\n",
        "        cluster_2_label_test.append(label)\n",
        "        cluster_2_multilabel_test.append(combine_doc.split('\\n\\n\\n')[4])\n",
        "        cluster_2_doc_id_test.append(combine_doc.split('\\n\\n\\n')[3])\n",
        "        cluster_2_file_name_test.append(combine_doc.split('\\n\\n\\n')[2])\n",
        "        cluster_2_label_test.append(label)\n",
        "        cluster_2_multilabel_test.append(combine_doc.split('\\n\\n\\n')[4])\n",
        "        cluster_2_doc_id_test.append(combine_doc.split('\\n\\n\\n')[3])\n",
        "        cluster_2_file_name_test.append(combine_doc.split('\\n\\n\\n')[2])\n",
        "        \n",
        "        root_test_data.append(combine_doc.split('\\n\\n\\n')[0])\n",
        "        root_test_data.append(combine_doc.split('\\n\\n\\n')[1])\n",
        "        root_test_label.append(2)\n",
        "        root_test_doc_id.append(combine_doc.split('\\n\\n\\n')[3])\n",
        "        root_test_file_name.append(combine_doc.split('\\n\\n\\n')[2])\n",
        "        root_test_multilabel.append(combine_doc.split('\\n\\n\\n')[4])\n",
        "        root_test_label.append(2)\n",
        "        root_test_doc_id.append(combine_doc.split('\\n\\n\\n')[3])\n",
        "        root_test_file_name.append(combine_doc.split('\\n\\n\\n')[2])\n",
        "        root_test_multilabel.append(combine_doc.split('\\n\\n\\n')[4])\n",
        "    else:\n",
        "        print('Something Wrong')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jk0PhKbOpmlW",
        "colab_type": "code",
        "outputId": "c655cf09-2a9e-4082-9ecc-91aaf9186d28",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "cell_type": "code",
      "source": [
        "# Train statistics\n",
        "print(\"Total docs in cluster 1 train are: {}\".format(len(cluster_1_data)))\n",
        "print(\"Total docs in cluster 2 train are: {}\".format(len(cluster_2_data)))\n",
        "print(\"Total docs in root_classifier train are: {}\".format(len(root_data)))\n",
        "\n",
        "# test statistics\n",
        "print(\"Total docs in cluster 1 test are: {}\".format(len(cluster_1_data_test)))\n",
        "print(\"Total docs in cluster 2 test are: {}\".format(len(cluster_2_data_test)))\n",
        "print(\"Total docs in root test are: {}\".format(len(root_test_data)))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total docs in cluster 1 train are: 1984\n",
            "Total docs in cluster 2 train are: 1796\n",
            "Total docs in root_classifier train are: 3780\n",
            "Total docs in cluster 1 test are: 874\n",
            "Total docs in cluster 2 test are: 748\n",
            "Total docs in root test are: 1622\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ifP-d5V936hz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Cluster 1 "
      ]
    },
    {
      "metadata": {
        "id": "Mqdw4S08Gixl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Assiginig numbers to labels"
      ]
    },
    {
      "metadata": {
        "id": "rgeYCckJ36u1",
        "colab_type": "code",
        "outputId": "9f328e6b-8182-42fc-b380-20be28605a58",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "cell_type": "code",
      "source": [
        "# Assigning numbers to labels of cluster 1 and 2\n",
        "num_label_cluster_1 = dict(list(enumerate(sorted(set(cluster_1_label)))))\n",
        "num_label_cluster_1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'agriculture',\n",
              " 1: 'audiovisual_and_media',\n",
              " 2: 'competition',\n",
              " 3: 'consumers',\n",
              " 4: 'employment_and_social_policy',\n",
              " 5: 'energy',\n",
              " 6: 'enterprise',\n",
              " 7: 'environment',\n",
              " 8: 'food_safety',\n",
              " 9: 'information_society',\n",
              " 10: 'internal_market',\n",
              " 11: 'public_health',\n",
              " 12: 'taxation',\n",
              " 13: 'transport'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "metadata": {
        "id": "XKu-R8NUGonO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Train sentence preparation"
      ]
    },
    {
      "metadata": {
        "id": "jx-tyGFwppHx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Cluster 1 train data, sentence conversion\n",
        "cluster_1_sent_train = []  # List to store the sentence\n",
        "cluster_1_labels_train = [] # List to store the label(alpha)\n",
        "cluster_1_label_num_train = []\n",
        "\n",
        "\n",
        "for first_data, first_label in zip(cluster_1_data,cluster_1_label):\n",
        "    # start chunking the text into 30 words with 10 word slide\n",
        "    slides = slidingWindow(first_data.split(' '),30,10)\n",
        "        \n",
        "    for key,value in num_label_cluster_1.items():\n",
        "        if value == first_label:\n",
        "            num = key\n",
        "    \n",
        "    \n",
        "    for slide in slides:\n",
        "        cluster_1_sent_train.append(' '.join(slide).lower())\n",
        "        cluster_1_labels_train.append(first_label)\n",
        "        cluster_1_label_num_train.append(num)\n",
        "\n",
        "        \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6Z8LX0RgbVE4",
        "colab_type": "code",
        "outputId": "98c4df48-2c6b-42d5-ba4c-be9c50becc71",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "len(cluster_1_sent_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "152009"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "metadata": {
        "id": "wtbKz_bJMA7E",
        "colab_type": "code",
        "outputId": "da26ea91-119a-4dd5-be18-73a4a5007c96",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "Counter(cluster_1_labels_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({'agriculture': 11555,\n",
              "         'audiovisual_and_media': 1762,\n",
              "         'competition': 4603,\n",
              "         'consumers': 10645,\n",
              "         'employment_and_social_policy': 19901,\n",
              "         'energy': 8486,\n",
              "         'enterprise': 5827,\n",
              "         'environment': 14746,\n",
              "         'food_safety': 11966,\n",
              "         'information_society': 19026,\n",
              "         'internal_market': 21260,\n",
              "         'public_health': 4971,\n",
              "         'taxation': 4622,\n",
              "         'transport': 12639})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "metadata": {
        "id": "4D0dmQ9CMBBd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class_weights_cls1 = dict()\n",
        "\n",
        "max_value = max(Counter(cluster_1_labels_train).values())\n",
        "\n",
        "for keys, values in Counter(cluster_1_labels_train).items():\n",
        "    for _keys, _values in num_label_cluster_1.items():\n",
        "        if keys == _values:\n",
        "            class_weights_cls1[_keys] = (max_value/ values)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sVjoYlVoMBAP",
        "colab_type": "code",
        "outputId": "4ef84ebe-398e-4985-f741-2e7cb3bea2fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "cell_type": "code",
      "source": [
        "class_weights_cls1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 1.8398961488533103,\n",
              " 1: 12.06583427922815,\n",
              " 2: 4.618726917227895,\n",
              " 3: 1.9971817754814467,\n",
              " 4: 1.0682880257273504,\n",
              " 5: 2.5053028517558333,\n",
              " 6: 3.648532692637721,\n",
              " 7: 1.441746914417469,\n",
              " 8: 1.7767006518468995,\n",
              " 9: 1.1174182697361505,\n",
              " 10: 1.0,\n",
              " 11: 4.276805471736069,\n",
              " 12: 4.599740372133276,\n",
              " 13: 1.6820951024606376}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "metadata": {
        "id": "-VDkrW7GGvVL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### One hot encoding train and test labels"
      ]
    },
    {
      "metadata": {
        "id": "vwd7rxfUGuo4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Define one_hot_encoder object\n",
        "onehot_encoder = OneHotEncoder(sparse=False)\n",
        "\n",
        "cluster_1_train_label = onehot_encoder.fit_transform(np.reshape(cluster_1_label_num_train,(-1,1)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AzfXxSCNG4HR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Tokenizing train sentences"
      ]
    },
    {
      "metadata": {
        "id": "bczn-grnG4kc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(num_words=50000)\n",
        "tokenizer.fit_on_texts(cluster_1_data)\n",
        "cluster_1_train_sequences = tokenizer.texts_to_sequences(cluster_1_sent_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vvx8HVlOG6kh",
        "colab_type": "code",
        "outputId": "6c09f975-8f36-4e59-c399-cdb177f32ece",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "word_index = tokenizer.word_index\n",
        "vocab_size = len(word_index)+1\n",
        "max_len = 30\n",
        "print('max_length is', max_len)\n",
        "cluster_1_padded_sents = keras.preprocessing.sequence.pad_sequences(cluster_1_train_sequences, maxlen=max_len, padding='post')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "max_length is 30\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0UP3ffY6G-RM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Embedding Matrix creation"
      ]
    },
    {
      "metadata": {
        "id": "FmheThMpG8V9",
        "colab_type": "code",
        "outputId": "cac514a5-3da6-4e27-b71f-108d8a98fef5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "# converting embedding matrix into a form that can be used in keras embedding layer\n",
        "embeddings_index = {}\n",
        "# with open(embding_path, 'r') as embpath:\n",
        "#     pretrained_embeding = embpath.readlines()\n",
        "    \n",
        "for i, line in enumerate(en_de):\n",
        "    if i == 0:\n",
        "        pass\n",
        "    else:\n",
        "        try:\n",
        "            values = line.split()\n",
        "            word = values[0]\n",
        "            coefs = np.asarray(values[1:], dtype='float32')\n",
        "            embeddings_index[word] = coefs\n",
        "        except ValueError:\n",
        "            print('Value error: {}'.format(values[1:5]))\n",
        "\n",
        "embedding_matrix = np.zeros((len(word_index) + 1, 300))\n",
        "for word, i in word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        # words not found in embedding index will be all-zeros.\n",
        "        embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Value error: ['·', '-0.116043', '-0.0278416', '0.0375914']\n",
            "Value error: ['—', '-0.000894651', '0.0377289', '-0.0714999']\n",
            "Value error: ['gebäude', '-0.0360703', '-0.0850809', '-0.0597942']\n",
            "Value error: ['waldfläche', '-0.0314779', '-0.0465583', '-0.0163933']\n",
            "Value error: ['verkehrsfläche', '-0.0356581', '-0.0029205', '0.0181392']\n",
            "Value error: ['erholungsfläche', '-0.0368387', '-0.0377135', '0.00746337']\n",
            "Value error: ['landwirtschaftsfläche', '-0.0263421', '-0.046624', '-0.0177181']\n",
            "Value error: ['sonstige_flächen', '-0.0559894', '-0.0219282', '-0.000380597']\n",
            "Value error: ['gesamtfläche', '-0.0660608', '-0.0324034', '0.0221355']\n",
            "Value error: ['wasserfläche', '-0.0588425', '-0.0477398', '-0.0339936']\n",
            "Value error: ['•', '-0.0626246', '-0.0190532', '-0.0432283']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "tCdLGiPM0UYL",
        "colab_type": "code",
        "outputId": "8ecf3b19-890d-4d93-ec69-7f967d9b8ce5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "print('shape embedding matrix: {}'.format(embedding_matrix.shape))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shape embedding matrix: (53487, 300)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "IMJwatXBCp1I",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### One Hot Encoding Labels\n",
        "\n",
        "The numerical labels needs to be converted into its one hot encoded form."
      ]
    },
    {
      "metadata": {
        "id": "MNegok1-HTY5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Callbacks\n"
      ]
    },
    {
      "metadata": {
        "id": "Is61FoE5HAeo",
        "colab_type": "code",
        "outputId": "bb592b6f-78d2-44ac-c930-5dac69ba89ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "# Other callbacks \n",
        "reduce_rate = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=0, verbose=1, \n",
        "                                                mode='auto', epsilon=0.0001, cooldown=0, min_lr=0)\n",
        "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, \n",
        "                                           patience=2, verbose=1, mode='auto')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/callbacks.py:1065: UserWarning: `epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
            "  warnings.warn('`epsilon` argument is deprecated and '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "07UMP2sQ4j62",
        "colab_type": "code",
        "outputId": "a3963d72-a387-479f-feb1-4a9200807a7a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        }
      },
      "cell_type": "code",
      "source": [
        "learning_rate = 0.001\n",
        "optimizer = keras.optimizers.RMSprop(lr=learning_rate, rho=0.9, epsilon=None, decay=0.0)\n",
        "#optimizer = keras.optimizers.Adam(lr=learning_rate, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "J4RzVNho_7dD",
        "colab_type": "code",
        "outputId": "59952326-1e7a-4be9-c571-cefbc2627cbe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "cell_type": "code",
      "source": [
        "# Cluster 1 test data, sentence conversion\n",
        "cluster_1_sent_test = []  # List to store the sentence\n",
        "cluster_1_labels_test = [] # List to store the label(alpha)\n",
        "cluster_1_label_num_test = []\n",
        "\n",
        "\n",
        "for first_data, first_label in zip(cluster_1_data_test, cluster_1_label_test):\n",
        "    # start chunking the text into 30 words with 10 word slide\n",
        "    slides = slidingWindow(first_data.split(' '),30,10)\n",
        "        \n",
        "    for key,value in num_label_cluster_1.items():\n",
        "        if value == first_label:\n",
        "            num = key\n",
        "    \n",
        "    \n",
        "    for slide in slides:\n",
        "        cluster_1_sent_test.append(' '.join(slide).lower())\n",
        "        cluster_1_labels_test.append(first_label)\n",
        "        cluster_1_label_num_test.append(num)\n",
        "\n",
        "cluster_1_test_label = onehot_encoder.fit_transform(np.reshape(cluster_1_label_num_test,(-1,1)))\n",
        "cluster_1_test_sequences = tokenizer.texts_to_sequences(cluster_1_sent_test)\n",
        "# Testing the data\n",
        "cluster_1_padded_sents_test = keras.preprocessing.sequence.pad_sequences(cluster_1_test_sequences, maxlen=max_len, padding='post')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
            "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
            "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "EPTWgxMHHbGM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Training"
      ]
    },
    {
      "metadata": {
        "id": "0pHqyBnrHaBy",
        "colab_type": "code",
        "outputId": "a82c7251-a6e1-4a01-8dd6-053fb87e8aac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 734
        }
      },
      "cell_type": "code",
      "source": [
        "# Create sequential model\n",
        "model = Sequential()\n",
        "model.add(emb(vocab_size, 300, weights=[embedding_matrix], input_length=30, trainable=False))   \n",
        "model.add(Bidirectional(LSTM(40, activation='tanh',return_sequences=True, kernel_regularizer=keras.regularizers.l2(0.04))))# LSTM layer \n",
        "model.add(keras.layers.Dropout(0.5))\n",
        "model.add(Bidirectional(LSTM(40, activation='tanh',return_sequences=False, kernel_regularizer=keras.regularizers.l2(0.01))))\n",
        "model.add(keras.layers.Dropout(0.5))\n",
        "model.add(Dense(14, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer= optimizer, metrics=['accuracy'])\n",
        "print(model.summary())\n",
        "model.fit(cluster_1_padded_sents, cluster_1_train_label, validation_data=(cluster_1_padded_sents_test,cluster_1_test_label), epochs=20, batch_size=32, \n",
        "          verbose=1, callbacks=[reduce_rate,early_stop])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 30, 300)           16046100  \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 30, 80)            109120    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 30, 80)            0         \n",
            "_________________________________________________________________\n",
            "bidirectional_2 (Bidirection (None, 80)                38720     \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 80)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 14)                1134      \n",
            "=================================================================\n",
            "Total params: 16,195,074\n",
            "Trainable params: 148,974\n",
            "Non-trainable params: 16,046,100\n",
            "_________________________________________________________________\n",
            "None\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train on 152009 samples, validate on 59256 samples\n",
            "Epoch 1/20\n",
            "152009/152009 [==============================] - 481s 3ms/step - loss: 2.5915 - acc: 0.1361 - val_loss: 2.4886 - val_acc: 0.1694\n",
            "Epoch 2/20\n",
            "152009/152009 [==============================] - 474s 3ms/step - loss: 2.4823 - acc: 0.1384 - val_loss: 2.4852 - val_acc: 0.1694\n",
            "Epoch 3/20\n",
            "152009/152009 [==============================] - 472s 3ms/step - loss: 2.4815 - acc: 0.1390 - val_loss: 2.4909 - val_acc: 0.1077\n",
            "\n",
            "Epoch 00003: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "Epoch 4/20\n",
            "152009/152009 [==============================] - 473s 3ms/step - loss: 2.4793 - acc: 0.1393 - val_loss: 2.4875 - val_acc: 0.1694\n",
            "\n",
            "Epoch 00004: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "Epoch 00004: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f26bc105e80>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "metadata": {
        "id": "ApFDb0nU3baR",
        "colab_type": "code",
        "outputId": "b1edd708-51a0-4423-e399-59f066bf968d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "model.evaluate(cluster_1_padded_sents_test, cluster_1_test_label)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "59256/59256 [==============================] - 50s 846us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2.487479957182977, 0.16940056703118672]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "metadata": {
        "id": "PKDB_PCQprMM",
        "colab_type": "code",
        "outputId": "b01daabd-91d5-4b8f-d32c-118aedcd8f61",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "cluster_1_padded_sents_test[0].shape, cluster_1_test_label[0].shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((30,), (14,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "metadata": {
        "id": "4kfJ56HSAMgX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Test Data Preparation\n"
      ]
    },
    {
      "metadata": {
        "id": "1i5UgxsFAHlD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Cluster 1 test data, sentence conversion\n",
        "from sklearn.preprocessing import MinMaxScaler, Normalizer, StandardScaler\n",
        "\n",
        "doc_id_pred = []\n",
        "file_name_pred = []\n",
        "multi_label_pred = []\n",
        "pred_one_hot_encoded = []\n",
        "label_one_hot_encoded = []\n",
        "prd_for_doc = []\n",
        "\n",
        "original_label = []\n",
        "predicted_label = []\n",
        "\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "from collections import Counter \n",
        "\n",
        "\n",
        "counter = 0\n",
        "for first_data, first_label, _doc_id, _multi, _file_name in zip(cluster_1_data_test, cluster_1_label_test, \n",
        "                                   cluster_1_doc_id_test,cluster_1_multilabel_test,\n",
        "                                   cluster_1_file_name_test ):\n",
        "    \n",
        "    ## TMP LIST for each doc\n",
        "    sent_pred = []\n",
        "    \n",
        "    # start chunking the text into 30 words with 10 word slide\n",
        "    slides = slidingWindow(first_data.split(' '),30,10)\n",
        "        \n",
        "    for key,value in num_label_cluster_1.items():\n",
        "        if value == first_label:\n",
        "            num = key\n",
        "    \n",
        "    doc_sent = []\n",
        "    for slide in slides:\n",
        "        \n",
        "        a = ' '.join(slide).lower()\n",
        "        \n",
        "        doc_sent.append(a)\n",
        "        \n",
        "    # we have the slide here, create the sequence from text to numbers\n",
        "    text_sequence = tokenizer.texts_to_sequences(doc_sent)\n",
        "#     print(text_sequence)\n",
        "#     sys.exit()\n",
        "\n",
        "    # pad it to make flat 30 lenght\n",
        "    text_padded = keras.preprocessing.sequence.pad_sequences(text_sequence, maxlen=30, padding='post')\n",
        "\n",
        "    # Convert the label for this into one hot encoding\n",
        "    label_one_hot = onehot_encoder.fit_transform(np.reshape(num,(1,-1)))\n",
        "\n",
        "    # predict the label\n",
        "    sent_pred.append(model.predict(text_padded))        \n",
        "    \n",
        "\n",
        "     #after predicting everything for every slide\n",
        "    # take the argmax on the document \n",
        "#     doc_predictions = []\n",
        "#     for i in sent_pred: \n",
        "#         doc_predictions.append(np.argmax(i,axis=1))\n",
        "    nor_data = []\n",
        "    for predc in sent_pred:\n",
        "        transformer2 = Normalizer().fit(predc)\n",
        "        nor_data.append(transformer2.transform(predc))    \n",
        "        \n",
        "    sent = np.zeros(14)\n",
        "    for sen in nor_data:\n",
        "        for i in range(len(sen)):\n",
        "            sent += sen[i]\n",
        "    \n",
        "    predicted_label.append(np.argmax(sent, axis=0))\n",
        "    original_label.append(num)\n",
        "    \n",
        "    \n",
        "    \n",
        "#     pre_for_doc = []\n",
        "#     # count the max number of instances \n",
        "#     for sentence_pred in doc_predictions:\n",
        "#         pre_for_doc.append(Counter(sentence_pred).most_common(1)[0][0])\n",
        "   \n",
        "#     prd_for_doc.append(Counter(pre_for_doc).most_common(1)[0][0])\n",
        "  \n",
        "    # for counting precision recall and fscore\n",
        "    label_one_hot_encoded.append(num)\n",
        "    doc_id_pred.append(_doc_id)\n",
        "    file_name_pred.append(_file_name)\n",
        "    multi_label_pred.append(_multi)\n",
        "#     counter+=1\n",
        "#     if counter == 2:\n",
        "#         sys.exit()\n",
        "    \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "#         cluster_1_sent_test.append(' '.join(slide))\n",
        "#         cluster_1_labels_test.append(first_label)\n",
        "#         cluster_1_label_num_test.append(num)\n",
        "#         cluster_1_sent_file_name_test.append(_file_name)\n",
        "#         cluster_1_sent_doc_id_test.append(_doc_id)\n",
        "#         cluster_1_sent_multilabel_test.append(_multi)\n",
        "        \n",
        "        \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RKYSghbgHcsn",
        "colab_type": "code",
        "outputId": "fc8a8617-0e76-4dde-cb64-83f9923fbd4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "accuracy_score(original_label, predicted_label)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.18309859154929578"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "metadata": {
        "id": "3TVNFRX7J_wz",
        "colab_type": "code",
        "outputId": "f0f81a6c-36c3-4dc8-87d8-d1db61f8eccf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "cell_type": "code",
      "source": [
        "Counter(original_label)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({0: 64,\n",
              "         1: 12,\n",
              "         2: 28,\n",
              "         3: 74,\n",
              "         4: 96,\n",
              "         5: 36,\n",
              "         6: 32,\n",
              "         7: 70,\n",
              "         8: 54,\n",
              "         9: 82,\n",
              "         10: 156,\n",
              "         11: 36,\n",
              "         12: 22,\n",
              "         13: 90})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "metadata": {
        "id": "IN5dJzbgHC8L",
        "colab_type": "code",
        "outputId": "d229443e-3e3a-41b8-9818-0ca23d1081e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        }
      },
      "cell_type": "code",
      "source": [
        "confusion_matrix(original_label, predicted_label)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  64,   0,   0,\n",
              "          0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  12,   0,   0,\n",
              "          0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  28,   0,   0,\n",
              "          0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  74,   0,   0,\n",
              "          0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  96,   0,   0,\n",
              "          0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  36,   0,   0,\n",
              "          0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  32,   0,   0,\n",
              "          0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  70,   0,   0,\n",
              "          0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  54,   0,   0,\n",
              "          0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  82,   0,   0,\n",
              "          0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 156,   0,   0,\n",
              "          0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  36,   0,   0,\n",
              "          0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  22,   0,   0,\n",
              "          0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  90,   0,   0,\n",
              "          0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "metadata": {
        "id": "ppjTeB_oGm7i",
        "colab_type": "code",
        "outputId": "da269b43-c29c-4ae4-ae84-e221fa0d638a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        }
      },
      "cell_type": "code",
      "source": [
        "print(classification_report(original_label, predicted_label))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        64\n",
            "           1       0.00      0.00      0.00        12\n",
            "           2       0.00      0.00      0.00        28\n",
            "           3       0.00      0.00      0.00        74\n",
            "           4       0.00      0.00      0.00        96\n",
            "           5       0.00      0.00      0.00        36\n",
            "           6       0.00      0.00      0.00        32\n",
            "           7       0.00      0.00      0.00        70\n",
            "           8       0.00      0.00      0.00        54\n",
            "           9       0.00      0.00      0.00        82\n",
            "          10       0.18      1.00      0.31       156\n",
            "          11       0.00      0.00      0.00        36\n",
            "          12       0.00      0.00      0.00        22\n",
            "          13       0.00      0.00      0.00        90\n",
            "\n",
            "   micro avg       0.18      0.18      0.18       852\n",
            "   macro avg       0.01      0.07      0.02       852\n",
            "weighted avg       0.03      0.18      0.06       852\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "2knH3IVOH6hy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Evaluation"
      ]
    },
    {
      "metadata": {
        "id": "3k3VzYoQH53h",
        "colab_type": "code",
        "outputId": "049e3a4e-de5b-4005-8f3e-052368295f7c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1271
        }
      },
      "cell_type": "code",
      "source": [
        "scores = model.evaluate(cluster_1_padded_sents_test, cluster_1_test_label, verbose=1)\n",
        "print(\"Accuracy: %.2f%%\" % (scores[1]*100))\n",
        "# Classification Report (Precision, Recall and F1-Score)\n",
        "\n",
        "\n",
        "y_true = np.argmax(cluster_1_test_label, axis=1)\n",
        "y_pred = np.argmax(model.predict(cluster_1_padded_sents_test),axis=1)\n",
        "classificationReport = classification_report(y_true, y_pred)\n",
        "\n",
        "print(classificationReport)\n",
        "\n",
        "conf = confusion_matrix(y_true, y_pred)\n",
        "seaborn.heatmap(conf)\n",
        "print(confusion_matrix(y_true, y_pred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "59256/59256 [==============================] - 52s 876us/step\n",
            "Accuracy: 16.94%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00      6522\n",
            "           1       0.00      0.00      0.00       994\n",
            "           2       0.00      0.00      0.00      1844\n",
            "           3       0.00      0.00      0.00      4730\n",
            "           4       0.00      0.00      0.00      6381\n",
            "           5       0.00      0.00      0.00      2388\n",
            "           6       0.00      0.00      0.00      2256\n",
            "           7       0.00      0.00      0.00      4429\n",
            "           8       0.00      0.00      0.00      3203\n",
            "           9       0.00      0.00      0.00      6956\n",
            "          10       0.17      1.00      0.29     10038\n",
            "          11       0.00      0.00      0.00      2319\n",
            "          12       0.00      0.00      0.00      1339\n",
            "          13       0.00      0.00      0.00      5857\n",
            "\n",
            "   micro avg       0.17      0.17      0.17     59256\n",
            "   macro avg       0.01      0.07      0.02     59256\n",
            "weighted avg       0.03      0.17      0.05     59256\n",
            "\n",
            "[[    0     0     0     0     0     0     0     0     0     0  6522     0\n",
            "      0     0]\n",
            " [    0     0     0     0     0     0     0     0     0     0   994     0\n",
            "      0     0]\n",
            " [    0     0     0     0     0     0     0     0     0     0  1844     0\n",
            "      0     0]\n",
            " [    0     0     0     0     0     0     0     0     0     0  4730     0\n",
            "      0     0]\n",
            " [    0     0     0     0     0     0     0     0     0     0  6381     0\n",
            "      0     0]\n",
            " [    0     0     0     0     0     0     0     0     0     0  2388     0\n",
            "      0     0]\n",
            " [    0     0     0     0     0     0     0     0     0     0  2256     0\n",
            "      0     0]\n",
            " [    0     0     0     0     0     0     0     0     0     0  4429     0\n",
            "      0     0]\n",
            " [    0     0     0     0     0     0     0     0     0     0  3203     0\n",
            "      0     0]\n",
            " [    0     0     0     0     0     0     0     0     0     0  6956     0\n",
            "      0     0]\n",
            " [    0     0     0     0     0     0     0     0     0     0 10038     0\n",
            "      0     0]\n",
            " [    0     0     0     0     0     0     0     0     0     0  2319     0\n",
            "      0     0]\n",
            " [    0     0     0     0     0     0     0     0     0     0  1339     0\n",
            "      0     0]\n",
            " [    0     0     0     0     0     0     0     0     0     0  5857     0\n",
            "      0     0]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcwAAAFNCAYAAACNN1/7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 576x396 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "KAXATl5DLuNm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Cluster 2"
      ]
    },
    {
      "metadata": {
        "id": "pcJJw8T-L4D4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Assigning numbers to labels"
      ]
    },
    {
      "metadata": {
        "id": "JvgXk-4hHZOB",
        "colab_type": "code",
        "outputId": "35970dbc-1c7b-47c9-8449-36361a36c4f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        }
      },
      "cell_type": "code",
      "source": [
        "num_label_cluster_2 = dict(list(enumerate(sorted(set(cluster_2_label)))))\n",
        "num_label_cluster_2\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'budget',\n",
              " 1: 'culture',\n",
              " 2: 'customs',\n",
              " 3: 'development',\n",
              " 4: 'economic_and_monetary_affairs',\n",
              " 5: 'education_training_youth',\n",
              " 6: 'enlargement',\n",
              " 7: 'external_relations',\n",
              " 8: 'external_trade',\n",
              " 9: 'fight_against_fraud',\n",
              " 10: 'foreign_and_security_policy',\n",
              " 11: 'human_rights',\n",
              " 12: 'humanitarian_aid',\n",
              " 13: 'institutional_affairs',\n",
              " 14: 'justice_freedom_security',\n",
              " 15: 'maritime_affairs_and_fisheries',\n",
              " 16: 'regional_policy',\n",
              " 17: 'research_innovation'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "metadata": {
        "id": "GEckdQiwMGah",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Tain sentence preparation"
      ]
    },
    {
      "metadata": {
        "id": "JkpvvKX1MDEF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Cluster 2 train data, sentence conversion\n",
        "cluster_2_sent_train = []  # List to store the sentence\n",
        "cluster_2_labels_train = [] # List to store the label(alpha)\n",
        "cluster_2_label_num_train = []\n",
        "\n",
        "\n",
        "for second_data, second_label in zip(cluster_2_data, cluster_2_label):\n",
        "    # start chunking the text into 30 words with 10 word slide\n",
        "    slides = slidingWindow(second_data.split(' '),30,10)\n",
        "        \n",
        "    for key,value in num_label_cluster_2.items():\n",
        "        if value == second_label:\n",
        "            num = key\n",
        "    \n",
        "    \n",
        "    for slide in slides:\n",
        "        cluster_2_sent_train.append(' '.join(slide).lower())\n",
        "        cluster_2_labels_train.append(second_label)\n",
        "        cluster_2_label_num_train.append(num)\n",
        "        \n",
        "# Cluster 2 test data        \n",
        "cluster_2_sent_test = []  # List to store the sentence\n",
        "cluster_2_labels_test = [] # List to store the label(alpha)\n",
        "cluster_2_label_num_test = []\n",
        "\n",
        "\n",
        "for second_data, second_label in zip(cluster_2_data_test, cluster_2_label_test):\n",
        "    # start chunking the text into 30 words with 10 word slide\n",
        "    slides = slidingWindow(second_data.split(' '),30,10)\n",
        "        \n",
        "    for key,value in num_label_cluster_2.items():\n",
        "        if value == second_label:\n",
        "            num = key\n",
        "    \n",
        "    \n",
        "    for slide in slides:\n",
        "        cluster_2_sent_test.append(' '.join(slide).lower())\n",
        "        cluster_2_labels_test.append(second_label)\n",
        "        cluster_2_label_num_test.append(num)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lOCPUGsAMNVD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Tokenizing train sentences & one hot encoding train test labels"
      ]
    },
    {
      "metadata": {
        "id": "9iY3p8HjMIgM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "outputId": "e5dab6af-7b37-46a6-e18d-c786790708d4"
      },
      "cell_type": "code",
      "source": [
        "# tokenizing cluster 2 sents\n",
        "tokenizer_cls2 = Tokenizer()\n",
        "tokenizer_cls2.fit_on_texts(cluster_2_data)\n",
        "cluster_2_train_sequences = tokenizer_cls2.texts_to_sequences(cluster_2_sent_train)\n",
        "cluster_2_test_sequences = tokenizer_cls2.texts_to_sequences(cluster_2_sent_test)\n",
        "\n",
        "# padding the sentences\n",
        "cluster_2_padded_sents = keras.preprocessing.sequence.pad_sequences(cluster_2_train_sequences, maxlen=30, padding='post')\n",
        "\n",
        "# checking vocab size\n",
        "word_index_cls2 = tokenizer_cls2.word_index\n",
        "vocab_size_cls2 = len(word_index_cls2)+1\n",
        "onehot_encoder = OneHotEncoder(sparse=False)\n",
        "\n",
        "onehot_encoder.fit(np.reshape(cluster_2_label_num_train,(-1,1)))\n",
        "\n",
        "cluster_2_train_label = onehot_encoder.transform(np.reshape(cluster_2_label_num_train,(-1,1)))\n",
        "cluster_2_test_label = onehot_encoder.transform(np.reshape(cluster_2_label_num_test,(-1,1)))\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
            "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
            "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "ZcnGRNjB9Nj-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cluster_2_padded_sents_test = keras.preprocessing.sequence.pad_sequences(cluster_2_test_sequences, maxlen=30, padding='post')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cN7ASuyXcPif",
        "colab_type": "code",
        "outputId": "7cd23019-33c4-4d55-820e-fc7a256893c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "cluster_2_train_label[1]"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
              "       0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "metadata": {
        "id": "7-FPFfCwMVFK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Embedding Matrix creation"
      ]
    },
    {
      "metadata": {
        "id": "39cGLW65MQLq",
        "colab_type": "code",
        "outputId": "78dd258d-c94b-4acf-e88c-680544b76ce0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        }
      },
      "cell_type": "code",
      "source": [
        "# converting embedding matrix into a form that can be used in keras embedding layer\n",
        "embeddings_index_cls2 = {}\n",
        "\n",
        "for i, line in enumerate(en_de):\n",
        "    if i == 0:\n",
        "        pass\n",
        "    else:\n",
        "        try:\n",
        "            values = line.split()\n",
        "            word = values[0]\n",
        "            coefs = np.asarray(values[1:], dtype='float32')\n",
        "            embeddings_index_cls2[word] = coefs\n",
        "        except ValueError:\n",
        "            print('Value error: {}'.format(values[1:5]))\n",
        "\n",
        "# preparing embedding matrix for cluster 2\n",
        "embedding_matrix_cls2 = np.zeros((len(word_index_cls2) + 1, 300))\n",
        "for word, i in word_index_cls2.items():\n",
        "    embedding_vector = embeddings_index_cls2.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        # words not found in embedding index will be all-zeros.\n",
        "        embedding_matrix_cls2[i] = embedding_vector"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Value error: ['·', '-0.116043', '-0.0278416', '0.0375914']\n",
            "Value error: ['—', '-0.000894651', '0.0377289', '-0.0714999']\n",
            "Value error: ['gebäude', '-0.0360703', '-0.0850809', '-0.0597942']\n",
            "Value error: ['waldfläche', '-0.0314779', '-0.0465583', '-0.0163933']\n",
            "Value error: ['verkehrsfläche', '-0.0356581', '-0.0029205', '0.0181392']\n",
            "Value error: ['erholungsfläche', '-0.0368387', '-0.0377135', '0.00746337']\n",
            "Value error: ['landwirtschaftsfläche', '-0.0263421', '-0.046624', '-0.0177181']\n",
            "Value error: ['sonstige_flächen', '-0.0559894', '-0.0219282', '-0.000380597']\n",
            "Value error: ['gesamtfläche', '-0.0660608', '-0.0324034', '0.0221355']\n",
            "Value error: ['wasserfläche', '-0.0588425', '-0.0477398', '-0.0339936']\n",
            "Value error: ['•', '-0.0626246', '-0.0190532', '-0.0432283']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xDBOd2P6vJJ1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "class_weights_cls2 = dict()\n",
        "\n",
        "max_value = max(Counter(cluster_2_labels_train).values())\n",
        "\n",
        "for keys, values in Counter(cluster_2_labels_train).items():\n",
        "    for _keys, _values in num_label_cluster_2.items():\n",
        "        if keys == _values:\n",
        "            class_weights_cls2[_keys] = (max_value/ values)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "88ZZBxqjClMe",
        "colab_type": "code",
        "outputId": "18bf9cf6-02cf-47d3-da21-226cbc2da528",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        }
      },
      "cell_type": "code",
      "source": [
        "class_weights_cls2"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 9.718353212774144,\n",
              " 1: 12.616383616383617,\n",
              " 2: 4.907324655138916,\n",
              " 3: 3.658988845429523,\n",
              " 4: 1.1875499553340543,\n",
              " 5: 2.1470588235294117,\n",
              " 6: 3.083628372604078,\n",
              " 7: 3.6269385410683515,\n",
              " 8: 4.435897435897436,\n",
              " 9: 8.275884665792923,\n",
              " 10: 5.122287568444534,\n",
              " 11: 7.327531186539019,\n",
              " 12: 7.890659169009685,\n",
              " 13: 1.7378560616485483,\n",
              " 14: 1.0,\n",
              " 15: 2.189493758668516,\n",
              " 16: 3.0634323832625836,\n",
              " 17: 4.209666666666666}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "metadata": {
        "id": "2mEKGliGMZNH",
        "colab_type": "code",
        "outputId": "e76cd8ca-049b-4be8-e52c-0a1c035d92e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 753
        }
      },
      "cell_type": "code",
      "source": [
        "# Create sequential model_cls2\n",
        "model_cls2 = Sequential()\n",
        "model_cls2.add(emb(vocab_size_cls2, 300, weights=[embedding_matrix_cls2], input_length=30, trainable=False))   \n",
        "model_cls2.add(Bidirectional(LSTM(64, activation='tanh',return_sequences=True, kernel_regularizer=keras.regularizers.l2(0.5))))# LSTM layer \n",
        "model_cls2.add(keras.layers.Dropout(0.5))\n",
        "model_cls2.add(Bidirectional(LSTM(64, activation='tanh',return_sequences=False, kernel_regularizer=keras.regularizers.l2(0.5))))\n",
        "model_cls2.add(keras.layers.Dropout(0.5))\n",
        "model_cls2.add(Dense(18, activation='softmax'))\n",
        "model_cls2.compile(loss='categorical_crossentropy', optimizer= 'adam', metrics=['accuracy'])\n",
        "print(model_cls2.summary())\n",
        "model_cls2.fit(cluster_2_padded_sents, cluster_2_train_label, validation_data=(cluster_2_padded_sents_test,cluster_2_test_label), epochs=50, batch_size=32, \n",
        "          verbose=1, callbacks=[reduce_rate,early_stop])"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 30, 300)           14437500  \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 30, 128)           186880    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 30, 128)           0         \n",
            "_________________________________________________________________\n",
            "bidirectional_2 (Bidirection (None, 128)               98816     \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 18)                2322      \n",
            "=================================================================\n",
            "Total params: 14,725,518\n",
            "Trainable params: 288,018\n",
            "Non-trainable params: 14,437,500\n",
            "_________________________________________________________________\n",
            "None\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train on 150737 samples, validate on 60843 samples\n",
            "Epoch 1/50\n",
            "150737/150737 [==============================] - 681s 5ms/step - loss: 5.7500 - acc: 0.1649 - val_loss: 2.6813 - val_acc: 0.1588\n",
            "Epoch 2/50\n",
            "150737/150737 [==============================] - 672s 4ms/step - loss: 2.6556 - acc: 0.1672 - val_loss: 2.6867 - val_acc: 0.1588\n",
            "\n",
            "Epoch 00002: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "Epoch 3/50\n",
            "150737/150737 [==============================] - 674s 4ms/step - loss: 2.6530 - acc: 0.1676 - val_loss: 2.6826 - val_acc: 0.1588\n",
            "\n",
            "Epoch 00003: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "Epoch 00003: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7faac9675828>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "metadata": {
        "id": "e7wu5EtCMexV",
        "colab_type": "code",
        "outputId": "ffc8c5a7-37da-40a5-bd00-6ff3a2819bd0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1561
        }
      },
      "cell_type": "code",
      "source": [
        "# Testing the data\n",
        "model_cls2.save('my_method_cluster_2_model_FB_MUSE.h5')  # creates a HDF5 file 'my_model.h5'\n",
        "\n",
        "#cluster_2_test_sequences = tokenizer_cls2.texts_to_sequences(cluster_2_sent_test)\n",
        "cluster_2_padded_sents_test = keras.preprocessing.sequence.pad_sequences(cluster_2_test_sequences, maxlen=30, padding='post')\n",
        "\n",
        "scores_cls2 = model_cls2.evaluate(cluster_2_padded_sents_test, cluster_2_test_label, verbose=1)\n",
        "print(\"Accuracy: %.2f%%\" % (scores_cls2[1]*100))\n",
        "\n",
        "y_true = np.argmax(cluster_2_test_label, axis=1)\n",
        "y_pred = np.argmax(model_cls2.predict(cluster_2_padded_sents_test),axis=1)\n",
        "classificationReport_cls2 = classification_report(y_true, y_pred)\n",
        "\n",
        "print(classificationReport_cls2)\n",
        "\n",
        "\n",
        "conf_cls2 = confusion_matrix(y_true, y_pred)\n",
        "seaborn.heatmap(conf_cls2)\n",
        "print(confusion_matrix(y_true, y_pred))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "60843/60843 [==============================] - 74s 1ms/step\n",
            "Accuracy: 15.88%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00      1331\n",
            "           1       0.00      0.00      0.00      1176\n",
            "           2       0.00      0.00      0.00      1580\n",
            "           3       0.00      0.00      0.00      2658\n",
            "           4       0.00      0.00      0.00      9606\n",
            "           5       0.00      0.00      0.00      4229\n",
            "           6       0.00      0.00      0.00      3460\n",
            "           7       0.00      0.00      0.00      3890\n",
            "           8       0.00      0.00      0.00      3107\n",
            "           9       0.00      0.00      0.00      1130\n",
            "          10       0.00      0.00      0.00      1426\n",
            "          11       0.00      0.00      0.00      2050\n",
            "          12       0.00      0.00      0.00      1214\n",
            "          13       0.00      0.00      0.00      4331\n",
            "          14       0.16      1.00      0.27      9661\n",
            "          15       0.00      0.00      0.00      4257\n",
            "          16       0.00      0.00      0.00      3627\n",
            "          17       0.00      0.00      0.00      2110\n",
            "\n",
            "   micro avg       0.16      0.16      0.16     60843\n",
            "   macro avg       0.01      0.06      0.02     60843\n",
            "weighted avg       0.03      0.16      0.04     60843\n",
            "\n",
            "[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "  1331    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "  1176    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "  1580    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "  2658    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "  9606    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "  4229    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "  3460    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "  3890    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "  3107    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "  1130    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "  1426    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "  2050    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "  1214    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "  4331    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "  9661    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "  4257    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "  3627    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "  2110    0    0    0]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAccAAAFKCAYAAABo0pS0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3XtUlXXa//HPBkFDQQXdJKVGTkqP\ng6YrTygWDo7p/DIqjwTWb5wmV5LloKikpqkomo0n8pSlNvWIYjk+s0osf1qW6GRM5rQenTzMjGFx\nEgUPCOj+/eGKyS1uYO97wz68X7P2Wnpv9nVftwNcXd/7e3+/JovFYhEAAKjm09gJAADgaiiOAABY\noTgCAGCF4ggAgBWKIwAAViiOAABYaeLsE1SUFjv7FAC8yMVTJw2N1+LeTobGc3X+QSFOi92t40N2\nf/abf31qYCaOc3pxBAB4B5PJ1NgpGIZhVQAArNA5AgAMYTJ5Tr/lOVcCAIBB6tQ5Xrp0SUVFRZKk\ntm3bKiAgwKlJAQDcj488556jzeJ49OhRLViwQKWlpWrdurUsFosKCgoUGhqq2bNnq0uXLg2VJwDA\nxXnShBybxTEtLU0LFixQp043T3X+9ttv9eqrr+rdd991anIAAPfh40H3HG0WR4vFckthlKSuXbvq\n2rVrTksKAOB+vKZz7N69uyZMmKDY2FgFBwdLkoqKipSdna3evXs3SIIAADQ0U22bHX/55ZfKycmp\nnpBjNpvVv39/9ejRo04nYIUcAEZihRzHOHOFnN6/GGL3Z/96ItvATBxX62zVXr16qVevXg2RCwDA\njZm8ZbYqAAB15TUTcgAAqCuvmZADAEBd+XhQcfScHhgAAINQHAEAsMKwKgC3YvL1bewUcBsmD+q3\nKI4AAEMwIQcAACueNCGH4ggAMIQnLQLgOQPEAAAYxO7iWFpaamQeAAC4DLuLY1JSkpF5AADcnI/J\nx+6Xq7F5z9HWZsb5+fmGJwMAcF9eM1t148aN6tevn8xm8y3vVVVVOS0pAID78ZrZqhkZGZo/f75m\nzpwpf3//m947dOiQUxMDALgXr5mt2rlzZ61du1ZNmtxaQ6dPn+60pAAAaEy1Pud4xx131Hi8a9eu\nhicDAHBfrjixxl6ecyUAABiEFXIAAIbwmtmqAADUldfMVgUAoK68ZrYqAADeiM4RgFupulze2Cng\nNrjnCACAFU+658iwKgAAVugcAQCG8LoJORaL5ZZjP/74o+HJAADclydtWWUzo48//lgxMTHq16+f\npk2bposXL1a/l5KS4vTkAABoDDaL47p16/TBBx/owIED6tmzp8aPH6+ysjJJNXeTAADvZTKZ7H65\nGpv3HH19fdWqVStJ0ujRoxUSEqLx48drzZo1LnkxAIDG40mzVW0Wx549e+q5557T8uXL1axZM8XG\nxqpp06Z65plndP78+YbKEQDgBjxpQo7N4piSkqJDhw6padOm1ceio6PVo0cPffjhh05PDgCAxlDr\noxx9+vS55ViLFi00atQopyQEAHBPnjSs6nrzZwEAaGQsAgAAMIQnTdSkOAIADOFJw6oURwCAIZw1\nW/XSpUuaNm2aLly4oMrKSk2cOFFt27bVnDlzJEldunTR3LlzJUlvvvmmdu3aJZPJpKSkJD300EMq\nKytTcnKyysrKFBAQoKVLl1Y/png7FEcAgCGc1Tl+8MEHCg8PV3JysvLz8/X000+rbdu2Sk1NVbdu\n3ZScnKxPP/1U9957rz788ENt2bJFFy9eVHx8vAYMGKBNmzapd+/e+t3vfqfMzEytX79eU6dOtXlO\niiMAt1L27yJD47W839BwcILWrVvr+PHjkqTS0lK1atVKeXl56tatmyQpJiZGOTk5KiwsVHR0tPz9\n/RUcHKy77rpLJ06cUE5OjtLS0qq/dsKECbWek9mqAACX9pvf/EZnz57V4MGDlZCQoJSUFAUFBVW/\nHxISosLCQhUVFSk4OLj6eHBw8C3HQ0JCVFBQUOs56RwBAIZw1mzVP//5zwoLC9OGDRt07NgxTZw4\nUYGBgdXv326t75qO13VdcIojAMAQzrrnmJubqwEDBkiSIiIidPXqVVVVVVW/n5+fL7PZLLPZrNOn\nT9d4vLCwUIGBgdXHasOwKgDAECYH/mdLx44ddeTIEUlSXl6emjdvrk6dOunw4cOSpN27dys6Olp9\n+/bVvn37VFFRofz8fBUUFOgXv/iF+vfvr127dt30tbWpd+d47ty5m8Z0AQCQnNc5jh49WqmpqUpI\nSFBVVZXmzJmjtm3bavbs2bp+/bq6d++uqKgoSdKoUaOUkJAgk8mkOXPmyMfHR4mJiZo6dari4+MV\nFBSkJUuW1HpOk8XGAOy+ffu0cOFCtWvXTqmpqZoyZYquXbumK1eu6JVXXtFDDz1U6wkqSovr8U8A\nALZ9n/25ofHuHjLA0Hiuzj8oxGmxn+2fZPdn13+xysBMHGezc1y9erXefvttnT17VhMmTNAbb7yh\niIgIFRUVacKECXUqjgAAuBubxdHf319hYWEKCwuT2WxWRESEJKlNmzY3bWMFAIAnra1qc0JOSEiI\nNmzYIEnasmWLJOnHH39UWlqa7rzzTudnBwBwGz4mk90vV2OzOC5atEjt2rW76VhxcbHCwsKqVxsA\nAEC60Tna+3I1NodVmzVrpmHDht10rGvXruratatTkwIAuB9nLTzeGHjOEQAAK6yQAwAwhI/nNI50\njgAAWKNzBAAYwhUn1tiL4ggAMIQrPpJhL4ojALfy+NQ/GhrvSy9bPs6ZPKlz5J4jAABW6BwBAIbw\n8aDnHCmOAABDMKwKAIAHq1dxzMnJcVYeAAA350kLj992WHXHjh03/d1isWj16tV6/vnnJUlxcXHO\nzQwA4FZcsMbZ7bbFMSMjQ61atbppQ+OrV6/q+++/b5DEAABoLLctjn/5y1/0xhtv6Pjx45o+fbru\nuusu7d+/X0lJSQ2ZHwDATbji8Ki9blscmzZtqsmTJ+vUqVN69dVX1aNHD12/fr0hcwMAuBGv2rLq\n3nvv1dq1a3XnnXfq7rvvboicAABuyGs2O/65uLg4JuEAALwCiwAAAAzhFfccAQCoDw+qjayQAwCA\nNTpHAIAhGFYFgEbyxvjExk4Bt+FJj3JQHAEAhvCkzpF7jgAAWKFzBAAYwoMaRzpHAACs1as4VlVV\nKS8vT1VVVc7KBwDgpjxp+TibxXH+/PnVfz5w4IAGDx6sl156Sb/+9a+1f/9+pycHAHAfXrHZsSQd\nP368+s8ZGRnavHmz2rdvr8LCQiUlJSk6OtrpCQIA3IML1ji72SyOP291W7Zsqfbt20uS2rZtqyZN\nmMsDAPgPV+wA7WWzwn333Xd68cUXZbFY9K9//UsfffSRhg4dqrfeekuBgYENlSMAAA3KZnFcvnz5\nTX/v2LGjpBud49KlS52XFQAAjchmcezdu3eNxx999FGnJAMAcF8sHwcAgBVXfCTDXhRHAIAhfDyn\nNlIcAQDG8KTOkeXjAACwQnEEAMAKw6oA3ErLNnc0dgq4DU8aVqU4AgAMwYQcAACs0DkCAGDFg2oj\nE3IAALBW787x3LlzCg4OdkYuAAA35km7ctjsHD/99FPNnj1bkpSTk6OYmBiNGzdOgwYN0r59+xoi\nPwAAGpzNznHFihVau3atpJs3Oy4pKdFzzz2nhx9+uCFyBAC4Aa9ZeLyqqkrNmzeXJAUGBuruu++W\nJLVq1UoWi8X52QEA3IYHjaraLo7jx49XXFyc+vfvr1atWun5559Xjx49dOjQIY0cObKhcgQAuAFn\n3nPcuXOn3nzzTTVp0kSTJk1Sly5dlJKSomvXrqlt27ZasmSJ/P39tXPnTm3atEk+Pj4aNWqURo4c\nqcrKSk2fPl1nz56Vr6+vFi5cqPbt29s8n83iOHz4cA0cOFAHDhxQXl6eLBaL2rRpo7S0NIWGhhp6\n4QAA1KSkpEQZGRnavn27Ll++rJUrVyo7O1vx8fEaOnSoXn/9dWVlZSkuLk4ZGRnKysqSn5+fRowY\nocGDB2vv3r0KCgrS0qVL9fnnn2vp0qVatmyZzXPWOlu1VatWGjZsmGEXCQDwTM5aBCAnJ0f9+vVT\nixYt1KJFC82bN0+DBg3S3LlzJUkxMTF66623FB4ersjISAUGBkqSevbsqdzcXOXk5CguLk6SFBUV\npdTU1FrPySIAAABDOGtU9fvvv1d5ebkmTJig0tJSvfDCC7py5Yr8/f0lSSEhISosLFRRUdFNjxoG\nBwffctzHx0cmk0kVFRXVn68JxREA4PLOnz+vVatW6ezZsxo3btxNk0JvN0G0vsd/jhVyAACGMJlM\ndr9sCQkJUY8ePdSkSRN16NBBzZs3V/PmzVVeXi5Jys/Pl9lsltlsVlFRUfXnCgoKqo8XFhZKkior\nK2WxWGx2jRLFEQBgEB+T/S9bBgwYoIMHD+r69esqKSnR5cuXFRUVpezsbEnS7t27FR0dre7du+vo\n0aMqLS3VpUuXlJubqwcffFD9+/fXrl27JEl79+5Vnz59ar0WhlUBAC4tNDRUQ4YM0ahRoyRJM2fO\nVGRkpKZNm6bMzEyFhYUpLi5Ofn5+Sk5O1vjx42UymTRx4kQFBgZq2LBhOnDggMaOHSt/f38tWrSo\n1nOaLE5+mr+itNiZ4QF4mW/W/sXQeN2e+z+GxnN1/kEhTov99tNL7P7s/9001cBMHEfnCAAwhNes\nkAMAQF15za4cAAB4IzpHAIAhnLVCTmOw2Tn27NlT8+bNU3Exk2oAAN7DZufYtWtXPfLII0pOTla7\ndu30xBNPVD+ICQDAz3lQ42i7OJpMJvXq1UsbN27U0aNHtW3bNs2aNUvNmzdXSEiI1q1b11B5AgBc\nnCcNq9osjj9/BDIyMlKRkZGSbizJ89NSPAAASF7UOT722GM1Hv9prToAAH7iNY9yjBgxoqHyAADA\nZfCcIwAAVph2CgAwhAeNqlIcAQDG8JrZqgAA1JUH1UaKIwDAGHSOANBIAtsGNHYK8ALMVgUAwAqd\nIwDAEB40qkpxBAAYw5NWyKE4AgAM4UG1sf7F0WKxeNSMJACAMTypNtickPP5559r6NCheuqpp/TN\nN9/oySef1MCBA/XII4/or3/9a0PlCABAg7LZOWZkZGjTpk26cOGCEhMTtXHjRkVERCgvL09Tp07V\ne++911B5AgBcnAc1jraLo5+fX/X2VEFBQYqIiJAk3XXXXfL19W2QBAEAaGg2i2PLli31xz/+USUl\nJerQoYNmz56t6Ohoff311woJCWmoHAEAbsBr7jmmp6fLbDarb9++evPNN/Xggw/qiy++UJs2bZSW\nltZQOQIA3IDJZP/L1djsHAMCAvTUU09V/3348OEaPny405MCALgfr+kcAQDwRiwCAAAwhAc1jhRH\nAIAxGFYFAMCD0TkCAAzhQY0jxRGAezH36tTYKeA22JUDAAArHlQbuecIAIA1OkcAgCE8abYqxREA\nYAgPqo11G1a1WCw6d+6ciouLnZ0PAACNzmbnePr0aaWnpysvL0/ff/+9OnXqpAsXLqhr166aMWOG\nQkNDGypPAICLM/l4Tutos3N85ZVX9PLLL+t//ud/tH37dkVGRurjjz/WE088oSlTpjRUjgAAN+BJ\nu3LYLI4VFRVq3769JOmee+7R8ePHJUkDBw5UeXm587MDAKAR2BxW7dy5s/7whz+oW7du2r9/v/r0\n6SNJSk1N1S9+8YsGSRAA4B68Zrbq3LlztWfPHv3zn//U008/rYEDB0qSxo0bpy5dujRIggAA9+BB\ntdF2cTSZTIqNjb3leEREhNMSAgC4J0/qHFkhBwAAKywCAAAwhAc1jnSOAABYo3MEABjDg1pHiiMA\nt3K9vKKxU8BteNKEHIojAMAQHlQbKY4AAGN4zdqqAAB4I4ojAABWKI4AAEM4e1eO8vJyxcbG6v33\n39cPP/ygxMRExcfH68UXX1RFxY2JWjt37tSTTz6pkSNHatu2bZKkyspKJScna+zYsUpISNCZM2dq\nPRfFEQBgCJPJZPerLlavXq2WLVtKklasWKH4+Hi999576tixo7KysnT58mVlZGRo48aNeuedd7Rp\n0yadP39ef/nLXxQUFKT//u//1oQJE7R06dJaz2VzQk5lZaW2b9+uAwcOqLCwUJJkNpsVHR2txx9/\nXL6+vnW6IACA53PmbNWTJ0/qxIkTevjhhyVJhw4d0ty5cyVJMTExeuuttxQeHq7IyEgFBgZKknr2\n7Knc3Fzl5OQoLi5OkhQVFaXU1NRaz2ezOKakpKhDhw767W9/q5CQEFksFuXn5ys7O1szZszQ4sWL\nHblWAIAHceZzjunp6Zo1a5Z27NghSbpy5Yr8/f0lSSEhISosLFRRUZGCg4OrPxMcHHzLcR8fH5lM\nJlVUVFR/viY2i2NhYaH++Mc/3nSsQ4cO6tWrlxISEuy7QgAA6mHHjh164IEH1L59+xrft1gshhz/\nuVq3rNq9e7diYmLk5+cnSaqoqFB2drbNigsAgFH27dunM2fOaN++ffrxxx/l7++vgIAAlZeXq1mz\nZsrPz5fZbJbZbFZRUVH15woKCvTAAw/IbDarsLBQERERqqyslMViqbWG2SyOS5Ys0fLly5Wenq4r\nV65Ikpo3b65+/fpp0aJFBlwyAMBTOGtUddmyZdV/Xrlype666y797W9/U3Z2th577DHt3r1b0dHR\n6t69u2bOnKnS0lL5+voqNzdXqampunjxonbt2qXo6Gjt3btXffr0qfWcNovjnXfeqYULF9b43rhx\n47R58+Z6XiIAwFM15NqqL7zwgqZNm6bMzEyFhYUpLi5Ofn5+Sk5O1vjx42UymTRx4kQFBgZq2LBh\nOnDggMaOHSt/f/86NXcmi43B13ffffe2H9y8ebOys7NrPUFFaXGtXwMAdVX23XeGxgu87z5D47k6\n/6AQp8U+vHST3Z99MPlpAzNxnM3OcePGjerXr5/MZvMt71VVVTktKQCA+/GaXTkyMjI0f/58zZw5\n85abl4cOHXJqYgAANBabK+R07txZa9euVZMmt9bQ6dOnOy0pAAAaU61bVt1xxx01Hu/atavhyQBA\nba6eKzM0XqCh0bybB42qsp8jAMAYXnPPEQCAuvKg2khxBAAYxIOqI1tWAQBghc4RAGAIkw+do157\n7TUj8wAAwGXY7Bx/Wmy8Jl9//bXhyQAA3JcH3XK0XRx79ep1y9JxJpNJFotFxcWsmQoA+A+veZQj\nJSVFxcXFmjx58i3vJSYmOi0pAID78aDaaPue47hx4xQeHq7Lly/f8t6AAQOclhQAAI2p1gk5cXFx\nCggIuOX4F1984ZSEAABuymSy/+VibA6r2trPMT8/3/BkAADuy5Me5WA/RwAArLCfIwDAEC44Omo3\nm8WR/RwBAHXmQdWR/RwBALDC2qoA3Eqz0NaNnQJuw4MaR4ojAMAYXjNbFQCAuvKk5ePYzxEAACt0\njgAAY3hO40jnCACANZvFsbi4WEuWLNHMmTN18ODBm9579dVXnZoYAMC9mEwmu1+uxmZxnDp1qsLC\nwtS/f39lZGQoIyOj+r0TJ044PTkAgPvwmuJYWVmpp556SkOHDtWmTZt06tQprVq1SpJksVgaJEEA\ngJvwceDlYmym1KRJE2VnZ8tiscjHx0dLlizRmTNnNGvWLF26dKmhcgQAuAGv6RzT0tK0d+9eXb16\n9cYX+/goPT1dvXr1UkVFRYMkCABAQ7NZHNu1a6dFixapWbNmNx0fPny4goODnZoYAACNhc2OAQCG\ncMXhUXux2TEAwBieUxvZ7BgAYAyvWXiczY4BAHXmLcOqEpsdA3At337wtaHx+kwONzQePIMLPnoJ\nAEDjYlcOAIAhPGhUleIIADCG1zzKAQBAnXnLbFUAAOrKkzpHJuQAAGDFZudYUlKibdu2KTQ0VI89\n9pjWrl2r3NxchYeH6/e//z3rqwIA/sNzGkfbnWNKSooqKir01VdfaeLEiSorK9PEiRN19913KyUl\npaFyBACgQdnsHK9evaqkpCRZLBY98sgjysjIkCR169ZN2dnZDZIgAMA9eM09x6qqKuXl5clkMmnm\nzJnVx48dO6bKykqnJwcAcB8mH5PdL1djszhOnTpVS5YskSRFR0dLkj755BNNmzZNL7/8svOzAwC4\nD5PJ/peLsTms2qNHD/Xo0eOmY7GxsYqNjdW4ceO0efNmpyYHAHAfnjSsymbHAABYYbNjAIAxPKdx\nZLNjAACssdkxAMAQrjjr1F5sdgzArUx86x1D4x2e/Lih8byaEyfkLF68WF999ZWqqqr03HPPKTIy\nUikpKbp27Zratm2rJUuWyN/fXzt37tSmTZvk4+OjUaNGaeTIkaqsrNT06dN19uxZ+fr6auHChWrf\nvr3N87HwOADAEM6arXrw4EF99913yszMVElJiR5//HH169dP8fHxGjp0qF5//XVlZWUpLi5OGRkZ\nysrKkp+fn0aMGKHBgwdr7969CgoK0tKlS/X5559r6dKlWrZsmc1zsvA4AMCl9erVS8uXL5ckBQUF\n6cqVKzp06JB+9atfSZJiYmKUk5OjI0eOKDIyUoGBgWrWrJl69uyp3Nxc5eTkaPDgwZKkqKgo5ebm\n1npOiiMAwBg+JvtfNvj6+iogIECSlJWVpYEDB+rKlSvVE0VDQkJUWFiooqKimzbECA4OvuW4j4+P\nTCaTKioqbF+KI/8OAAD8xGQy2f2qi08++URZWVmaPXv2TcctFkuNX1/f4z9HcQQAuLz9+/drzZo1\nWr9+vQIDAxUQEKDy8nJJNxalMZvNMpvNKioqqv5MQUFB9fHCwkJJUmVlpSwWyy2PJ1qrd3FMTEys\n70cAAN7A5MDLhrKyMi1evFhr165Vq1atJN24d/jT7lC7d+9WdHS0unfvrqNHj6q0tFSXLl1Sbm6u\nHnzwQfXv31+7du2SJO3du1d9+vSp9VJszlaNiIiQ2WyWn59fdRtaWFioQYMGyWQyac+ePbWeAADg\nHZw1W/XDDz9USUmJXnrppepjixYt0syZM5WZmamwsDDFxcXJz89PycnJGj9+vEwmkyZOnKjAwEAN\nGzZMBw4c0NixY+Xv769FixbVfi0WG4Ov+/fv17p165SQkKAhQ4ZIkkaPHq3MzMw6X1RFaXGdvxYA\navNg5BOGxjt89H1D47k6/6AQp8X+cd//s/uzdz48yMBMHGdzWDU6OlobNmzQ8ePHNXHiRJ05c8aj\nVl0HABjISbNVG0OtiwD4+/tr0qRJOn36tObPn69z585JkkpLSxUUFOT0BAEA7sGTmqc6T8gJDw/X\n2rVr9c47N5ZuSkpKclpSAAA35C2bHbOfIwDAG7GfIwDAEJ40rMp+jgAAWGE/RwCAMVxw1qm92M8R\ngFtZ/btxjZ0CbsNrhlUBAKgziiMAADczedCwKrtyAABgheIIAIAVhlUBAMbgniMAADfzpNmqNodV\nP/300+o/nz9/XvPmzVNiYqLmzZtXvQA5AACSPGptVZvFccOGDdV/njdvnkJDQzVnzhx16tRJqamp\nTk8OAOA+TD4mu1+ups7DqkVFRVq6dKkkqVOnTvroo4+clhQAAI3JZnEsKSmpHlr19/fXsWPHFBER\noTNnzujKlSsNkiAAAA3NZnH85S9/qV27dkmS2rRpo/Pnz0uSlixZoueee8752QEA3IcL3ju0l83i\nuHDhwhqPr1ixQuPGjdPgwYOdkhQAwA15S3Fks2MAQF150qMcbHYMADCGC846tRebHQMAYIXNjgEA\nhjCZPGe5bjY7BuBWmrds2tgpwAuwtioAwBjeMiEHAIC68prZqgAA1JkHzVb1nLunAAAYhM4RAGAI\nhlUBALDmLcWxrKxMhw8fVkxMjEpLS7VmzRqdPHlS4eHh+v3vf6/g4OCGyhMAgAZj857jpEmTVFRU\nJEmaO3euAgMDlZSUpHvuuUfTpk1rkAQBAG7C5GP/y8XY7BwvXryokSNHSpIKCgqqNzuOjIzUzp07\nnZ8dAMBtmLxltmqHDh2Ulpamo0ePqk+fPvroo49UVFSk999/X23btm2oHAEAaFA2O8f09HRt3bpV\nK1asUF5eniwWi9q0aaOBAwdq5syZDZUjAMAdeMuEnCZNmig+Pl7x8fG3vDdu3Dht3rzZaYkBANyL\n1zzKwWbHAIA6c8GJNfZis2MAAKyw2TEAwBBeM1uVzY4BAN6IzY4BuBXz/aGNnQJux1sm5AAAUFde\nM1sVAIA685bZqgAA1Jm3TMgBAMAbURwBALBiszjOnj1bR48ebahcAABuzGQy2f1yNTbvOX799deq\nqqrS+vXrlZCQoN69ezdUXgAAd+MtE3JatmyptLQ0nT59Wps3b9aCBQvUrVs3RUREKDg4WEOHDm2o\nPAEALs4VO0B72SyOP11oeHi4XnnlFVVWVurLL7/U0aNHdfr0aYojAOA/vKVzbN269U1/9/PzU1RU\nlKKiolRaWurUxAAAaCw2y/zy5ctv+15SUpLhyQAA4ArYzxEAYAhn7sqRlpamI0eOyGQyKTU1Vd26\ndXPauST2cwQAGMVJE3L++te/6l//+pcyMzN18uRJpaamKjMz0ynn+gn7OQIADGFy0oScnJwcxcbG\nSpI6deqkCxcu6OLFi2rRooVTziexnyMAwCgmk/0vG4qKim6aIBocHKzCwkKnXorT93P0DwqpX0YA\nYEPY4MGNnQJuo6F+31ssFqefw3MeSgEAeCSz2ayioqLqvxcUFKht27ZOPSfFEQDg0vr376/s7GxJ\n0rfffiuz2ezU+40S+zkCAFxcz5491bVrV40ZM0Ymk0mvvPKK089psjTE4C0AAG6EYVUAAKxQHAEA\nsOISxTEtLU2jR4/WmDFj9M033zgc7x//+IdiY2P1pz/9yYDspMWLF2v06NF68skntXv3brvjXLly\nRS+++KISEhI0cuRI7d2715D8ysvLFRsbq/fff9+hOIcOHVLfvn2VmJioxMREzZs3z+Hcdu7cqeHD\nh+uJJ57Qvn37HIq1bdu26twSExPVo0cPu2NdunRJSUlJSkxM1JgxY7R//36Hcrt+/bpmzZqlMWPG\nKDExUSdPnrQ7lvX37w8//KDExETFx8frxRdfVEVFhd2xJGnz5s3q2rWrLl26ZEhuzzzzjBISEvTM\nM8/U+9kz63h/+9vfNHbsWCVI6PauAAAIMElEQVQmJmr8+PE6d+6cQ/F+sn//fnXp0qVesWqKN336\ndD366KPV34P1/Z62jldZWank5GSNGDFCTz/9tC5cuOBQvEmTJlXn9uijj2rWrFn1iof/aPQJOUYv\nC3T58mXNmzdP/fr1MyS/gwcP6rvvvlNmZqZKSkr0+OOP69e//rVdsfbu3atf/vKXevbZZ5WXl6ff\n/va3iomJcTjH1atXq2XLlg7HkaTevXtrxYoVhsQqKSlRRkaGtm/frsuXL2vlypV6+OGH7Y43cuRI\njRw5UtKN75uPPvrI7lgffPCBwsPDlZycrPz8fD399NPatWuX3fH27NmjsrIybdmyRf/+97+1YMEC\nrV27tt5xavr+XbFiheLj4zV06FC9/vrrysrKUnx8vF2xduzYoeLi4hqXhLQn3rJlyzRq1CgNGzZM\n7777rt5++22lpKTYHe/tt9/W4sWL1b59e61atUpbt27VhAkT7I4nSVevXtW6devqPfX/dvH+8Ic/\n2PVzW1O8rVu3qnXr1lq6dKkyMzN1+PBh/epXv7I73s9/dmfMmFH984L6a/TO8XbLAtnL399f69ev\nt+uHvya9evWq3p0kKChIV65c0bVr1+yKNWzYMD377LOSbvwXd2hoqMP5nTx5UidOnHCo6DhLTk6O\n+vXrpxYtWshsNhvSif4kIyNDzz//vN2fb926tc6fPy9JKi0tvWV7tvr65z//Wb0QcocOHXT27Fm7\nvk9q+v49dOhQ9S/MmJgY5eTk2B0rNjZWkydPtmtT2privfLKKxoyZIikm/9N7Y23YsUKtW/fXhaL\nRfn5+brzzjsdiidJa9asUXx8/C1LYNobz141xdu7d6+GDx8uSRo9enSdC2Nt+Z06dUplZWVOX5zb\nkzV6cTR6WaAmTZqoWbNmRqQmSfL19VVAQIAkKSsrSwMHDpSvr69DMceMGaMpU6YoNTXV4fzS09MN\nXcrvxIkTmjBhgsaOHasvvvjCoVjff/+9ysvLNWHCBMXHx9f5l3ptvvnmG7Vr186hh4B/85vf6OzZ\nsxo8eLASEhI0bdo0h3Lq3LmzPv/8c127dk2nTp3SmTNnVFJSUu84NX3/XrlypfoXe0hISJ1/PmqK\n5cizYTXFCwgIkK+vr65du6b33ntPjz76qEPxJOmzzz7TI488oqKiourCYW+806dP69ixY3ZtzH67\n/P70pz9p3Lhxmjx5cr2GfWuKl5eXp88++0yJiYmaPHlyvf7jwtbvus2bNyshIaHOsXCrRi+O1lz1\nyZJPPvlEWVlZmj17tsOxtmzZotWrV2vq1KkOXe+OHTv0wAMPqH379g7nJEn33HOPkpKStHr1aqWn\np+vll1+u1/2tmpw/f16rVq3SokWLNGPGDEP+/83KytLjjz/uUIw///nPCgsL08cff6xNmzbp1Vdf\ndSjeQw89pMjISD311FPatGmT7r33Xqd8L7viz8e1a9eUkpKivn37GnI7Y+DAgdq1a5fuvfderVu3\nzqFYCxcu1IwZMxzO6SePPfaYpkyZos2bN+v+++/XqlWrHIpnsVgUHh6ud955R/fdd59dQ/HWKioq\n9NVXX6lv374Ox/JmjV4cG2NZoPrav3+/1qxZo/Xr1yswMNDuOH//+9/1ww8/SJLuv/9+Xbt2rd4T\nDn5u37592rNnj0aNGqVt27bpjTfe0IEDB+yOFxoaqmHDhslkMqlDhw5q06aNQ/t2hoSEqEePHmrS\npIk6dOig5s2bO3S9Pzl06JBDk3EkKTc3VwMGDJAkRUREqKCgwO7h8p9MnjxZW7Zs0dy5c1VaWqqQ\nEGPWmQwICFB5ebmkG/uoGjXMZ5QZM2aoY8eOhmyA/vHHH0uSTCaThgwZoq+++sruWPn5+Tp16pSm\nTJmiUaNGqaCgwOFuql+/frr//vslSYMGDdI//vEPh+K1adNGvXr1kiQNGDBAJ06ccCieJH355ZcM\npxqg0YtjYywLVB9lZWVavHix1q5dq1atWjkU6/Dhw3rrrbck3RhOvnz5skP3upYtW6bt27dr69at\nGjlypJ5//nlFRUXZHW/nzp3asGGDJKmwsFDFxcUO3RcdMGCADh48qOvXr6ukpMTh65Vu/MJr3rx5\nve8fWevYsaOOHDki6cbQVvPmzR0aLj927Fh1h/LZZ5/pv/7rv+TjY8yPV1RUVPXPyO7duxUdHW1I\nXCPs3LlTfn5+mjRpkiHxVq5cqf/93/+VJB05ckTh4eF2xwoNDdUnn3yirVu3auvWrTKbzQ7PYH/h\nhRd05swZSTf+I+2+++5zKN7AgQOrZ0p/++23Dl3vT44ePaqIiAiH43i7Rp+tavSyQH//+9+Vnp6u\nvLw8NWnSRNnZ2Vq5cqXdhe3DDz9USUmJXnrppepj6enpCgsLq3esMWPG6OWXX1Z8fLzKy8s1e/Zs\nw36BGmHQoEGaMmWK9uzZo8rKSs2ZM8ehIhQaGqohQ4Zo1KhRkqSZM2c6fL2FhYUKDg52KIZ0Y/JD\namqqEhISVFVVpTlz5jgUr3PnzrJYLBoxYoSaNm2q1157za44NX3/vvbaa5o+fboyMzMVFhamuLg4\nu2NFRUXpwIEDKiws1LPPPqsHHnigzrNLa4pXXFyspk2bKjExUdKNSXV1/besKd78+fM1d+5c+fr6\nqlmzZlq8eHGdYt0uniM/+zXFS0hI0EsvvaQ77rhDAQEBWrhwoUPxXnvtNS1YsEBZWVkKCAhQenq6\nQ/FWrlypwsJCdejQwZ5Lxs+wfBwAAFZcp20BAMBFUBwBALBCcQQAwArFEQAAKxRHAACsUBwBALBC\ncQQAwArFEQAAK/8fmusPVS2oAw8AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 576x396 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "WntUbP5k7Km1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Cluster 1 test data, sentence conversion\n",
        "from sklearn.preprocessing import MinMaxScaler, Normalizer, StandardScaler\n",
        "\n",
        "doc_id_pred = []\n",
        "file_name_pred = []\n",
        "multi_label_pred = []\n",
        "pred_one_hot_encoded = []\n",
        "label_one_hot_encoded = []\n",
        "prd_for_doc = []\n",
        "\n",
        "original_label = []\n",
        "predicted_label = []\n",
        "\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "from collections import Counter \n",
        "\n",
        "\n",
        "counter = 0\n",
        "for first_data, first_label in zip(cluster_2_data_test, cluster_2_label_test):\n",
        "    \n",
        "    ## TMP LIST for each doc\n",
        "    sent_pred = []\n",
        "    \n",
        "    # start chunking the text into 30 words with 10 word slide\n",
        "    slides = slidingWindow(first_data.split(' '),30,10)\n",
        "        \n",
        "    for key,value in num_label_cluster_2.items():\n",
        "        if value == first_label:\n",
        "            num = key\n",
        "    \n",
        "    doc_sent = []\n",
        "    for slide in slides:\n",
        "        \n",
        "        a = ' '.join(slide).lower()\n",
        "        \n",
        "        doc_sent.append(a)\n",
        "        \n",
        "    # we have the slide here, create the sequence from text to numbers\n",
        "    text_sequence = tokenizer_cls2.texts_to_sequences(doc_sent)\n",
        "#     print(text_sequence)\n",
        "#     sys.exit()\n",
        "\n",
        "    # pad it to make flat 30 lenght\n",
        "    text_padded = keras.preprocessing.sequence.pad_sequences(text_sequence, maxlen=30, padding='post')\n",
        "\n",
        "    # Convert the label for this into one hot encoding\n",
        "    label_one_hot = onehot_encoder.fit_transform(np.reshape(num,(1,-1)))\n",
        "\n",
        "    # predict the label\n",
        "    sent_pred.append(model_cls2.predict(text_padded))        \n",
        "    \n",
        "\n",
        "     #after predicting everything for every slide\n",
        "    # take the argmax on the document \n",
        "#     doc_predictions = []\n",
        "#     for i in sent_pred: \n",
        "#         doc_predictions.append(np.argmax(i,axis=1))\n",
        "    nor_data = []\n",
        "    for predc in sent_pred:\n",
        "        transformer2 = Normalizer().fit(predc)\n",
        "        nor_data.append(transformer2.transform(predc))    \n",
        "        \n",
        "    sent = np.zeros(18)\n",
        "    for sen in nor_data:\n",
        "        for i in range(len(sen)):\n",
        "            sent += sen[i]\n",
        "    \n",
        "    predicted_label.append(np.argmax(sent, axis=0))\n",
        "    original_label.append(num)\n",
        "    \n",
        "    \n",
        "    \n",
        "#     pre_for_doc = []\n",
        "#     # count the max number of instances \n",
        "#     for sentence_pred in doc_predictions:\n",
        "#         pre_for_doc.append(Counter(sentence_pred).most_common(1)[0][0])\n",
        "   \n",
        "#     prd_for_doc.append(Counter(pre_for_doc).most_common(1)[0][0])\n",
        "  \n",
        "   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JANRu8nhWcnz",
        "colab_type": "code",
        "outputId": "828c1172-2e05-48e7-8bef-c6898f5aa308",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 533
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "accuracy_score(original_label, predicted_label)\n",
        "confusion_matrix(original_label, predicted_label)\n",
        "print(classification_report(original_label, predicted_label))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        12\n",
            "           1       0.00      0.00      0.00        18\n",
            "           2       0.00      0.00      0.00        22\n",
            "           3       0.00      0.00      0.00        32\n",
            "           4       0.00      0.00      0.00        96\n",
            "           5       0.00      0.00      0.00        54\n",
            "           6       0.00      0.00      0.00        32\n",
            "           7       0.00      0.00      0.00        44\n",
            "           8       0.00      0.00      0.00        36\n",
            "           9       0.00      0.00      0.00        18\n",
            "          10       0.00      0.00      0.00        24\n",
            "          11       0.00      0.00      0.00        26\n",
            "          12       0.00      0.00      0.00        20\n",
            "          13       0.00      0.00      0.00        64\n",
            "          14       0.17      1.00      0.30       130\n",
            "          15       0.00      0.00      0.00        50\n",
            "          16       0.00      0.00      0.00        38\n",
            "          17       0.00      0.00      0.00        32\n",
            "\n",
            "   micro avg       0.17      0.17      0.17       748\n",
            "   macro avg       0.01      0.06      0.02       748\n",
            "weighted avg       0.03      0.17      0.05       748\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "1vkaof1MQ27s",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# SAVING THE DATA"
      ]
    },
    {
      "metadata": {
        "id": "3vOHDSGmLkIC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def save_data(obj, objname):\n",
        "    with open(objname, 'wb') as picklehandle:\n",
        "        pickle.dump(obj,picklehandle)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Jarykr2FQ3BW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "save_data(cluster_2_padded_sents, 'LegDiv_cls2_train_sents.pkl')\n",
        "save_data(cluster_2_train_label, 'LegDiv_cls2_train_labels.pkl')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FuugIAmBAIfK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    }
  ]
}