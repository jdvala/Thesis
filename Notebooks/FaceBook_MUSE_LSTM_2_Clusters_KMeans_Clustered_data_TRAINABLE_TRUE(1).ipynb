{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FaceBook MUSE LSTM 2 Clusters KMeans Clustered data TRAINABLE-TRUE.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "xPmUx16HunB7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# LSTM 2 Cluster KMeans Clustered Data(EN-DE) with Facebooks MUSE word embedding\n",
        "\n",
        "The idea here is to divide the data into two clusters based on the results from K-Means clustering. Trainable true\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "WYNVUD3ZpFZj",
        "colab_type": "code",
        "outputId": "b30be045-c3a1-4b03-d276-315943ed6e4f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "# Imports\n",
        "import os\n",
        "import keras\n",
        "import sys\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM, Bidirectional\n",
        "from keras.layers import Embedding as emb\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import load_model\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn \n",
        "\n",
        "# Setting seed to get reproducable results\n",
        "from numpy.random import seed\n",
        "from tensorflow import set_random_seed\n",
        "SEED = 13\n",
        "seed(SEED)\n",
        "set_random_seed(SEED)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "eLNThdyLHGHo",
        "colab_type": "code",
        "outputId": "781b02c2-33d5-4fcd-971c-e6e2d6881de6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "TEeI0omc0F10",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Getting English and German word embeddings\n",
        "with open('/content/gdrive/My Drive/Thesis/fbMUSE/wiki.multi.en.vec') as e:\n",
        "    en_vec = e.readlines()\n",
        "with open('/content/gdrive/My Drive/Thesis/fbMUSE/wiki.multi.de.vec') as d:\n",
        "    de_vec = d.readlines()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YBd_CLDaH6NR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "en_de= en_vec+de_vec"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7-Y-5EKbnpAJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Preparing Data\n",
        "The word embedding created using facebooks MUSE are not preprocessed in anyway except fot lower case the words. So in order to use these word embedding we need the data into the same format. "
      ]
    },
    {
      "metadata": {
        "id": "DaS4Gsp1Eb0B",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!unzip /content/gdrive/My\\ Drive/Thesis/data/Scrapped_raw.zip "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RLnKeFeGqMvS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!python removeMajority_drive.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OLyX7ZHoGtFE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The above command will create dataset for the training of facebooks word embeddings as the embeddings were trained on unprocessed data, I had to prepare that too. All though all the words need to be lower cased."
      ]
    },
    {
      "metadata": {
        "id": "J5B7SaFVq1nx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# unpickle data\n",
        "import pickle\n",
        "def unpickle(obj):\n",
        "    with open(obj, 'rb') as picklehandle:\n",
        "        toReturn = pickle.load(picklehandle)\n",
        "    return toReturn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LbHesQk90IL5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "en_de_combined = unpickle('/content/combined_data.pkl')\n",
        "label = unpickle('/content/en-de-label.pkl')\n",
        "# en_data = unpickle('/content/EN-DATA.pkl')\n",
        "# en_label = unpickle('/content/EN-LABEL.pkl')\n",
        "# de_data = unpickle('/content/DE-DATA.pkl')\n",
        "# de_label = unpickle('/content/DE-LABEL.pkl')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yH0Y3azSUnbc",
        "colab_type": "code",
        "outputId": "ee34ecc3-7209-4f09-d402-6a1c52ca28a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "len(en_de_combined), len(label)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2716, 2716)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "yIONIpFCocp2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Initial Test Train Split\n",
        "train_data, test_data, train_la, test_la = train_test_split(en_de_combined, label,test_size=0.3, random_state=13)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fxZqZW2Uwhru",
        "colab_type": "code",
        "outputId": "939b5c8a-16a9-4e7d-a37d-185f49d2f869",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "len(train_data)+ len(test_data)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2716"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "wfXj3Bat__EH",
        "colab_type": "code",
        "outputId": "7315f213-31a3-4c8c-ebd2-ee6900c0aa18",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "cell_type": "code",
      "source": [
        "train_la[1:5]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['justice_freedom_security',\n",
              " 'research_innovation',\n",
              " 'fight_against_fraud',\n",
              " 'education_training_youth']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "oJTyalw5ulTp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# KMeans performed on the documents suggested that these classes should be togather in one cluster.\n",
        "cluster_1_info = ['agriculture',\n",
        " 'audiovisual_and_media',\n",
        " 'competition',\n",
        " 'consumers',\n",
        " 'employment_and_social_policy',\n",
        " 'energy',\n",
        " 'enterprise',\n",
        " 'environment',\n",
        " 'food_safety',\n",
        " 'information_society',\n",
        " 'internal_market',\n",
        " 'public_health',\n",
        " 'taxation',\n",
        " 'transport']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "47cpzbQMNeL1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# sliding window for creating sentences\n",
        "def slidingWindow(sequence,winSize,step):\n",
        "    \"\"\"Returns a generator that will iterate through\n",
        "    the defined chunks of input sequence. Input sequence\n",
        "    must be sliceable.\"\"\"\n",
        "\n",
        "    # Pre-compute number of chunks to emit\n",
        "    numOfChunks = ((len(sequence)-winSize)/step)+1\n",
        "    # Do the work\n",
        "    for i in range(0,round(numOfChunks)*step,step):\n",
        "        yield sequence[i:i+winSize]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Nf-PqYs8oSNy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# TRAIN DATA\n",
        "# dividing data with second sampling technique, the first one was already done where the duplicates from the \n",
        "# major class were removed, and if there were duplicates in the same class they were removed too.\n",
        "# we dont need the multiclass information of doc ids here so I will not bother about it here \n",
        "cluster_1_data = []\n",
        "cluster_1_label = []\n",
        "\n",
        "root_data = []\n",
        "root_label = []\n",
        "\n",
        "cluster_2_data = []\n",
        "cluster_2_label = []\n",
        "\n",
        "# for statistics\n",
        "count_cluster_1 =0\n",
        "count_cluster_2 =0\n",
        "count_root = 0\n",
        "\n",
        "# we will just divide the train data and labels\n",
        "\n",
        "for combined_doc, label in zip(train_data, train_la):\n",
        "    if label == 'content':\n",
        "        pass\n",
        "    elif label in cluster_1_info:\n",
        "        \"\"\"call the split function on the data\"\"\"\n",
        "        count_cluster_1 +=1\n",
        "        count_root +=1\n",
        "        cluster_1_data.append(combined_doc.split('\\n\\n\\n')[0])\n",
        "        cluster_1_data.append(combined_doc.split('\\n\\n\\n')[1])\n",
        "        cluster_1_label.append(label)\n",
        "        cluster_1_label.append(label)\n",
        "        \n",
        "        root_data.append(combined_doc.split('\\n\\n\\n')[0])\n",
        "        root_data.append(combined_doc.split('\\n\\n\\n')[1])\n",
        "        root_label.append(1)    # label for cluster 1 in the root classifier is 1\n",
        "        root_label.append(1)\n",
        "    elif label not in cluster_1_info:\n",
        "        count_cluster_2 +=1\n",
        "        count_root+=1\n",
        "        cluster_2_data.append(combined_doc.split('\\n\\n\\n')[0])\n",
        "        cluster_2_data.append(combined_doc.split('\\n\\n\\n')[1])\n",
        "        cluster_2_label.append(label)\n",
        "        cluster_2_label.append(label)\n",
        "        \n",
        "        root_data.append(combined_doc.split('\\n\\n\\n')[0])\n",
        "        root_data.append(combined_doc.split('\\n\\n\\n')[1])\n",
        "        root_label.append(2)    # label for cluster 2 in root classifier is 2 \n",
        "        root_label.append(2)\n",
        "    else:\n",
        "        print('Something wrong')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "loeYPI89AJbx",
        "colab_type": "code",
        "outputId": "931318a2-462e-4c06-9fe1-c5a572c1ef2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        }
      },
      "cell_type": "code",
      "source": [
        "cluster_1_label[1:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['information_society',\n",
              " 'information_society',\n",
              " 'information_society',\n",
              " 'employment_and_social_policy',\n",
              " 'employment_and_social_policy',\n",
              " 'internal_market',\n",
              " 'internal_market',\n",
              " 'information_society',\n",
              " 'information_society']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "metadata": {
        "id": "pM9HlQnrpOev",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# TEST DATA\n",
        "cluster_1_data_test = []\n",
        "cluster_1_doc_id_test = []\n",
        "cluster_1_label_test = []\n",
        "cluster_1_multilabel_test = []\n",
        "cluster_1_file_name_test = []\n",
        "\n",
        "\n",
        "root_test_data = []\n",
        "root_test_label = []\n",
        "root_test_doc_id = []\n",
        "root_test_file_name = []\n",
        "root_test_multilabel = []\n",
        "\n",
        "cluster_2_data_test = []\n",
        "cluster_2_doc_id_test = []\n",
        "cluster_2_label_test = []\n",
        "cluster_2_multilabel_test = []\n",
        "cluster_2_file_name_test = []\n",
        "\n",
        "# for statistics\n",
        "count_cluster_1_test = 0\n",
        "count_cluster_2_test = 0\n",
        "count_root_test = 0\n",
        "# we will just divide the train data and labels\n",
        "\n",
        "for combine_doc, label in zip(test_data, test_la):\n",
        "    if label == 'content':\n",
        "        pass\n",
        "    elif label in cluster_1_info:\n",
        "        count_cluster_1_test +=1\n",
        "        count_root_test +=1\n",
        "        cluster_1_data_test.append(combine_doc.split('\\n\\n\\n')[0])\n",
        "        cluster_1_data_test.append(combine_doc.split('\\n\\n\\n')[1])\n",
        "        cluster_1_label_test.append(label)\n",
        "        \n",
        "        cluster_1_multilabel_test.append(combine_doc.split('\\n\\n\\n')[4])\n",
        "        cluster_1_doc_id_test.append(combine_doc.split('\\n\\n\\n')[3])\n",
        "        cluster_1_file_name_test.append(combine_doc.split('\\n\\n\\n')[2])\n",
        "        cluster_1_label_test.append(label)\n",
        "        \n",
        "        cluster_1_multilabel_test.append(combine_doc.split('\\n\\n\\n')[4])\n",
        "        cluster_1_doc_id_test.append(combine_doc.split('\\n\\n\\n')[3])\n",
        "        cluster_1_file_name_test.append(combine_doc.split('\\n\\n\\n')[2])\n",
        "        \n",
        "        root_test_data.append(combine_doc.split('\\n\\n\\n')[0])\n",
        "        root_test_data.append(combine_doc.split('\\n\\n\\n')[1])\n",
        "        root_test_label.append(1)\n",
        "        root_test_doc_id.append(combine_doc.split('\\n\\n\\n')[3])\n",
        "        root_test_file_name.append(combine_doc.split('\\n\\n\\n')[2])\n",
        "        root_test_multilabel.append(combine_doc.split('\\n\\n\\n')[4])\n",
        "        root_test_label.append(1)\n",
        "        root_test_doc_id.append(combine_doc.split('\\n\\n\\n')[3])\n",
        "        root_test_file_name.append(combine_doc.split('\\n\\n\\n')[2])\n",
        "        root_test_multilabel.append(combine_doc.split('\\n\\n\\n')[4])\n",
        "        \n",
        "    elif label not in cluster_1_info:\n",
        "        count_cluster_2_test +=1\n",
        "        count_root_test +=1\n",
        "        cluster_2_data_test.append(combine_doc.split('\\n\\n\\n')[0])\n",
        "        cluster_2_data_test.append(combine_doc.split('\\n\\n\\n')[1])\n",
        "        cluster_2_label_test.append(label)\n",
        "        cluster_2_multilabel_test.append(combine_doc.split('\\n\\n\\n')[4])\n",
        "        cluster_2_doc_id_test.append(combine_doc.split('\\n\\n\\n')[3])\n",
        "        cluster_2_file_name_test.append(combine_doc.split('\\n\\n\\n')[2])\n",
        "        cluster_2_label_test.append(label)\n",
        "        cluster_2_multilabel_test.append(combine_doc.split('\\n\\n\\n')[4])\n",
        "        cluster_2_doc_id_test.append(combine_doc.split('\\n\\n\\n')[3])\n",
        "        cluster_2_file_name_test.append(combine_doc.split('\\n\\n\\n')[2])\n",
        "        \n",
        "        root_test_data.append(combine_doc.split('\\n\\n\\n')[0])\n",
        "        root_test_data.append(combine_doc.split('\\n\\n\\n')[1])\n",
        "        root_test_label.append(2)\n",
        "        root_test_doc_id.append(combine_doc.split('\\n\\n\\n')[3])\n",
        "        root_test_file_name.append(combine_doc.split('\\n\\n\\n')[2])\n",
        "        root_test_multilabel.append(combine_doc.split('\\n\\n\\n')[4])\n",
        "        root_test_label.append(2)\n",
        "        root_test_doc_id.append(combine_doc.split('\\n\\n\\n')[3])\n",
        "        root_test_file_name.append(combine_doc.split('\\n\\n\\n')[2])\n",
        "        root_test_multilabel.append(combine_doc.split('\\n\\n\\n')[4])\n",
        "        \n",
        "    else:\n",
        "        print('Something wrong')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jk0PhKbOpmlW",
        "colab_type": "code",
        "outputId": "9c65393f-f3cc-4d0f-ae20-e0a17304cd88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "cell_type": "code",
      "source": [
        "# Train statistics\n",
        "print(\"Total docs in cluster 1 train are: {}\".format(len(cluster_1_data)))\n",
        "print(\"Total docs in cluster 2 train are: {}\".format(len(cluster_2_data)))\n",
        "print(\"Total docs in root_classifier train are: {}\".format(len(root_data)))\n",
        "\n",
        "# test statistics\n",
        "print(\"Total docs in cluster 1 test are: {}\".format(len(cluster_1_data_test)))\n",
        "print(\"Total docs in cluster 2 test are: {}\".format(len(cluster_2_data_test)))\n",
        "print(\"Total docs in root test are: {}\".format(len(root_test_data)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total docs in cluster 1 train are: 1980\n",
            "Total docs in cluster 2 train are: 1822\n",
            "Total docs in root_classifier train are: 3802\n",
            "Total docs in cluster 1 test are: 898\n",
            "Total docs in cluster 2 test are: 732\n",
            "Total docs in root test are: 1630\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ifP-d5V936hz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Cluster 1 "
      ]
    },
    {
      "metadata": {
        "id": "Mqdw4S08Gixl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Assiginig numbers to labels"
      ]
    },
    {
      "metadata": {
        "id": "rgeYCckJ36u1",
        "colab_type": "code",
        "outputId": "2f897b31-289c-4eff-95d4-9e158c0331f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 274
        }
      },
      "cell_type": "code",
      "source": [
        "# Assigning numbers to labels of cluster 1 and 2\n",
        "num_label_cluster_1 = dict(list(enumerate(sorted(set(cluster_1_label)))))\n",
        "num_label_cluster_1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'agriculture',\n",
              " 1: 'audiovisual_and_media',\n",
              " 2: 'competition',\n",
              " 3: 'consumers',\n",
              " 4: 'employment_and_social_policy',\n",
              " 5: 'energy',\n",
              " 6: 'enterprise',\n",
              " 7: 'environment',\n",
              " 8: 'food_safety',\n",
              " 9: 'information_society',\n",
              " 10: 'internal_market',\n",
              " 11: 'public_health',\n",
              " 12: 'taxation',\n",
              " 13: 'transport'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "metadata": {
        "id": "XKu-R8NUGonO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Train sentence preparation"
      ]
    },
    {
      "metadata": {
        "id": "jx-tyGFwppHx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Cluster 1 train data, sentence conversion\n",
        "cluster_1_sent_train = []  # List to store the sentence\n",
        "cluster_1_labels_train = [] # List to store the label(alpha)\n",
        "cluster_1_label_num_train = []\n",
        "\n",
        "\n",
        "for first_data, first_label in zip(cluster_1_data,cluster_1_label):\n",
        "    # start chunking the text into 30 words with 10 word slide\n",
        "    slides = slidingWindow(first_data.split(' '),30,10)\n",
        "        \n",
        "    for key,value in num_label_cluster_1.items():\n",
        "        if value == first_label:\n",
        "            num = key\n",
        "    \n",
        "    \n",
        "    for slide in slides:\n",
        "        cluster_1_sent_train.append(' '.join(slide).lower())\n",
        "        cluster_1_labels_train.append(first_label)\n",
        "        cluster_1_label_num_train.append(num)\n",
        "\n",
        "        \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6Z8LX0RgbVE4",
        "colab_type": "code",
        "outputId": "17d381e9-b045-486b-f3d6-e97dc07020ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "len(cluster_1_sent_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "109895"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "metadata": {
        "id": "wtbKz_bJMA7E",
        "colab_type": "code",
        "outputId": "c1daf260-186f-4359-dcaf-9bc1de9e420e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 274
        }
      },
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "Counter(cluster_1_labels_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({'agriculture': 8788,\n",
              "         'audiovisual_and_media': 1501,\n",
              "         'competition': 3119,\n",
              "         'consumers': 8052,\n",
              "         'employment_and_social_policy': 14797,\n",
              "         'energy': 5600,\n",
              "         'enterprise': 4841,\n",
              "         'environment': 10005,\n",
              "         'food_safety': 7652,\n",
              "         'information_society': 14794,\n",
              "         'internal_market': 15409,\n",
              "         'public_health': 3094,\n",
              "         'taxation': 3204,\n",
              "         'transport': 9039})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "metadata": {
        "id": "4D0dmQ9CMBBd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class_weights_cls1 = dict()\n",
        "\n",
        "max_value = max(Counter(cluster_1_labels_train).values())\n",
        "\n",
        "for keys, values in Counter(cluster_1_labels_train).items():\n",
        "    for _keys, _values in num_label_cluster_1.items():\n",
        "        if keys == _values:\n",
        "            class_weights_cls1[_keys] = (max_value/ values)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sVjoYlVoMBAP",
        "colab_type": "code",
        "outputId": "7efc88ea-3d6e-4f96-e8b2-472f916b1f7a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 274
        }
      },
      "cell_type": "code",
      "source": [
        "class_weights_cls1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 1.7534137460172963,\n",
              " 1: 10.265822784810126,\n",
              " 2: 4.940365501763385,\n",
              " 3: 1.913686040735221,\n",
              " 4: 1.0413597350814354,\n",
              " 5: 2.751607142857143,\n",
              " 6: 3.1830200371824002,\n",
              " 7: 1.5401299350324837,\n",
              " 8: 2.0137219027705173,\n",
              " 9: 1.0415709071245098,\n",
              " 10: 1.0,\n",
              " 11: 4.980284421460892,\n",
              " 12: 4.809300873907615,\n",
              " 13: 1.7047239738909172}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "metadata": {
        "id": "-VDkrW7GGvVL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### One hot encoding train and test labels"
      ]
    },
    {
      "metadata": {
        "id": "vwd7rxfUGuo4",
        "colab_type": "code",
        "outputId": "ac2d709b-fb9a-4a04-de38-3dc1b19d1807",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        }
      },
      "cell_type": "code",
      "source": [
        "# Define one_hot_encoder object\n",
        "onehot_encoder = OneHotEncoder(sparse=False)\n",
        "\n",
        "cluster_1_train_label = onehot_encoder.fit_transform(np.reshape(cluster_1_label_num_train,(-1,1)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
            "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
            "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "AzfXxSCNG4HR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Tokenizing train sentences"
      ]
    },
    {
      "metadata": {
        "id": "bczn-grnG4kc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(num_words=50000)\n",
        "tokenizer.fit_on_texts(cluster_1_data)\n",
        "cluster_1_train_sequences = tokenizer.texts_to_sequences(cluster_1_sent_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vvx8HVlOG6kh",
        "colab_type": "code",
        "outputId": "2c3f6236-0892-4c16-86b5-b7ed36128c59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "word_index = tokenizer.word_index\n",
        "vocab_size = len(word_index)+1\n",
        "max_len = 30\n",
        "print('max_length is', max_len)\n",
        "cluster_1_padded_sents = keras.preprocessing.sequence.pad_sequences(cluster_1_train_sequences, maxlen=max_len, padding='post')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "max_length is 30\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0UP3ffY6G-RM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Embedding Matrix creation"
      ]
    },
    {
      "metadata": {
        "id": "FmheThMpG8V9",
        "colab_type": "code",
        "outputId": "8bf96396-56eb-4a0d-95cf-12ee3d4b804f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        }
      },
      "cell_type": "code",
      "source": [
        "# converting embedding matrix into a form that can be used in keras embedding layer\n",
        "embeddings_index = {}\n",
        "# with open(embding_path, 'r') as embpath:\n",
        "#     pretrained_embeding = embpath.readlines()\n",
        "    \n",
        "for i, line in enumerate(en_de):\n",
        "    if i == 0:\n",
        "        pass\n",
        "    else:\n",
        "        try:\n",
        "            values = line.split()\n",
        "            word = values[0]\n",
        "            coefs = np.asarray(values[1:], dtype='float32')\n",
        "            embeddings_index[word] = coefs\n",
        "        except ValueError:\n",
        "            print('Value error: {}'.format(values[1:5]))\n",
        "\n",
        "embedding_matrix = np.zeros((len(word_index) + 1, 300))\n",
        "for word, i in word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        # words not found in embedding index will be all-zeros.\n",
        "        embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Value error: ['·', '-0.116043', '-0.0278416', '0.0375914']\n",
            "Value error: ['—', '-0.000894651', '0.0377289', '-0.0714999']\n",
            "Value error: ['gebäude', '-0.0360703', '-0.0850809', '-0.0597942']\n",
            "Value error: ['waldfläche', '-0.0314779', '-0.0465583', '-0.0163933']\n",
            "Value error: ['verkehrsfläche', '-0.0356581', '-0.0029205', '0.0181392']\n",
            "Value error: ['erholungsfläche', '-0.0368387', '-0.0377135', '0.00746337']\n",
            "Value error: ['landwirtschaftsfläche', '-0.0263421', '-0.046624', '-0.0177181']\n",
            "Value error: ['sonstige_flächen', '-0.0559894', '-0.0219282', '-0.000380597']\n",
            "Value error: ['gesamtfläche', '-0.0660608', '-0.0324034', '0.0221355']\n",
            "Value error: ['wasserfläche', '-0.0588425', '-0.0477398', '-0.0339936']\n",
            "Value error: ['•', '-0.0626246', '-0.0190532', '-0.0432283']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "tCdLGiPM0UYL",
        "colab_type": "code",
        "outputId": "5dbd663c-0505-42e4-8059-3daf0261e199",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "print('shape embedding matrix: {}'.format(embedding_matrix.shape))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shape embedding matrix: (43339, 300)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "IMJwatXBCp1I",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### One Hot Encoding Labels\n",
        "\n",
        "The numerical labels needs to be converted into its one hot encoded form."
      ]
    },
    {
      "metadata": {
        "id": "MNegok1-HTY5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Callbacks\n"
      ]
    },
    {
      "metadata": {
        "id": "Is61FoE5HAeo",
        "colab_type": "code",
        "outputId": "19ea6c3f-4266-48b3-98c0-8d82da3edaa1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "# Other callbacks \n",
        "reduce_rate = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=0, verbose=1, \n",
        "                                                mode='auto', epsilon=0.0001, cooldown=0, min_lr=0)\n",
        "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, \n",
        "                                           patience=3, verbose=1, mode='auto')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/callbacks.py:1065: UserWarning: `epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
            "  warnings.warn('`epsilon` argument is deprecated and '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "07UMP2sQ4j62",
        "colab_type": "code",
        "outputId": "dd83722c-85f4-41f6-f46f-2eafa99de867",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        }
      },
      "cell_type": "code",
      "source": [
        "learning_rate = 0.001\n",
        "optimizer = keras.optimizers.RMSprop(lr=learning_rate, rho=0.9, epsilon=None, decay=0.0)\n",
        "#optimizer = keras.optimizers.Adam(lr=learning_rate, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "J4RzVNho_7dD",
        "colab_type": "code",
        "outputId": "29f81aa2-fafb-4e47-9a6e-02b6724a8d9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        }
      },
      "cell_type": "code",
      "source": [
        "# Cluster 1 test data, sentence conversion\n",
        "cluster_1_sent_test = []  # List to store the sentence\n",
        "cluster_1_labels_test = [] # List to store the label(alpha)\n",
        "cluster_1_label_num_test = []\n",
        "\n",
        "\n",
        "for first_data, first_label in zip(cluster_1_data_test, cluster_1_label_test):\n",
        "    # start chunking the text into 30 words with 10 word slide\n",
        "    slides = slidingWindow(first_data.split(' '),30,10)\n",
        "        \n",
        "    for key,value in num_label_cluster_1.items():\n",
        "        if value == first_label:\n",
        "            num = key\n",
        "    \n",
        "    \n",
        "    for slide in slides:\n",
        "        cluster_1_sent_test.append(' '.join(slide).lower())\n",
        "        cluster_1_labels_test.append(first_label)\n",
        "        cluster_1_label_num_test.append(num)\n",
        "\n",
        "cluster_1_test_label = onehot_encoder.fit_transform(np.reshape(cluster_1_label_num_test,(-1,1)))\n",
        "cluster_1_test_sequences = tokenizer.texts_to_sequences(cluster_1_sent_test)\n",
        "# Testing the data\n",
        "cluster_1_padded_sents_test = keras.preprocessing.sequence.pad_sequences(cluster_1_test_sequences, maxlen=max_len, padding='post')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
            "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
            "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "EPTWgxMHHbGM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Training"
      ]
    },
    {
      "metadata": {
        "id": "0pHqyBnrHaBy",
        "colab_type": "code",
        "outputId": "4a42713b-eb57-476b-bd76-8ec2d729ca54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 974
        }
      },
      "cell_type": "code",
      "source": [
        "# Create sequential model\n",
        "model = Sequential()\n",
        "model.add(emb(vocab_size, 300, weights=[embedding_matrix], input_length=30, trainable=True))   \n",
        "model.add(Bidirectional(LSTM(40, activation='tanh',return_sequences=True, kernel_regularizer=keras.regularizers.l2(0.04))))# LSTM layer \n",
        "model.add(keras.layers.Dropout(0.5))\n",
        "model.add(Bidirectional(LSTM(40, activation='tanh',return_sequences=False, kernel_regularizer=keras.regularizers.l2(0.01))))\n",
        "model.add(keras.layers.Dropout(0.5))\n",
        "model.add(Dense(14, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer= optimizer, metrics=['accuracy'])\n",
        "print(model.summary())\n",
        "model.fit(cluster_1_padded_sents, cluster_1_train_label, validation_data=(cluster_1_padded_sents_test,cluster_1_test_label), epochs=20, batch_size=32, \n",
        "          verbose=1, callbacks=[reduce_rate,early_stop])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 30, 300)           13001700  \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 30, 80)            109120    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 30, 80)            0         \n",
            "_________________________________________________________________\n",
            "bidirectional_2 (Bidirection (None, 80)                38720     \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 80)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 14)                1134      \n",
            "=================================================================\n",
            "Total params: 13,150,674\n",
            "Trainable params: 13,150,674\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train on 109895 samples, validate on 48781 samples\n",
            "Epoch 1/20\n",
            "109895/109895 [==============================] - 868s 8ms/step - loss: 2.0834 - acc: 0.3546 - val_loss: 2.0812 - val_acc: 0.4021\n",
            "Epoch 2/20\n",
            "109895/109895 [==============================] - 860s 8ms/step - loss: 1.2808 - acc: 0.6301 - val_loss: 1.8953 - val_acc: 0.4778\n",
            "Epoch 3/20\n",
            "109895/109895 [==============================] - 852s 8ms/step - loss: 1.0546 - acc: 0.7096 - val_loss: 1.9887 - val_acc: 0.4852\n",
            "\n",
            "Epoch 00003: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "Epoch 4/20\n",
            "109895/109895 [==============================] - 846s 8ms/step - loss: 0.8118 - acc: 0.7864 - val_loss: 1.8172 - val_acc: 0.5247\n",
            "Epoch 5/20\n",
            "109895/109895 [==============================] - 862s 8ms/step - loss: 0.7631 - acc: 0.7980 - val_loss: 1.8561 - val_acc: 0.5286\n",
            "\n",
            "Epoch 00005: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "Epoch 6/20\n",
            "109895/109895 [==============================] - 860s 8ms/step - loss: 0.7233 - acc: 0.8102 - val_loss: 1.8425 - val_acc: 0.5322\n",
            "\n",
            "Epoch 00006: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
            "Epoch 7/20\n",
            "109895/109895 [==============================] - 862s 8ms/step - loss: 0.7165 - acc: 0.8126 - val_loss: 1.8405 - val_acc: 0.5327\n",
            "\n",
            "Epoch 00007: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
            "Epoch 00007: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2b5dc689b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "metadata": {
        "id": "ApFDb0nU3baR",
        "colab_type": "code",
        "outputId": "3289be69-0d80-4edd-f242-25437978c31c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "model.evaluate(cluster_1_padded_sents_test, cluster_1_test_label)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "48781/48781 [==============================] - 41s 831us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.8404504770438967, 0.5327484061432629]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "metadata": {
        "id": "PKDB_PCQprMM",
        "colab_type": "code",
        "outputId": "e5975cb8-24ee-409b-eee3-4e2e43d4af58",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "cluster_1_padded_sents_test[0].shape, cluster_1_test_label[0].shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((30,), (14,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "metadata": {
        "id": "4kfJ56HSAMgX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Test Data Preparation\n"
      ]
    },
    {
      "metadata": {
        "id": "2knH3IVOH6hy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Evaluation"
      ]
    },
    {
      "metadata": {
        "id": "1i5UgxsFAHlD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Cluster 1 test data, sentence conversion\n",
        "from sklearn.preprocessing import MinMaxScaler, Normalizer, StandardScaler\n",
        "\n",
        "doc_id_pred = []\n",
        "file_name_pred = []\n",
        "multi_label_pred = []\n",
        "pred_one_hot_encoded = []\n",
        "label_one_hot_encoded = []\n",
        "prd_for_doc = []\n",
        "\n",
        "original_label = []\n",
        "predicted_label = []\n",
        "\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "from collections import Counter \n",
        "\n",
        "\n",
        "counter = 0\n",
        "for first_data, first_label, _doc_id, _multi, _file_name in zip(cluster_1_data_test, cluster_1_label_test, \n",
        "                                   cluster_1_doc_id_test,cluster_1_multilabel_test,\n",
        "                                   cluster_1_file_name_test ):\n",
        "    \n",
        "    ## TMP LIST for each doc\n",
        "    sent_pred = []\n",
        "    \n",
        "    # start chunking the text into 30 words with 10 word slide\n",
        "    slides = slidingWindow(first_data.split(' '),30,10)\n",
        "        \n",
        "    for key,value in num_label_cluster_1.items():\n",
        "        if value == first_label:\n",
        "            num = key\n",
        "    \n",
        "    doc_sent = []\n",
        "    for slide in slides:\n",
        "        \n",
        "        a = ' '.join(slide).lower()\n",
        "        \n",
        "        doc_sent.append(a)\n",
        "        \n",
        "    # we have the slide here, create the sequence from text to numbers\n",
        "    text_sequence = tokenizer.texts_to_sequences(doc_sent)\n",
        "\n",
        "\n",
        "    # pad it to make flat 30 lenght\n",
        "    text_padded = keras.preprocessing.sequence.pad_sequences(text_sequence, maxlen=30, padding='post')\n",
        "\n",
        "    # Convert the label for this into one hot encoding\n",
        "    label_one_hot = onehot_encoder.fit_transform(np.reshape(num,(1,-1)))\n",
        "\n",
        "    # predict the label\n",
        "    sent_pred.append(model.predict(text_padded))        \n",
        "\n",
        "    nor_data = []\n",
        "    for predc in sent_pred:\n",
        "        transformer2 = Normalizer().fit(predc)\n",
        "        nor_data.append(transformer2.transform(predc))    \n",
        "        \n",
        "    sent = np.zeros(14)\n",
        "    for sen in nor_data:\n",
        "        for i in range(len(sen)):\n",
        "            sent += sen[i]\n",
        "    \n",
        "    predicted_label.append(np.argmax(sent, axis=0))\n",
        "    original_label.append(num)\n",
        "\n",
        "    label_one_hot_encoded.append(num)\n",
        "    doc_id_pred.append(_doc_id)\n",
        "    file_name_pred.append(_file_name)\n",
        "    multi_label_pred.append(_multi)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RKYSghbgHcsn",
        "colab_type": "code",
        "outputId": "bde31801-a424-45f8-99de-34337d2e151e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "accuracy_score(original_label, predicted_label)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7828507795100222"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "metadata": {
        "id": "3TVNFRX7J_wz",
        "colab_type": "code",
        "outputId": "a258c237-a810-4c37-eb29-0caa6508096c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 274
        }
      },
      "cell_type": "code",
      "source": [
        "Counter(original_label)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({0: 50,\n",
              "         1: 10,\n",
              "         2: 30,\n",
              "         3: 74,\n",
              "         4: 94,\n",
              "         5: 56,\n",
              "         6: 26,\n",
              "         7: 88,\n",
              "         8: 76,\n",
              "         9: 80,\n",
              "         10: 148,\n",
              "         11: 44,\n",
              "         12: 28,\n",
              "         13: 94})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "metadata": {
        "id": "IN5dJzbgHC8L",
        "colab_type": "code",
        "outputId": "4065325f-d8b2-4b21-9908-9760f4f6b093",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 531
        }
      },
      "cell_type": "code",
      "source": [
        "confusion_matrix(original_label, predicted_label)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 40,   0,   0,   4,   2,   0,   0,   2,   2,   0,   0,   0,   0,\n",
              "          0],\n",
              "       [  0,   0,   1,   0,   0,   0,   3,   0,   0,   6,   0,   0,   0,\n",
              "          0],\n",
              "       [  0,   0,  25,   2,   0,   0,   0,   0,   0,   0,   1,   0,   0,\n",
              "          2],\n",
              "       [  2,   0,   0,  48,   1,   0,   0,   0,   6,   0,  13,   0,   0,\n",
              "          4],\n",
              "       [  0,   0,   0,   0,  81,   0,   2,   0,   0,   2,   8,   1,   0,\n",
              "          0],\n",
              "       [  2,   0,   0,   1,   2,  40,   0,   7,   0,   1,   1,   0,   0,\n",
              "          2],\n",
              "       [  2,   0,   0,   1,   2,   1,   9,   3,   0,   4,   4,   0,   0,\n",
              "          0],\n",
              "       [  2,   0,   0,   1,   0,   0,   0,  78,   2,   0,   1,   0,   0,\n",
              "          4],\n",
              "       [  1,   0,   0,   4,   0,   0,   0,   2,  66,   0,   3,   0,   0,\n",
              "          0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  72,   5,   0,   0,\n",
              "          3],\n",
              "       [  0,   0,   0,  11,   8,   0,   0,   0,   0,   7, 119,   1,   0,\n",
              "          2],\n",
              "       [  0,   0,   2,   2,  13,   0,   0,   0,   2,   0,   1,  23,   1,\n",
              "          0],\n",
              "       [  0,   0,   0,   0,   5,   0,   0,   0,   1,   1,   1,   0,  18,\n",
              "          2],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   5,   0,   2,   3,   0,   0,\n",
              "         84]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "metadata": {
        "id": "ppjTeB_oGm7i",
        "colab_type": "code",
        "outputId": "6761901c-97c2-4496-b4cd-990a6d72eefc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "cell_type": "code",
      "source": [
        "print(classification_report(original_label, predicted_label))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.80      0.81        50\n",
            "           1       0.00      0.00      0.00        10\n",
            "           2       0.89      0.83      0.86        30\n",
            "           3       0.65      0.65      0.65        74\n",
            "           4       0.71      0.86      0.78        94\n",
            "           5       0.98      0.71      0.82        56\n",
            "           6       0.64      0.35      0.45        26\n",
            "           7       0.80      0.89      0.84        88\n",
            "           8       0.84      0.87      0.85        76\n",
            "           9       0.76      0.90      0.82        80\n",
            "          10       0.74      0.80      0.77       148\n",
            "          11       0.92      0.52      0.67        44\n",
            "          12       0.95      0.64      0.77        28\n",
            "          13       0.82      0.89      0.85        94\n",
            "\n",
            "   micro avg       0.78      0.78      0.78       898\n",
            "   macro avg       0.75      0.69      0.71       898\n",
            "weighted avg       0.78      0.78      0.77       898\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "3k3VzYoQH53h",
        "colab_type": "code",
        "outputId": "01f0dfdc-428e-4774-8603-89247424b5d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1027
        }
      },
      "cell_type": "code",
      "source": [
        "scores = model.evaluate(cluster_1_padded_sents_test, cluster_1_test_label, verbose=1)\n",
        "print(\"Accuracy: %.2f%%\" % (scores[1]*100))\n",
        "# Classification Report (Precision, Recall and F1-Score)\n",
        "\n",
        "\n",
        "y_true = np.argmax(cluster_1_test_label, axis=1)\n",
        "y_pred = np.argmax(model.predict(cluster_1_padded_sents_test),axis=1)\n",
        "classificationReport = classification_report(y_true, y_pred)\n",
        "\n",
        "print(classificationReport)\n",
        "\n",
        "conf = confusion_matrix(y_true, y_pred)\n",
        "seaborn.heatmap(conf)\n",
        "print(confusion_matrix(y_true, y_pred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "48781/48781 [==============================] - 40s 823us/step\n",
            "Accuracy: 53.27%\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.63      0.59      0.61      4421\n",
            "           1       0.41      0.06      0.11       719\n",
            "           2       0.38      0.45      0.41      1651\n",
            "           3       0.36      0.44      0.40      3339\n",
            "           4       0.57      0.68      0.62      5064\n",
            "           5       0.57      0.46      0.50      2702\n",
            "           6       0.23      0.30      0.26      1330\n",
            "           7       0.51      0.56      0.54      4149\n",
            "           8       0.65      0.61      0.63      3657\n",
            "           9       0.55      0.63      0.59      5052\n",
            "          10       0.53      0.53      0.53      7712\n",
            "          11       0.60      0.32      0.42      2492\n",
            "          12       0.53      0.36      0.43      1186\n",
            "          13       0.61      0.57      0.59      5307\n",
            "\n",
            "   micro avg       0.53      0.53      0.53     48781\n",
            "   macro avg       0.51      0.47      0.47     48781\n",
            "weighted avg       0.54      0.53      0.53     48781\n",
            "\n",
            "[[2621    1  212  266   98   83   57  280  396   71  168   31   80   57]\n",
            " [   3   45   50   11  103   10  135    0    4  259   54   19   13   13]\n",
            " [ 112    0  739  138   58   39   36   50   47   62  147   48   52  123]\n",
            " [ 118    0   94 1485  102   24   17  143  367   61  605    3    3  317]\n",
            " [ 103   11  105   95 3428   69  193   77   14  309  416  153   36   55]\n",
            " [ 192    2   31   67   79 1230  146  426   13  181  161   11   17  146]\n",
            " [ 107    3   34   37  108  116  395  106   28  190  152    9   17   28]\n",
            " [ 299    1   62  207   69  189  105 2321  154  127  245   12   21  337]\n",
            " [ 260    1  136  525   26    3   12  205 2236    9  150   38   10   46]\n",
            " [  38    7   27   74  288  133  250   96    7 3196  630   17   11  278]\n",
            " [ 103    9  161  756  666  102  189  196   74  825 4061   89   51  430]\n",
            " [  55   21  191  169  780   12   66   40   62   62  146  797   70   21]\n",
            " [  66    8   77   33  126   26   54   40   21   52  113   87  431   52]\n",
            " [  84    0   38  259  100  136   59  528   24  414  651    8    3 3003]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAccAAAFKCAYAAABo0pS0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAA8UBwBAPBAcQQAwMP/Az9xlPfj37JWAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 576x396 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "KAXATl5DLuNm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Cluster 2"
      ]
    },
    {
      "metadata": {
        "id": "pcJJw8T-L4D4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Assigning numbers to labels"
      ]
    },
    {
      "metadata": {
        "id": "JvgXk-4hHZOB",
        "colab_type": "code",
        "outputId": "962f997c-0c51-463e-8a20-a8a4e618b331",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        }
      },
      "cell_type": "code",
      "source": [
        "num_label_cluster_2 = dict(list(enumerate(sorted(set(cluster_2_label)))))\n",
        "num_label_cluster_2\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'budget',\n",
              " 1: 'culture',\n",
              " 2: 'customs',\n",
              " 3: 'development',\n",
              " 4: 'economic_and_monetary_affairs',\n",
              " 5: 'education_training_youth',\n",
              " 6: 'enlargement',\n",
              " 7: 'external_relations',\n",
              " 8: 'external_trade',\n",
              " 9: 'fight_against_fraud',\n",
              " 10: 'foreign_and_security_policy',\n",
              " 11: 'human_rights',\n",
              " 12: 'humanitarian_aid',\n",
              " 13: 'institutional_affairs',\n",
              " 14: 'justice_freedom_security',\n",
              " 15: 'maritime_affairs_and_fisheries',\n",
              " 16: 'regional_policy',\n",
              " 17: 'research_innovation'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "metadata": {
        "id": "GEckdQiwMGah",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Tain sentence preparation"
      ]
    },
    {
      "metadata": {
        "id": "JkpvvKX1MDEF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Cluster 2 train data, sentence conversion\n",
        "cluster_2_sent_train = []  # List to store the sentence\n",
        "cluster_2_labels_train = [] # List to store the label(alpha)\n",
        "cluster_2_label_num_train = []\n",
        "\n",
        "\n",
        "for second_data, second_label in zip(cluster_2_data, cluster_2_label):\n",
        "    # start chunking the text into 30 words with 10 word slide\n",
        "    slides = slidingWindow(second_data.split(' '),30,10)\n",
        "        \n",
        "    for key,value in num_label_cluster_2.items():\n",
        "        if value == second_label:\n",
        "            num = key\n",
        "    \n",
        "    \n",
        "    for slide in slides:\n",
        "        cluster_2_sent_train.append(' '.join(slide).lower())\n",
        "        cluster_2_labels_train.append(second_label)\n",
        "        cluster_2_label_num_train.append(num)\n",
        "        \n",
        "# Cluster 2 test data        \n",
        "cluster_2_sent_test = []  # List to store the sentence\n",
        "cluster_2_labels_test = [] # List to store the label(alpha)\n",
        "cluster_2_label_num_test = []\n",
        "\n",
        "\n",
        "for second_data, second_label in zip(cluster_2_data_test, cluster_2_label_test):\n",
        "    # start chunking the text into 30 words with 10 word slide\n",
        "    slides = slidingWindow(second_data.split(' '),30,10)\n",
        "        \n",
        "    for key,value in num_label_cluster_2.items():\n",
        "        if value == second_label:\n",
        "            num = key\n",
        "    \n",
        "    \n",
        "    for slide in slides:\n",
        "        cluster_2_sent_test.append(' '.join(slide).lower())\n",
        "        cluster_2_labels_test.append(second_label)\n",
        "        cluster_2_label_num_test.append(num)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QxK8Pqb_AUv2",
        "colab_type": "code",
        "outputId": "a05d3621-e33e-411e-d711-8663eba2d962",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "cluster_2_labels_train[500], cluster_2_label_num_train[500]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('fight_against_fraud', 9)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "metadata": {
        "id": "Cp9xlfrLtYo-",
        "colab_type": "code",
        "outputId": "89417eda-f041-4835-c308-a786887ea276",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "cluster_2_labels_test[500], cluster_2_label_num_test[500]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('regional_policy', 16)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "metadata": {
        "id": "biUqoc1VA9xa",
        "colab_type": "code",
        "outputId": "9f380e91-5182-4fc7-c85a-7a3711d2dded",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "cell_type": "code",
      "source": [
        "cluster_2_sent_train[1], cluster_2_sent_test[1]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('withdraw refugee status this directive lay minimum standard procedure grant withdraw refugee status order reduce disparity national examine procedure safeguard quality decision make european-union eu-country act council-directive december minimum standard',\n",
              " 'group expert responsible advise commission matter relate traffic human being exist since pron composition operation regularly adjust accordance development take place field within european-union eu-act commission-decision eu august set group')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "metadata": {
        "id": "lOCPUGsAMNVD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Tokenizing train sentences & one hot encoding train test labels"
      ]
    },
    {
      "metadata": {
        "id": "9iY3p8HjMIgM",
        "colab_type": "code",
        "outputId": "a10db1ae-326e-405c-d457-65290f28da32",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        }
      },
      "cell_type": "code",
      "source": [
        "# tokenizing cluster 2 sents\n",
        "tokenizer_cls2 = Tokenizer()\n",
        "tokenizer_cls2.fit_on_texts(cluster_2_data)\n",
        "cluster_2_train_sequences = tokenizer_cls2.texts_to_sequences(cluster_2_sent_train)\n",
        "cluster_2_test_sequences = tokenizer_cls2.texts_to_sequences(cluster_2_sent_test)\n",
        "\n",
        "# padding the sentences\n",
        "cluster_2_padded_sents = keras.preprocessing.sequence.pad_sequences(cluster_2_train_sequences, maxlen=30, padding='post')\n",
        "cluster_2_padded_sents_test = keras.preprocessing.sequence.pad_sequences(cluster_2_test_sequences, maxlen=30, padding='post')\n",
        "\n",
        "# checking vocab size\n",
        "word_index_cls2 = tokenizer_cls2.word_index\n",
        "vocab_size_cls2 = len(word_index_cls2)+1\n",
        "onehot_encoder = OneHotEncoder(sparse=False)\n",
        "\n",
        "onehot_encoder.fit(np.reshape(cluster_2_label_num_train,(-1,1)))\n",
        "\n",
        "cluster_2_train_label = onehot_encoder.transform(np.reshape(cluster_2_label_num_train,(-1,1)))\n",
        "cluster_2_test_label = onehot_encoder.transform(np.reshape(cluster_2_label_num_test,(-1,1)))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
            "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
            "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "kq5Wv4LKA42h",
        "colab_type": "code",
        "outputId": "7b808c75-8d4b-4110-b38e-bc9ed71522dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "cell_type": "code",
      "source": [
        "cluster_2_padded_sents[1], cluster_2_padded_sents_test[1]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([  76,  170,  367,  969,  362,  141,  464, 2027, 1105,  658,  209,\n",
              "         430, 4710,   29, 1127,  141, 1282,  404,   46,   78,   10,   20,\n",
              "           3,   15,   87,   28,  170,  252,  969,  362], dtype=int32),\n",
              " array([5012,   21,  435,  178, 1093,  270, 2290,  672,  311,   35, 2625,\n",
              "         284, 2467, 3785,  803,   68,   91,  395,  251,  206,   10,   20,\n",
              "           3,   87,   21,   46,    3, 1189,  111,  378], dtype=int32))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "metadata": {
        "id": "w0nE9TMBs_C6",
        "colab_type": "code",
        "outputId": "3a1eeaf7-fce7-4bb4-82ee-58bd02778c8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "len(cluster_2_train_sequences), len(cluster_2_train_label)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(111649, 111649)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "metadata": {
        "id": "cN7ASuyXcPif",
        "colab_type": "code",
        "outputId": "4e348977-69f6-40d4-daae-021cf90819ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "cluster_2_train_label[1]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
              "       0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "metadata": {
        "id": "7-FPFfCwMVFK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Embedding Matrix creation"
      ]
    },
    {
      "metadata": {
        "id": "39cGLW65MQLq",
        "colab_type": "code",
        "outputId": "d7316190-3db1-4617-98e4-045ab530a0e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        }
      },
      "cell_type": "code",
      "source": [
        "# converting embedding matrix into a form that can be used in keras embedding layer\n",
        "embeddings_index_cls2 = {}\n",
        "\n",
        "for i, line in enumerate(en_de):\n",
        "    if i == 0:\n",
        "        pass\n",
        "    else:\n",
        "        try:\n",
        "            values = line.split()\n",
        "            word = values[0]\n",
        "            coefs = np.asarray(values[1:], dtype='float32')\n",
        "            embeddings_index_cls2[word] = coefs\n",
        "        except ValueError:\n",
        "            print('Value error: {}'.format(values[1:5]))\n",
        "\n",
        "# preparing embedding matrix for cluster 2\n",
        "embedding_matrix_cls2 = np.zeros((len(word_index_cls2) + 1, 300))\n",
        "for word, i in word_index_cls2.items():\n",
        "    embedding_vector = embeddings_index_cls2.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        # words not found in embedding index will be all-zeros.\n",
        "        embedding_matrix_cls2[i] = embedding_vector"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Value error: ['·', '-0.116043', '-0.0278416', '0.0375914']\n",
            "Value error: ['—', '-0.000894651', '0.0377289', '-0.0714999']\n",
            "Value error: ['gebäude', '-0.0360703', '-0.0850809', '-0.0597942']\n",
            "Value error: ['waldfläche', '-0.0314779', '-0.0465583', '-0.0163933']\n",
            "Value error: ['verkehrsfläche', '-0.0356581', '-0.0029205', '0.0181392']\n",
            "Value error: ['erholungsfläche', '-0.0368387', '-0.0377135', '0.00746337']\n",
            "Value error: ['landwirtschaftsfläche', '-0.0263421', '-0.046624', '-0.0177181']\n",
            "Value error: ['sonstige_flächen', '-0.0559894', '-0.0219282', '-0.000380597']\n",
            "Value error: ['gesamtfläche', '-0.0660608', '-0.0324034', '0.0221355']\n",
            "Value error: ['wasserfläche', '-0.0588425', '-0.0477398', '-0.0339936']\n",
            "Value error: ['•', '-0.0626246', '-0.0190532', '-0.0432283']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xDBOd2P6vJJ1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "class_weights_cls2 = dict()\n",
        "\n",
        "max_value = max(Counter(cluster_2_labels_train).values())\n",
        "\n",
        "for keys, values in Counter(cluster_2_labels_train).items():\n",
        "    for _keys, _values in num_label_cluster_2.items():\n",
        "        if keys == _values:\n",
        "            class_weights_cls2[_keys] = (max_value/ values)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "88ZZBxqjClMe",
        "colab_type": "code",
        "outputId": "adb3fb60-74fb-45ad-9da5-b4f511d72c59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        }
      },
      "cell_type": "code",
      "source": [
        "class_weights_cls2"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 10.20210993892282,\n",
              " 1: 10.481460353679406,\n",
              " 2: 6.056031641397495,\n",
              " 3: 3.330433206452782,\n",
              " 4: 1.1814557613168724,\n",
              " 5: 2.026916712630998,\n",
              " 6: 2.7898572730033404,\n",
              " 7: 3.387536873156342,\n",
              " 8: 3.5341411809963454,\n",
              " 9: 8.115724381625443,\n",
              " 10: 4.914148167959348,\n",
              " 11: 6.483415666901905,\n",
              " 12: 7.885836909871244,\n",
              " 13: 1.7701348747591523,\n",
              " 14: 1.0,\n",
              " 15: 2.146244597593739,\n",
              " 16: 4.205539024948501,\n",
              " 17: 3.775220875282515}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "metadata": {
        "id": "7JqlQq0q_vsX",
        "colab_type": "code",
        "outputId": "02870127-e872-46ed-9038-782f85c891ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        }
      },
      "cell_type": "code",
      "source": [
        "learning_rate_2 = 0.01\n",
        "optimizer_2 = keras.optimizers.RMSprop(lr=learning_rate_2, rho=0.9, epsilon=None, decay=0.0)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2mEKGliGMZNH",
        "colab_type": "code",
        "outputId": "f8155ffb-0bda-4f13-cca5-6625b9bd0682",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 807
        }
      },
      "cell_type": "code",
      "source": [
        "# Create sequential model_cls2\n",
        "model_cls2 = Sequential()\n",
        "model_cls2.add(emb(vocab_size_cls2, 300, weights=[embedding_matrix_cls2], input_length=30, trainable=True))   \n",
        "model_cls2.add(Bidirectional(LSTM(40, activation='tanh',return_sequences=True, kernel_regularizer=keras.regularizers.l2(0.04))))# LSTM layer \n",
        "model_cls2.add(keras.layers.Dropout(0.3))\n",
        "model_cls2.add(Bidirectional(LSTM(40, activation='tanh',return_sequences=False, kernel_regularizer=keras.regularizers.l2(0.01))))\n",
        "model_cls2.add(keras.layers.Dropout(0.3))\n",
        "model_cls2.add(Dense(18, activation='softmax'))\n",
        "model_cls2.compile(loss='categorical_crossentropy', optimizer = optimizer_2, metrics=['accuracy'])\n",
        "print(model_cls2.summary())\n",
        "model_cls2.fit(cluster_2_padded_sents, cluster_2_train_label, validation_split=0.3, epochs=50, batch_size=32, \n",
        "          verbose=1, callbacks=[reduce_rate,early_stop])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, 30, 300)           11797200  \n",
            "_________________________________________________________________\n",
            "bidirectional_3 (Bidirection (None, 30, 80)            109120    \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 30, 80)            0         \n",
            "_________________________________________________________________\n",
            "bidirectional_4 (Bidirection (None, 80)                38720     \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 80)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 18)                1458      \n",
            "=================================================================\n",
            "Total params: 11,946,498\n",
            "Trainable params: 11,946,498\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Train on 78154 samples, validate on 33495 samples\n",
            "Epoch 1/50\n",
            "78154/78154 [==============================] - 629s 8ms/step - loss: 2.2062 - acc: 0.4039 - val_loss: 2.1731 - val_acc: 0.4149\n",
            "Epoch 2/50\n",
            "78154/78154 [==============================] - 626s 8ms/step - loss: 1.3382 - acc: 0.6259 - val_loss: 2.2464 - val_acc: 0.4244\n",
            "\n",
            "Epoch 00002: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
            "Epoch 3/50\n",
            "78154/78154 [==============================] - 625s 8ms/step - loss: 0.9403 - acc: 0.7527 - val_loss: 2.0233 - val_acc: 0.4897\n",
            "Epoch 4/50\n",
            "78154/78154 [==============================] - 624s 8ms/step - loss: 0.8477 - acc: 0.7767 - val_loss: 2.0462 - val_acc: 0.4991\n",
            "\n",
            "Epoch 00004: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n",
            "Epoch 5/50\n",
            "78154/78154 [==============================] - 626s 8ms/step - loss: 0.7788 - acc: 0.7997 - val_loss: 2.0479 - val_acc: 0.4960\n",
            "\n",
            "Epoch 00005: ReduceLROnPlateau reducing learning rate to 9.99999883788405e-07.\n",
            "Epoch 6/50\n",
            "78154/78154 [==============================] - 626s 8ms/step - loss: 0.7671 - acc: 0.8025 - val_loss: 2.0480 - val_acc: 0.4978\n",
            "\n",
            "Epoch 00006: ReduceLROnPlateau reducing learning rate to 9.99999883788405e-08.\n",
            "Epoch 00006: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe480a606d8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "metadata": {
        "id": "DRCCDRvW66yn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Evaluation\n"
      ]
    },
    {
      "metadata": {
        "id": "e7wu5EtCMexV",
        "colab_type": "code",
        "outputId": "3b811ddd-9467-456f-e97a-a270c9735efc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1504
        }
      },
      "cell_type": "code",
      "source": [
        "# Testing the data\n",
        "model_cls2.save('my_method_cluster_2_model_FB_MUSE_trainableTrue.h5')  # creates a HDF5 file 'my_model.h5'\n",
        "\n",
        "#cluster_2_test_sequences = tokenizer_cls2.texts_to_sequences(cluster_2_sent_test)\n",
        "cluster_2_padded_sents_test = keras.preprocessing.sequence.pad_sequences(cluster_2_test_sequences, maxlen=30, padding='post')\n",
        "\n",
        "scores_cls2 = model_cls2.evaluate(cluster_2_padded_sents_test, cluster_2_test_label, verbose=1)\n",
        "print(\"Accuracy: %.2f%%\" % (scores_cls2[1]*100))\n",
        "\n",
        "y_true = np.argmax(cluster_2_test_label, axis=1)\n",
        "y_pred = np.argmax(model_cls2.predict(cluster_2_padded_sents_test),axis=1)\n",
        "classificationReport_cls2 = classification_report(y_true, y_pred)\n",
        "\n",
        "print(classificationReport_cls2)\n",
        "\n",
        "\n",
        "conf_cls2 = confusion_matrix(y_true, y_pred)\n",
        "seaborn.heatmap(conf_cls2)\n",
        "print(confusion_matrix(y_true, y_pred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "47157/47157 [==============================] - 39s 835us/step\n",
            "Accuracy: 49.87%\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.39      0.17      0.24      1139\n",
            "           1       0.33      0.27      0.30       652\n",
            "           2       0.51      0.30      0.38      1964\n",
            "           3       0.35      0.46      0.40      1986\n",
            "           4       0.76      0.79      0.78      6914\n",
            "           5       0.60      0.73      0.66      3027\n",
            "           6       0.31      0.30      0.31      2462\n",
            "           7       0.26      0.23      0.24      2793\n",
            "           8       0.31      0.35      0.33      1451\n",
            "           9       0.26      0.13      0.18       840\n",
            "          10       0.26      0.29      0.27      1061\n",
            "          11       0.35      0.23      0.27      1417\n",
            "          12       0.74      0.26      0.38      1050\n",
            "          13       0.39      0.49      0.43      3687\n",
            "          14       0.57      0.62      0.60      7592\n",
            "          15       0.56      0.62      0.59      3276\n",
            "          16       0.50      0.40      0.45      4443\n",
            "          17       0.36      0.50      0.42      1403\n",
            "\n",
            "   micro avg       0.50      0.50      0.50     47157\n",
            "   macro avg       0.43      0.40      0.40     47157\n",
            "weighted avg       0.50      0.50      0.49     47157\n",
            "\n",
            "[[ 199   54   22   31  128   39   55   66   51   30    0    5    3  231\n",
            "    50   40   88   47]\n",
            " [  15  177    0   21   14   57  139    2    2    0    1    0    0   47\n",
            "    16    2   74   85]\n",
            " [  15   29  590   34  125   18  162  115  184   57   11   98    0  108\n",
            "   245  106   48   19]\n",
            " [   9   20   29  904   41   49   48  260  118    0   59   19   37   39\n",
            "    59   55  157   83]\n",
            " [  26   19   26   30 5484   87  441   48   35   28    3    0    1  264\n",
            "   105  151  128   38]\n",
            " [   1    4    6   31   58 2209   27   21    2    1   54   17    1   42\n",
            "   209   80  123  141]\n",
            " [  15   36   41   40  326   47  740   59   62   20    6   19    0  186\n",
            "   255  287  260   63]\n",
            " [  16   42   60  504   67   69   40  648  313   12  123   34   12  120\n",
            "   339   75  208  111]\n",
            " [  25   28  101  119   52   20   55  168  501   18   21    8    7  126\n",
            "    73   30   73   26]\n",
            " [   8    1   85   16   34   11   12   82   61  112    9   26    0  157\n",
            "   163   31   20   12]\n",
            " [   3    1   16  101   16   60    6  102   15    1  303   66   13   73\n",
            "   155   14   49   67]\n",
            " [   0    0   30   40   19   52   10  114   11   23  153  319    5  159\n",
            "   419   18   25   20]\n",
            " [   2    7    7  109    6   23    2  115   47    5  184   32  273  114\n",
            "    78    6    9   31]\n",
            " [  52   16   23   48  204  107   17  118   16   38   23   31    1 1818\n",
            "   940   34   60  141]\n",
            " [  38   34  102   80  159  263  125  285   56   87  146  227    9  836\n",
            "  4739  173  125  108]\n",
            " [  65    4   19   49  180  114   77  116   26    5   19    7    0  105\n",
            "   242 2016  201   31]\n",
            " [  23   37    7  347  269  344  378  188   74    1   17    7    3  144\n",
            "   138  446 1784  236]\n",
            " [   2   26    1   50   32  138   51   28   24    0   18    2    5  118\n",
            "    77    9  119  703]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAccAAAFKCAYAAABo0pS0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 576x396 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "WntUbP5k7Km1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Cluster 1 test data, sentence conversion\n",
        "from sklearn.preprocessing import MinMaxScaler, Normalizer, StandardScaler\n",
        "\n",
        "doc_id_pred = []\n",
        "file_name_pred = []\n",
        "multi_label_pred = []\n",
        "pred_one_hot_encoded = []\n",
        "label_one_hot_encoded = []\n",
        "prd_for_doc = []\n",
        "\n",
        "original_label = []\n",
        "predicted_label = []\n",
        "\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "from collections import Counter \n",
        "\n",
        "\n",
        "counter = 0\n",
        "for first_data, first_label, _doc_id, _multi, _file_name in zip(cluster_2_data_test, cluster_2_label_test, \n",
        "                                   cluster_2_doc_id_test,cluster_2_multilabel_test,\n",
        "                                   cluster_2_file_name_test ):\n",
        "    \n",
        "    ## TMP LIST for each doc\n",
        "    sent_pred = []\n",
        "    \n",
        "    # start chunking the text into 30 words with 10 word slide\n",
        "    slides = slidingWindow(first_data.split(' '),30,10)\n",
        "        \n",
        "    for key,value in num_label_cluster_2.items():\n",
        "        if value == first_label:\n",
        "            num = key\n",
        "    \n",
        "    doc_sent = []\n",
        "    for slide in slides:\n",
        "        \n",
        "        a = ' '.join(slide).lower()\n",
        "        \n",
        "        doc_sent.append(a)\n",
        "        \n",
        "    # we have the slide here, create the sequence from text to numbers\n",
        "    text_sequence = tokenizer_cls2.texts_to_sequences(doc_sent)\n",
        "\n",
        "    # pad it to make flat 30 lenght\n",
        "    text_padded = keras.preprocessing.sequence.pad_sequences(text_sequence, maxlen=30, padding='post')\n",
        "\n",
        "    # Convert the label for this into one hot encoding\n",
        "    label_one_hot = onehot_encoder.fit_transform(np.reshape(num,(1,-1)))\n",
        "\n",
        "    # predict the label\n",
        "    sent_pred.append(model_cls2.predict(text_padded))        \n",
        "    \n",
        "\n",
        " \n",
        "    nor_data = []\n",
        "    for predc in sent_pred:\n",
        "        transformer2 = Normalizer().fit(predc)\n",
        "        nor_data.append(transformer2.transform(predc))    \n",
        "        \n",
        "    sent = np.zeros(18)\n",
        "    for sen in nor_data:\n",
        "        for i in range(len(sen)):\n",
        "            sent += sen[i]\n",
        "    \n",
        "    predicted_label.append(np.argmax(sent, axis=0))\n",
        "    original_label.append(num)\n",
        "    \n",
        "   \n",
        "    label_one_hot_encoded.append(num)\n",
        "    doc_id_pred.append(_doc_id)\n",
        "    file_name_pred.append(_file_name)\n",
        "    multi_label_pred.append(_multi)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-8moYg9D7BQ0",
        "colab_type": "code",
        "outputId": "83a39c3c-e565-47f6-83e2-f1e3909eadf6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "accuracy_score(original_label, predicted_label)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7540983606557377"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "metadata": {
        "id": "WWAw6_818zVR",
        "colab_type": "code",
        "outputId": "a1755c55-251b-4311-b32d-1d52b62c7b33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 678
        }
      },
      "cell_type": "code",
      "source": [
        "confusion_matrix(original_label, predicted_label)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  4,   0,   0,   0,   2,   0,   0,   0,   0,   1,   0,   0,   0,\n",
              "         12,   0,   0,   1,   0],\n",
              "       [  0,   7,   0,   0,   0,   0,   3,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   2,   2],\n",
              "       [  0,   0,  16,   0,   1,   0,   4,   2,   0,   0,   0,   0,   0,\n",
              "          0,   6,   1,   0,   0],\n",
              "       [  0,   0,   0,  29,   2,   0,   0,   2,   0,   0,   0,   0,   0,\n",
              "          0,   1,   1,   1,   0],\n",
              "       [  0,   0,   0,   0,  82,   0,   0,   2,   0,   0,   0,   0,   0,\n",
              "          1,   0,   0,   0,   1],\n",
              "       [  0,   0,   0,   0,   0,  49,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   3,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   2,   0,  20,   0,   0,   0,   0,   0,   0,\n",
              "          3,   2,   4,   1,   0],\n",
              "       [  0,   0,   0,   6,   0,   0,   0,  26,   4,   0,   0,   0,   0,\n",
              "          1,   6,   0,   1,   0],\n",
              "       [  0,   0,   1,   4,   0,   0,   2,   3,  13,   0,   0,   0,   0,\n",
              "          4,   1,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   5,   0,   0,   0,\n",
              "          3,   7,   1,   0,   0],\n",
              "       [  0,   0,   0,   2,   0,   1,   0,   0,   0,   0,  15,   0,   0,\n",
              "          1,   4,   0,   1,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   8,   0,\n",
              "          5,  11,   0,   0,   0],\n",
              "       [  0,   0,   0,   1,   0,   0,   0,   0,   0,   0,   3,   0,   8,\n",
              "          1,   1,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   1,   2,   0,   0,   0,   0,   0,   0,   0,\n",
              "         48,   7,   0,   0,   2],\n",
              "       [  0,   0,   0,   0,   0,   0,   2,   2,   0,   0,   1,   1,   0,\n",
              "          7, 114,   0,   0,   1],\n",
              "       [  2,   0,   0,   0,   1,   0,   0,   1,   0,   0,   0,   0,   0,\n",
              "          0,   1,  48,   1,   0],\n",
              "       [  0,   0,   0,   3,   0,   1,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,  38,   0],\n",
              "       [  0,   0,   0,   0,   0,   1,   0,   0,   1,   0,   0,   0,   0,\n",
              "          2,   1,   0,   1,  22]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "metadata": {
        "id": "3lubM1T_83VK",
        "colab_type": "code",
        "outputId": "62a1ee16-c2ff-4cf1-a8b1-d6cdd5779df4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        }
      },
      "cell_type": "code",
      "source": [
        "print(classification_report(original_label, predicted_label))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.20      0.31        20\n",
            "           1       1.00      0.50      0.67        14\n",
            "           2       0.94      0.53      0.68        30\n",
            "           3       0.64      0.81      0.72        36\n",
            "           4       0.90      0.95      0.93        86\n",
            "           5       0.91      0.94      0.92        52\n",
            "           6       0.65      0.62      0.63        32\n",
            "           7       0.68      0.59      0.63        44\n",
            "           8       0.72      0.46      0.57        28\n",
            "           9       0.83      0.31      0.45        16\n",
            "          10       0.79      0.62      0.70        24\n",
            "          11       0.89      0.33      0.48        24\n",
            "          12       1.00      0.57      0.73        14\n",
            "          13       0.55      0.80      0.65        60\n",
            "          14       0.69      0.89      0.78       128\n",
            "          15       0.87      0.89      0.88        54\n",
            "          16       0.81      0.90      0.85        42\n",
            "          17       0.79      0.79      0.79        28\n",
            "\n",
            "   micro avg       0.75      0.75      0.75       732\n",
            "   macro avg       0.80      0.65      0.69       732\n",
            "weighted avg       0.77      0.75      0.74       732\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}