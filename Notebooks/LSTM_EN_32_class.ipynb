{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM EN 32 class.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jdvala/Thesis/blob/master/LSTM_EN_32_class.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "m0TxQ65zixbh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Bidirectional LSTM for English with 32 classes\n",
        "\n",
        "The bidirectional LSTM is trained on sentence level and there are two evaluations, one on sentence level and one on document level"
      ]
    },
    {
      "metadata": {
        "id": "cIiz-Z6uivei",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Imports\n",
        "import os\n",
        "import keras\n",
        "import sys\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM, Bidirectional\n",
        "from keras.layers import Embedding as emb\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import load_model\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn\n",
        "from keras.utils import generic_utils \n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "\n",
        "# Setting seed to get reproducable results\n",
        "from numpy.random import seed\n",
        "from tensorflow import set_random_seed\n",
        "SEED = 13\n",
        "seed(SEED)\n",
        "set_random_seed(SEED)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "H2lyy5hCjMqa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Setting Up Google Drive\n",
        "The data used in this notebook is available in my drive."
      ]
    },
    {
      "metadata": {
        "id": "pVsPIWVTK3Gf",
        "colab_type": "code",
        "outputId": "a67e2e28-d7e6-45b9-89a4-da5526511cb2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "embding_path = '/content/gdrive/My Drive/en.de.context.emb'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "aScNdU9Ujc_w",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Getting the data\n",
        "\n",
        "The data is pickled and hence unpickling it here.\n"
      ]
    },
    {
      "metadata": {
        "id": "lqHTjrhlkMy8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# unpickle data\n",
        "import pickle\n",
        "def unpickle(obj):\n",
        "    with open(obj, 'rb') as picklehandle:\n",
        "        toReturn = pickle.load(picklehandle)\n",
        "    return toReturn\n",
        "\n",
        "en_de_combined = unpickle('/content/gdrive/My Drive/combined_data.pkl')\n",
        "label = unpickle('/content/gdrive/My Drive/en-de-label.pkl')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mDq-U-yXjpE9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Test Train Split\n",
        "\n",
        "Before doing anything, Split the data into test and train sets, so there is no information leak from train data to test data.\n",
        "This is not a problem in case of one language as every instance is either in train or test set, but in case of multilingual data it might so happen that a document from one language is in  train set and the same document from another language might end up in test set, this might be a problem, and to avoid it we split the data as soon as we have it."
      ]
    },
    {
      "metadata": {
        "id": "z_i2lhgDk83J",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Initial Test Train Split\n",
        "train_data, test_data, train_la, test_la = train_test_split(en_de_combined, label,test_size=0.3, random_state=SEED)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QIMp2zuQkleM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Seperate the data\n",
        "\n",
        "As mentioned above there is a slight chance that the information leak might happen. Hence during curation of the data, **English** and **German** data as well as their document id(manually generated), file names, multiple labels and thier labels were combined in a single list with *'\\n\\n\\n'*(three new line characters). This was done to ensure there is no information loss what so ever."
      ]
    },
    {
      "metadata": {
        "id": "_psRNM96GxUM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def seperate_data(data, label):\n",
        "    \"\"\"Seperates data from combined data, it is seperated by '\\n\\n\\n', three new line charaters\n",
        "    Returns: english data, german data, file name, doc_id, multiple labels\n",
        "    \"\"\"\n",
        "    en_data = [] \n",
        "    de_data = []\n",
        "    file_name = []\n",
        "    doc_id = []\n",
        "    multilabel = []\n",
        "    labels = []\n",
        "    \n",
        "    if isinstance(data, list):\n",
        "        for doc, l in zip(data,label):\n",
        "            en_data.append(doc.split('\\n\\n\\n')[0])\n",
        "            de_data.append(doc.split('\\n\\n\\n')[1])\n",
        "            file_name.append(doc.split('\\n\\n\\n')[2])\n",
        "            doc_id.append(doc.split('\\n\\n\\n')[3])\n",
        "            multilabel.append(doc.split('\\n\\n\\n')[4])\n",
        "            labels.append(l)\n",
        "    return en_data,de_data, file_name, doc_id, multilabel, labels\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ci53TB18HrT-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Seperating train and test data\n",
        "train_en_data,train_de_data, train_file_name, train_doc_id, train_multilabel, train_label = seperate_data(train_data, train_la)\n",
        "\n",
        "test_en_data,test_de_data, test_file_name, test_doc_id, test_multilabel, test_label = seperate_data(test_data, test_la)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PvcWndJsluXo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Sliding Window\n",
        "\n",
        "Sliding window, helper function to chunk the incoming document into predefined chuck length and step size"
      ]
    },
    {
      "metadata": {
        "id": "T0p0-kVyEfcu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def slidingWindow(sequence,winSize,step):\n",
        "    \"\"\"Returns a generator that will iterate through\n",
        "    the defined chunks of input sequence. Input sequence\n",
        "    must be sliceable.\"\"\"\n",
        "\n",
        "    # Pre-compute number of chunks to emit\n",
        "    numOfChunks = ((len(sequence)-winSize)/step)+1\n",
        "    # Do the work\n",
        "    for i in range(0,round(numOfChunks)*step,step):\n",
        "        yield sequence[i:i+winSize]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vNgEzuTNl-nl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Numbering Labels\n",
        "\n",
        "Manually labeling the alpha labels as the evaluation based on documents will require more control over the label  "
      ]
    },
    {
      "metadata": {
        "id": "JBmZ9505DgPg",
        "colab_type": "code",
        "outputId": "2e308722-9fda-494a-e14c-8d558a531759",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "# Numbering the labels\n",
        "label_num = dict(enumerate(sorted(set(label))))\n",
        "print(label_num)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{0: 'agriculture', 1: 'audiovisual_and_media', 2: 'budget', 3: 'competition', 4: 'consumers', 5: 'culture', 6: 'customs', 7: 'development', 8: 'economic_and_monetary_affairs', 9: 'education_training_youth', 10: 'employment_and_social_policy', 11: 'energy', 12: 'enlargement', 13: 'enterprise', 14: 'environment', 15: 'external_relations', 16: 'external_trade', 17: 'fight_against_fraud', 18: 'food_safety', 19: 'foreign_and_security_policy', 20: 'human_rights', 21: 'humanitarian_aid', 22: 'information_society', 23: 'institutional_affairs', 24: 'internal_market', 25: 'justice_freedom_security', 26: 'maritime_affairs_and_fisheries', 27: 'public_health', 28: 'regional_policy', 29: 'research_innovation', 30: 'taxation', 31: 'transport'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Bqjj3K1NmWS5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Train Sentence preparation\n",
        "\n",
        "From the training documents we are creating sentences and the giving them corresponding numeric labels to each sentence"
      ]
    },
    {
      "metadata": {
        "id": "8JImdQ4qlE9a",
        "colab_type": "code",
        "outputId": "18b89744-9af5-4a36-e19c-b9af995089d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# Train data preparation\n",
        "_train_sentence = []\n",
        "_train_label = []\n",
        "\n",
        "for doc, labe in zip(train_en_data, train_label):\n",
        "    # call the sliding window on doc\n",
        "    \n",
        "    slides = slidingWindow(doc.split(' '), 30, 10)\n",
        "    \n",
        "    # get the num label \n",
        "    for key, value in label_num.items():\n",
        "        if value == labe:\n",
        "            num = key\n",
        "            \n",
        "      \n",
        "    for slide in slides:\n",
        "        _train_sentence.append(slide)\n",
        "        _train_label.append(num)\n",
        "\n",
        "\n",
        "# ensuring the number of samples in train set and labels\n",
        "print(len(_train_sentence), len(_train_label))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "84225 84225\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qemei-HbmuL2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Tokenizing training sentence\n",
        "\n",
        "Toknizing the training sentences and then fitting it on train sentence and then use the same tokenizer object on test data\n",
        "Also calculate the vocabulary size which we will need in the embedding layer. "
      ]
    },
    {
      "metadata": {
        "id": "PM5hxLg-GYDH",
        "colab_type": "code",
        "outputId": "9a60700d-7309-4c26-f6e8-f9d37620109c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "cell_type": "code",
      "source": [
        "# tokenizing Sentences Using Keras tokenizer\n",
        "tokenizer = keras.preprocessing.text.Tokenizer()\n",
        "\n",
        "# Tokenizing the sentences (This process may take some time depending on your corpus size)\n",
        "tokenizer.fit_on_texts(_train_sentence)\n",
        "\n",
        "# Lets see what our vocabulary size is\n",
        "vocab_size = len(tokenizer.word_index) + 1   # We are adding 1 here because it takes indexing from zero\n",
        "print(\"Vocabulary size is: {}\".format(vocab_size))\n",
        "\n",
        "# Sentence encoding (it means we are now converting words into numbers)\n",
        "sent_encoded = tokenizer.texts_to_sequences(_train_sentence)\n",
        "print(\"The number of sentence in train set after encoding: {}\".format(len(sent_encoded)))\n",
        "\n",
        "\n",
        "# Start padding with the 30, although we wont need it, but still as precautionary measure\n",
        "max_len = len(_train_sentence[1])\n",
        "print('Maximum length of sentences in training set is', max_len)\n",
        "padded_sents = keras.preprocessing.sequence.pad_sequences(sent_encoded, maxlen=max_len, padding='post')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocabulary size is: 18455\n",
            "The number of sentence in train set after encoding: 84225\n",
            "Maximum length of sentences in training set is 30\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RXswQd3qn0Xt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## One Hot Encoding Labels\n",
        "\n",
        "The numerical labels needs to be converted into its one hot encoded form."
      ]
    },
    {
      "metadata": {
        "id": "GJbJAHtlgNYN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Converting train labels into one hot encoded form\n",
        "oht_obj = OneHotEncoder(sparse=False, categories='auto')\n",
        "oht_obj.fit((np.reshape(_train_label, (-1,1))))\n",
        "\n",
        "train_labels = oht_obj.transform((np.reshape(_train_label, (-1,1))))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "68jWOCson--a",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Callback\n",
        "\n",
        "Two call backs are used here,\n",
        "\n",
        "* *reduce_rate*:  Which helps in situation where we are stuck on a Plateau.\n",
        "* *early_stopping*: It monitors the validation loss and in case of overfitting it will wait for the number of epochs given by user before stopping the leanring process.\n"
      ]
    },
    {
      "metadata": {
        "id": "sB2BE6IjHNBk",
        "colab_type": "code",
        "outputId": "58c3c457-f305-4764-b282-5887776e7966",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "# Other callbacks \n",
        "reduce_rate = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=0, verbose=1, \n",
        "                                                mode='auto', epsilon=0.0001, cooldown=0, min_lr=0)\n",
        "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, \n",
        "                                           patience=2, verbose=1, mode='auto')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/callbacks.py:1065: UserWarning: `epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
            "  warnings.warn('`epsilon` argument is deprecated and '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "M8b1_QAPv_pl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learning_rate = 0.001\n",
        "optimizer = keras.optimizers.RMSprop(lr=learning_rate, rho=0.9, epsilon=None, decay=0.0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Si5H--iso4ki",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Model Architecture"
      ]
    },
    {
      "metadata": {
        "id": "QnatoFO6qL6W",
        "colab_type": "code",
        "outputId": "246c8d61-555a-4c89-a901-587e45bdcc64",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 661
        }
      },
      "cell_type": "code",
      "source": [
        "from IPython.display import Image\n",
        "Image('/content/model.png')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAKECAIAAACB3HpjAAAABmJLR0QA/wD/AP+gvaeTAAAgAElE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\niiI5AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "metadata": {
        "id": "Y2qkLpDhG4Pb",
        "colab_type": "code",
        "outputId": "d143a65d-77ce-4b9e-9eda-8f9fb3c0bf70",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        }
      },
      "cell_type": "code",
      "source": [
        "# Create sequential model\n",
        "model = Sequential()\n",
        "model.add(emb(vocab_size, 200, input_length=max_len))   \n",
        "model.add(Bidirectional(LSTM(40, activation='tanh',return_sequences=True, kernel_regularizer=keras.regularizers.l2(0.04))))# LSTM layer \n",
        "model.add(keras.layers.Dropout(0.5))\n",
        "model.add(Bidirectional(LSTM(40, activation='tanh',return_sequences=False, kernel_regularizer=keras.regularizers.l2(0.03))))\n",
        "model.add(keras.layers.Dropout(0.5))\n",
        "model.add(Dense(32, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer= optimizer, metrics=['accuracy'])\n",
        "print(model.summary())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, 30, 200)           3691000   \n",
            "_________________________________________________________________\n",
            "bidirectional_3 (Bidirection (None, 30, 80)            77120     \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 30, 80)            0         \n",
            "_________________________________________________________________\n",
            "bidirectional_4 (Bidirection (None, 80)                38720     \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 80)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 32)                2592      \n",
            "=================================================================\n",
            "Total params: 3,809,432\n",
            "Trainable params: 3,809,432\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "fI6lwDyBpGsu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Model visualization\n",
        "from keras.utils import plot_model\n",
        "plot_model(model, to_file='model.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "S_xYFvkjpES6",
        "colab_type": "code",
        "outputId": "4c828b84-396d-401a-fe14-0c06ad10d639",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 567
        }
      },
      "cell_type": "code",
      "source": [
        "# Training the mdoel\n",
        "model.fit(padded_sents, train_labels, validation_split=0.3, epochs=20, batch_size=32, \n",
        "          verbose=1, callbacks=[reduce_rate,early_stop])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 58957 samples, validate on 25268 samples\n",
            "Epoch 1/20\n",
            "58957/58957 [==============================] - 277s 5ms/step - loss: 3.1507 - acc: 0.1920 - val_loss: 2.8249 - val_acc: 0.2113\n",
            "Epoch 2/20\n",
            "58957/58957 [==============================] - 272s 5ms/step - loss: 2.3581 - acc: 0.3159 - val_loss: 2.7380 - val_acc: 0.2526\n",
            "Epoch 3/20\n",
            "58957/58957 [==============================] - 272s 5ms/step - loss: 2.1365 - acc: 0.4000 - val_loss: 2.6875 - val_acc: 0.2965\n",
            "Epoch 4/20\n",
            "58957/58957 [==============================] - 264s 4ms/step - loss: 1.8885 - acc: 0.4959 - val_loss: 2.6528 - val_acc: 0.3586\n",
            "Epoch 5/20\n",
            "58957/58957 [==============================] - 264s 4ms/step - loss: 1.6585 - acc: 0.5703 - val_loss: 2.5336 - val_acc: 0.3776\n",
            "Epoch 6/20\n",
            "58957/58957 [==============================] - 265s 4ms/step - loss: 1.4880 - acc: 0.6274 - val_loss: 2.6710 - val_acc: 0.3826\n",
            "\n",
            "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "Epoch 7/20\n",
            "58957/58957 [==============================] - 261s 4ms/step - loss: 1.1965 - acc: 0.7109 - val_loss: 2.4414 - val_acc: 0.4341\n",
            "Epoch 8/20\n",
            "58957/58957 [==============================] - 264s 4ms/step - loss: 1.1292 - acc: 0.7267 - val_loss: 2.4173 - val_acc: 0.4318\n",
            "Epoch 9/20\n",
            "58957/58957 [==============================] - 266s 5ms/step - loss: 1.0921 - acc: 0.7358 - val_loss: 2.4114 - val_acc: 0.4386\n",
            "Epoch 10/20\n",
            "58957/58957 [==============================] - 266s 5ms/step - loss: 1.0571 - acc: 0.7464 - val_loss: 2.4482 - val_acc: 0.4380\n",
            "\n",
            "Epoch 00010: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "Epoch 11/20\n",
            "58957/58957 [==============================] - 264s 4ms/step - loss: 1.0102 - acc: 0.7588 - val_loss: 2.4435 - val_acc: 0.4432\n",
            "\n",
            "Epoch 00011: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
            "Epoch 00011: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f36bc3f6dd8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "metadata": {
        "id": "7iDNmLaa1hMd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Saving the model\n",
        "model.save('/content/gdrive/My Drive/Thesis Models/EN_32_CLASS_LSTM.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "f3vkqxvtqtKp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Evaluation on Document level\n",
        "\n",
        "SVMs are trained on document level and to make a fair evaluation the LSTMs needs to be evaluated on document level as well, but LSTM are trained on sentence level as due to hardware limitations one can not feed the whole document hence the technique used here is a little unique. \n",
        "\n",
        "So to make a fair comparision, the evaluation has to be done manually, first the document has to be divided into sentences with same technique used during training, then when all the sentence from a single document is curated then they are encoded into numeric form and padded to make all of them of equal length.\n",
        "\n",
        "Then each sentence is predicted and the predictions are normalized and combined to make it a single prediction for the whole document.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "S5Lq1Y2hl_DG",
        "colab_type": "code",
        "outputId": "6d1839c8-216e-4c54-96ef-e0db9dc39d09",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        }
      },
      "cell_type": "code",
      "source": [
        "# Loading the model for evaluation\n",
        "from keras.models import load_model\n",
        "model = load_model('/content/gdrive/My Drive/Thesis Models/EN_32_CLASS_LSTM.h5')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "UqYuNrVoHNuo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler, Normalizer, StandardScaler\n",
        "\n",
        "original_label = []   # list to store the original label \n",
        "predicted_label = []   # list to store the predicted label\n",
        "\n",
        "for first_data, first_label in zip(test_en_data,test_label):\n",
        "    ## TMP LIST for each doc\n",
        "    sent_pred = []\n",
        "    \n",
        "    # start chunking the text into 30 words with 10 word slide\n",
        "    slides = slidingWindow(first_data.split(' '),30,10)\n",
        "        \n",
        "    for key,value in label_num.items():\n",
        "        if value == first_label:\n",
        "            num = key\n",
        "    \n",
        "    doc_sent = []\n",
        "    for slide in slides:\n",
        "        \n",
        "        a = ' '.join(slide)\n",
        "        \n",
        "        doc_sent.append(a)\n",
        "    \n",
        "        \n",
        "    # we have the slide here, create the sequence from text to numbers\n",
        "    text_sequence = tokenizer.texts_to_sequences(doc_sent)\n",
        "\n",
        "    # pad it to make flat 30 lenght\n",
        "    text_padded = keras.preprocessing.sequence.pad_sequences(text_sequence, maxlen=30, padding='post')\n",
        "\n",
        "\n",
        "    # predict the label\n",
        "    sent_pred.append(model.predict(text_padded))        \n",
        "    \n",
        "    # normailizing the predictions before combining them.\n",
        "    nor_data = []\n",
        "    for predc in sent_pred:\n",
        "        transformer2 = Normalizer().fit(predc)\n",
        "        nor_data.append(transformer2.transform(predc))    \n",
        "        \n",
        "    # adding all the predictions of sentences of a single document into one.\n",
        "    sent = np.zeros(32)\n",
        "    for sen in nor_data:\n",
        "        for i in range(len(sen)):\n",
        "            sent += sen[i]\n",
        "    \n",
        "    # populating lists of the predicted labels and original labels for further evaluation\n",
        "    predicted_label.append(np.argmax(sent, axis=0))\n",
        "    original_label.append(num)\n",
        "    \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EQXiyNdcfvPZ",
        "colab_type": "code",
        "outputId": "1badf855-ba4c-4171-bc0b-9b17ce479db5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# Accuracy on document level\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "print(\"Accuracy of the model on document level is: {:.2f} %\".format(accuracy_score(original_label, predicted_label)*100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the model on document level is: 64.66 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RxpNYfiSrpac",
        "colab_type": "code",
        "outputId": "f788afe7-39b5-49b6-d215-199a638e37f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1154
        }
      },
      "cell_type": "code",
      "source": [
        "# Classification report and confusion Matrix\n",
        "np.set_printoptions(threshold=np.nan)\n",
        "print(confusion_matrix(original_label, predicted_label))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[21  0  0  0  1  0  0  0  0  0  1  0  1  0  1  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  4  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0]\n",
            " [ 1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  2  1  0  0  0  0  0  3\n",
            "   0  0  0  1  0  0  2  0]\n",
            " [ 2  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  9  0  0  0  0  0  0  0\n",
            "   1  0  1  0  0  0  0  1]\n",
            " [ 1  0  0  0 23  0  0  0  0  0  1  0  0  0  0  0  1  0  1  0  0  0  0  0\n",
            "   4  2  0  0  0  0  0  4]\n",
            " [ 0  0  0  0  0  6  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  1  0  0]\n",
            " [ 0  0  0  0  0  0  8  0  0  0  1  0  2  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  2  0  0  0  0  0  2]\n",
            " [ 0  0  0  0  0  0  0 11  1  0  0  0  0  1  1  0  1  0  0  0  0  0  0  1\n",
            "   0  1  0  0  0  0  1  0]\n",
            " [ 0  0  0  0  0  0  0  0 39  0  1  0  0  0  0  0  0  0  0  0  0  0  1  0\n",
            "   2  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0 24  1  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  1  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  1 33  0  0  1  0  0  0  0  0  0  0  0  2  1\n",
            "   3  0  1  1  3  1  0  0]\n",
            " [ 1  0  0  0  1  0  0  1  0  0  1 17  0  2  4  0  0  0  0  0  0  0  0  1\n",
            "   0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  1  3  8  0  0  0  1  0  0  0  0  0  0  0\n",
            "   0  2  1  0  0  0  0  0]\n",
            " [ 2  0  0  0  1  0  0  0  0  0  0  1  1  3  1  0  0  0  0  1  0  0  1  0\n",
            "   2  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  1  0  0  1  0  0  0  0  0  1 35  0  1  0  0  0  0  0  0  1\n",
            "   0  0  1  0  1  0  0  2]\n",
            " [ 0  0  0  0  0  0  0  5  1  0  0  0  0  0  0  8  3  0  0  1  0  0  0  2\n",
            "   0  2  0  0  0  0  0  0]\n",
            " [ 1  0  0  0  0  0  1  0  0  0  0  0  0  1  2  0  9  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0]\n",
            " [ 1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  4  0  0  0  0  0  0\n",
            "   0  3  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  3  0  0  0  0  0  0  0  0  0  1  0  0  0 30  0  0  0  0  0\n",
            "   3  0  0  0  1  0  0  0]\n",
            " [ 0  0  0  0  0  0  1  0  0  0  0  0  0  0  1  0  0  0  0  6  0  0  0  4\n",
            "   0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  1  0  0  0  0  2  0  0  4\n",
            "   0  3  0  0  0  1  0  0]\n",
            " [ 0  0  0  0  0  0  0  2  0  0  0  0  0  0  0  0  0  0  0  2  0  2  0  0\n",
            "   0  1  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  1  0  0  1  2  1  0  0  0  0  0  0  0  0  0  0  0 25  2\n",
            "   2  4  0  0  0  2  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  2  1  0  0  1  0  0  0  0  0  0  0  0 22\n",
            "   0  3  0  0  0  0  0  1]\n",
            " [ 0  0  0  0  8  0  0  0  1  0  6  0  0  0  1  0  1  0  0  0  0  0  3  3\n",
            "  47  2  0  0  0  0  1  1]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  1  6\n",
            "   1 55  0  0  0  0  0  0]\n",
            " [ 2  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0 23  0  0  0  0  1]\n",
            " [ 2  0  0  0  2  0  0  0  0  0  7  1  0  1  0  0  0  0  0  0  0  0  0  1\n",
            "   2  0  0  6  0  0  0  0]\n",
            " [ 3  0  0  0  0  0  0  1  0  0  0  1  1  1  1  0  0  0  0  0  0  0  1  0\n",
            "   0  0  2  0  9  0  0  1]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  1  0  0  0  1  0  1  0  0  0  0  0  1  3\n",
            "   0  0  0  0  0  7  0  0]\n",
            " [ 0  0  0  0  0  0  1  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   1  0  0  0  0  0 10  1]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  1  0  1  1  3  0  0  0  0  0  0  0  2  0\n",
            "   1  1  1  0  1  1  0 34]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "38kGsHlrr6tk",
        "colab_type": "code",
        "outputId": "6d30ce83-39f2-477a-e6b2-600bd73eed0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 745
        }
      },
      "cell_type": "code",
      "source": [
        "print(classification_report(original_label, predicted_label))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.84      0.68        25\n",
            "           1       0.00      0.00      0.00         5\n",
            "           2       0.00      0.00      0.00        10\n",
            "           3       0.00      0.00      0.00        15\n",
            "           4       0.56      0.62      0.59        37\n",
            "           5       0.55      0.86      0.67         7\n",
            "           6       0.73      0.53      0.62        15\n",
            "           7       0.52      0.61      0.56        18\n",
            "           8       0.89      0.91      0.90        43\n",
            "           9       0.86      0.92      0.89        26\n",
            "          10       0.56      0.70      0.62        47\n",
            "          11       0.71      0.61      0.65        28\n",
            "          12       0.50      0.50      0.50        16\n",
            "          13       0.25      0.23      0.24        13\n",
            "          14       0.66      0.80      0.72        44\n",
            "          15       0.89      0.36      0.52        22\n",
            "          16       0.31      0.64      0.42        14\n",
            "          17       0.80      0.50      0.62         8\n",
            "          18       0.97      0.79      0.87        38\n",
            "          19       0.60      0.50      0.55        12\n",
            "          20       1.00      0.17      0.29        12\n",
            "          21       1.00      0.29      0.44         7\n",
            "          22       0.68      0.62      0.65        40\n",
            "          23       0.41      0.73      0.52        30\n",
            "          24       0.68      0.64      0.66        74\n",
            "          25       0.67      0.86      0.75        64\n",
            "          26       0.77      0.85      0.81        27\n",
            "          27       0.75      0.27      0.40        22\n",
            "          28       0.60      0.43      0.50        21\n",
            "          29       0.54      0.50      0.52        14\n",
            "          30       0.71      0.71      0.71        14\n",
            "          31       0.71      0.72      0.72        47\n",
            "\n",
            "   micro avg       0.65      0.65      0.65       815\n",
            "   macro avg       0.61      0.55      0.55       815\n",
            "weighted avg       0.65      0.65      0.63       815\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "FsA-X2Bqo6Lh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Evaluation on Sentence level\n"
      ]
    },
    {
      "metadata": {
        "id": "dAAY4c28n23m",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# converting docs into sentences and corresponding numerical labels\n",
        "_test_sentences = []\n",
        "_test_label_alpha = []\n",
        "_test_label_num = []\n",
        "\n",
        "for _t_data, t_label in zip(test_en_data, test_label):\n",
        "    # start chunking the text into 30 words with 10 word slide\n",
        "    slides = slidingWindow(_t_data.split(' '),30,10)\n",
        "        \n",
        "    for key,value in label_num.items():\n",
        "        if value == t_label:\n",
        "            num = key\n",
        "    \n",
        "    \n",
        "    for slide in slides:\n",
        "        _test_sentences.append(' '.join(slide))\n",
        "        _test_label_alpha.append(t_label)\n",
        "        _test_label_num.append(num)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Gnl6eZ4ApV7j",
        "colab_type": "code",
        "outputId": "722f5a22-ce32-42cf-8cb2-1e453dbd8221",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "len(_test_sentences), len(_test_label_alpha), len(_test_label_num)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(36490, 36490, 36490)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "metadata": {
        "id": "0e5eYf8kqdQj",
        "colab_type": "code",
        "outputId": "b3d71755-7d2c-472d-fc97-bc0b1b4c889b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# Coverting labels to one hot encoded format\n",
        "test_label = oht_obj.transform(np.reshape(_test_label_num,(-1,1)))\n",
        "print(len(test_label))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "36490\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "DVFw4c3iq90t",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Test sentences to numeric converstion\n",
        "test_sequences = tokenizer.texts_to_sequences(_test_sentences)\n",
        "padded_sents_test = keras.preprocessing.sequence.pad_sequences(test_sequences, maxlen=max_len, padding='post')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "U8B9g1OmrReh",
        "colab_type": "code",
        "outputId": "27bed540-1d0a-4e4b-de55-fcf685c14e74",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "print(len(padded_sents_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "36490\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1CqU97fXrdT3",
        "colab_type": "code",
        "outputId": "219d0e5f-d558-4348-872c-45a6c251da5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "scores = model.evaluate(padded_sents_test, test_label, verbose=1)\n",
        "print(\"Accuracy on sentence level: %.2f%%\" % (scores[1]*100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "36490/36490 [==============================] - 26s 723us/step\n",
            "Accuracy on sentence level: 40.26%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "JxEJNQLZrmz6",
        "colab_type": "code",
        "outputId": "58c72151-4101-4a90-866a-a9abd106e6ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1723
        }
      },
      "cell_type": "code",
      "source": [
        "pred = model.predict(padded_sents_test)\n",
        "y_pred = np.argmax(pred, axis=1)\n",
        "y_true = np.argmax(test_label, axis=1)\n",
        "print(confusion_matrix(y_true, y_pred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 713    0   15   35  112    0    7   94    6    2   32   12   31   43\n",
            "    95   11   95    4   95    0    0    0    8   24   33   14   78   32\n",
            "    41    6   11   14]\n",
            " [   5   26   12    3    3   87    3    2    3   31    4    7    7   10\n",
            "     1   12    4    0    0    3    1    2   17    3    4    3    1    4\n",
            "     1   21    0    1]\n",
            " [  29    0   19    7    3    3   17   22   12   11   12   16   10   16\n",
            "    12   23   39    9    1    3    1    0    6   40   11   13    2   20\n",
            "    15    6   43    8]\n",
            " [  58    0   11   63   42    2    3    5    8    1    2    3    8   12\n",
            "    39    2  182    7   13    1    0    0    2   15   50    9   22    9\n",
            "     2    2    6   45]\n",
            " [  59    0    2    8  493    0    3    4   10    4   46    0    3   20\n",
            "    34    1   19    4   96    0    1    0   17   25  173   72   25    7\n",
            "    10    3    3  131]\n",
            " [   1   21    2    0    0   81    0    1    0   31    2   15   30    9\n",
            "     1   18    0    0    0    1    0    1    5    7    0    0    0    4\n",
            "     2   11    0    0]\n",
            " [  12    0   12    3   32    1  210    6    7    3   29    0   52    7\n",
            "     3   21   48   37    8   18   22    0    9   24   26   81    5    8\n",
            "     2    3   40   23]\n",
            " [  31    7    7    2    1    5   17  269   14    7    8   29   15   19\n",
            "    19   64   58    5    0   40    7   46    2   25    2   14    3    2\n",
            "     9    9   10    1]\n",
            " [   5    0   25    3    5    4    1    5 1888   11  179    9  109   44\n",
            "     3   16   24   38    1    0    2    2   35   35   99   15    4   24\n",
            "    10   17    5    2]\n",
            " [   0    1    2    0    2    4    8    0    9  773   76    1   52    3\n",
            "     0    8    3    2    0    5    1    0   60   46    1   43    1    2\n",
            "     5   31    0    1]\n",
            " [  11    1    9    5   38    0    3    5   60   83  824   14  101   54\n",
            "    15   13   16   10    3    0    9    1   97   77   97  122   29   60\n",
            "    65   37    0   38]\n",
            " [  46   19    3    6   31    5    5   37    4    3   28  403    4  124\n",
            "    87    7   48    2    1    4    1    5   18   21   33   17   12   10\n",
            "    18   25    0   13]\n",
            " [  36   11   12    1    3   11   13   15   24    3   53  125  230   23\n",
            "    20   28   19   24    5    3   43    0    2   46   19  109   31   17\n",
            "     3    8    5    3]\n",
            " [  32    1    7    5   18    3    4   18   19    3   17   41   39   79\n",
            "    21   16   23    5    4   29    0    1   15   15   38    6    5    9\n",
            "     9   15    2    9]\n",
            " [ 120    0    4    8   60    0    6   88    5    4   24   65   13   85\n",
            "   637   23   59    3    6    4    0    0   16   68   41   16   56   18\n",
            "    42   19    0   89]\n",
            " [  23    1   22    0    4   21   33  125   11   37   14   34   37   26\n",
            "    12  176   74   11    1   64   26   26   10   91   13   82   11    5\n",
            "    12   29    4    5]\n",
            " [  58    0    5    5   22    0   26   38    7    0   12    6    5   26\n",
            "    30   17  171    6    4    5    5    2    6   18   28   22    2    7\n",
            "     9    0    7    9]\n",
            " [  15    0    2    3    7    0   21    1    8    1    6    0    2    4\n",
            "     4    5   10   71    4    4    2    0    3   20   20   72    2    0\n",
            "     4    0   19    3]\n",
            " [  78    0    4   10  193    0    3    4    1    0    5    1    2   12\n",
            "    42    3   20    2  806    0    0    0    4    8   70   17   58    9\n",
            "     7    0   10   24]\n",
            " [   3    2    6    1    2    2   29   37    0    0    9    5    5    7\n",
            "    24   41   14    2    0   96    7    6    6   54    3   11    2    2\n",
            "    11    7    1    9]\n",
            " [   0    0    1    0    0    0   12   13    0    8   16    0   40    1\n",
            "     0   78    2    1    1   29   84    0    6  119    1  123    0    1\n",
            "     0    6    1    1]\n",
            " [   2    0    5    0    0    1    8   42    0    6    1    6    3    3\n",
            "     5   76   12    0    0   96    9   55    1   44    2   20    0    2\n",
            "     1    1    0    1]\n",
            " [   4    8   10    3   31   13    2    5   24   84  140    5   41   39\n",
            "    38    9    9    9    1    0    5    2  866  128   87  145    5    9\n",
            "    36  122    0   79]\n",
            " [   6    3    2    0    5    5    4    6   18   23   54   28   21   17\n",
            "    20   41   16    9    1    4   13    2   52  650   25  287    1    7\n",
            "     8   19    0   34]\n",
            " [  34    0   12   18  264    0   25   13  116   10  232   19   27  109\n",
            "    70   18   85   36   49    5    3    1  191  160 1120  153    3   27\n",
            "    29   17   25  109]\n",
            " [  10    1    7    1   45    0   36   22   12    7   73    8   44   17\n",
            "    20   63   46   45    1    6  101    1   76  360  120 1689    3   12\n",
            "     6    8    8   34]\n",
            " [ 113    0    5   17   21    0    5   14   20    0   17    4    6   17\n",
            "    74    4   31    5   23    0    4    0   11   27   14    8  714    5\n",
            "    22    4    0   59]\n",
            " [  41    3   14   12   88    9    8   14   17   11  194   25   15   65\n",
            "    13   14   15    1   26    0    1    4   23   21   43   28    9  149\n",
            "    46   14    7   16]\n",
            " [ 168    3   25   12   18    5    7  132   35   33  111   81   54  117\n",
            "   113   43   20    3    3    5    0    4   99   32   26    9  125   83\n",
            "   205   47    7   49]\n",
            " [  12    0    1    4    0    0    0    7   18   26   16   36   12   25\n",
            "    30    6   15    2    0    0    1    0   63   78   11    4    5    2\n",
            "    16  121    2    4]\n",
            " [  13    0    2   13   20    0   45    2   11    0   32    2   17    3\n",
            "     6    3   20   27   16    0    0    0    1    3   30    9    2    2\n",
            "     2    4  168   10]\n",
            " [  27    1    3    2  218    0    9   10    9    1   83   15   29   50\n",
            "   125   22   22    7    5    2    2    0  144   48  117   69   94   17\n",
            "    48   23    5  842]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "CgTt24tFsllq",
        "colab_type": "code",
        "outputId": "6ff00ded-a152-421e-c2a7-9eca391a7a6d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 710
        }
      },
      "cell_type": "code",
      "source": [
        "print(classification_report(y_true, y_pred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.40      0.43      0.42      1663\n",
            "           1       0.24      0.09      0.13       281\n",
            "           2       0.07      0.04      0.05       429\n",
            "           3       0.25      0.10      0.14       624\n",
            "           4       0.28      0.39      0.32      1273\n",
            "           5       0.31      0.33      0.32       243\n",
            "           6       0.37      0.28      0.32       752\n",
            "           7       0.25      0.36      0.30       747\n",
            "           8       0.79      0.72      0.76      2620\n",
            "           9       0.64      0.68      0.66      1140\n",
            "          10       0.35      0.43      0.39      1897\n",
            "          11       0.40      0.39      0.39      1040\n",
            "          12       0.22      0.24      0.23       945\n",
            "          13       0.07      0.16      0.10       508\n",
            "          14       0.39      0.40      0.40      1579\n",
            "          15       0.20      0.17      0.18      1040\n",
            "          16       0.14      0.31      0.19       558\n",
            "          17       0.18      0.23      0.20       313\n",
            "          18       0.69      0.58      0.63      1393\n",
            "          19       0.22      0.24      0.23       404\n",
            "          20       0.24      0.15      0.19       544\n",
            "          21       0.34      0.14      0.20       402\n",
            "          22       0.46      0.44      0.45      1959\n",
            "          23       0.28      0.47      0.35      1381\n",
            "          24       0.48      0.38      0.42      2980\n",
            "          25       0.51      0.59      0.55      2882\n",
            "          26       0.55      0.57      0.56      1244\n",
            "          27       0.26      0.16      0.20       946\n",
            "          28       0.29      0.12      0.17      1674\n",
            "          29       0.19      0.23      0.21       517\n",
            "          30       0.43      0.36      0.39       463\n",
            "          31       0.51      0.41      0.45      2049\n",
            "\n",
            "   micro avg       0.40      0.40      0.40     36490\n",
            "   macro avg       0.34      0.33      0.33     36490\n",
            "weighted avg       0.42      0.40      0.40     36490\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mfE7y7tfstYZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}